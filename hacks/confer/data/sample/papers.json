{
  "tut01": {
    "abstract": "This tutorial will cover the process of building and validating IR test collections. The goal is not for attendees to kick off their own evaluation campaigns, but to enable them to consider whether they may be able to build their own test collections to support their research. At the end of the day, attendees will be familiar with the history of the test collection evaluation paradigm; the design process starting from identifying user tasks and abstracting them; different ways of establishing a document collection; methods for operationalizing relevance; strategies for identifying items in the collection to label, including pooling and sampling; and methods for measuring and validating test collections.",
    "title": "Building Test Collections: An Interactive Guide for Students and Others Without their own Evaluation Conference Series",
    "authors": [
      {
        "affiliation": "National Institute of Standards and Technology",
        "location": "Gaithersburg, MD, USA",
        "name": "Ian Soboroff",
        "email": "ian.soboroff@nist.gov"
      }
    ]
  },
  "tut02": {
    "abstract": "This full-day tutorial presents a comprehensive introduction to entity linking and retrieval. Part I provides a detailed overview of entity linking, which addresses identifying and disambiguating entity occurrences in unstructured text. We introduce the fundamental concepts and principles underlying entity linking, and detail state-of-the-art algorithms including unsupervised solutions, graph-based methods, and feature-based approaches in a machine learning setting. We continue with applications of entity linking for IR and conclude this part with a discussion of evaluation methodologies and initiatives in the context of entity linking. Part II focuses on entity retrieval and begins with a study of scenarios where explicit representations of entities are available in the form of, e.g., Wikipedia pages or RDF triples. We then continue in a setting with more complex queries, requiring evidence to be collected and aggregated from massive volumes of unstructured textual data (with the potential help of some structured data). Such complex queries require a combination of techniques from both entity linking and entity retrieval. Throughout Part II, two main families of models are discussed: generative language models and discriminative feature-based models. Both the entity linking and entity retrieval parts are anchored in recent evaluation efforts conducted at standard benchmarking campaigns such as INEX, TAC, and TREC. We introduce test collections, tasks, evaluation methodology, and experimental results from these evaluation initiatives. Part III concludes the tutorial with an overview and hands-on comparative analysis of applications and publicly available toolkits and web services.",
    "title": "Entity Linking and Retrieval",
    "authors": [
      {
        "affiliation": "Yahoo! Research",
        "location": "Barcelona, Spain",
        "name": "Edgar Meij",
        "email": "emeij@yahoo-inc.com"
      },
      {
        "affiliation": "University of Stavanger",
        "location": "Stavanger, Norway",
        "name": "Krisztian Balog",
        "email": "krisztian.balog@uis.no"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Daan Odijk",
        "email": "d.odijk@uva.nl"
      }
    ]
  },
  "tut03": {
    "abstract": "This tutorial serves as an introductory course to the field of and state-of-the-art in music information retrieval (MIR) and in particular to music similarity estimation which is an essential component of music retrieval. Apart from briefly explaining approaches that estimate similarity based on acoustic properties of an audio signal, we will review methods that exploit (mostly textual) meta-data from the web to build representations of music then used for similarity calculation. Additionally, topics such as (large-scale) music indexing, information extraction for music, personalisation and adaptation in music retrieval, and evaluation of MIR systems will be addressed.",
    "title": "Music Similarity and Retrieval",
    "authors": [
      {
        "affiliation": "Johannes Kepler University Linz",
        "location": "Linz, Austria",
        "name": "Peter Knees and Markus Schedl",
        "email": "peter.knees@jku.at"
      }
    ]
  },
  "tut04": {
    "abstract": "The cluster hypothesis (van Rijsbergen '79) states that closely associated documents tend to be relevant to the same requests. This is one of the most fundamental and influential hypotheses in the information retrieval field. This tutorial will survey the different lines of work that the hypothesis has given rise to (e.g., cluster-based retrieval, using topic modeling for retrieval, search results visualization). The survey will be accompanied by an in-depth analysis of the retrieval techniques that are inspired by the cluster hypothesis and which are used for various tasks including ad hoc retrieval, meta-search, microblog (e.g., Twitter) retrieval, query-performance prediction, search-results diversification.",
    "title": "The Cluster Hypothesis in Information Retrieval",
    "authors": [
      {
        "affiliation": "Technion - Israel Institute of Technology",
        "location": "Haifa, Israel",
        "name": "Oren Kurland",
        "email": "kurland@ie.technion.ac.il"
      }
    ]
  },
  "tut05": {
    "abstract": "Commercial web search engines rely on very large compute infrastructures to be able to cope with the continuous growth of the Web and user bases. Achieving scalability and efficiency in such large-scale search engines requires making careful architectural design choices while devising algorithmic performance optimizations. Unfortunately, most details about the internal functioning of commercial web search engines remain undisclosed due to their financial value and the high level of competition in the search market. The main objective of this tutorial is to provide an overview of the fundamental scalability and efficiency challenges in commercial web search engines, bridging the existing gap between the industry and academia.",
    "title": "Scalability and Efficiency Challenges in Commercial Web Search Engines",
    "authors": [
      {
        "affiliation": "Yahoo! Research",
        "location": "Barcelona, Spain",
        "name": "B. Barla Cambazoglu",
        "email": "barla@yahoo-inc.com"
      },
      {
        "affiliation": "Yahoo! Research",
        "location": "Barcelona, Spain",
        "name": "Ricardo Baeza-Yates",
        "email": "rbaeza@acm.org"
      }
    ]
  },
  "tut06": {
    "abstract": "Today plenty of data is emerging from various city systems. Beyond the classical Web resources, large amounts of data are retrieved from sensors, devices, social networks, governmental applications, or service networks. In such a diversity of information, answering specific information needs of city inhabitants requires holistic IR techniques, capable of harnessing different types of city data and turned it into actionable insights to answer different queries. This tutorial will present deep insights, challenges, opportunities and techniques to make heterogeneous city data searchable and show how emerging IR techniques models can be employed to retrieve relevant information for the citizens.",
    "title": "Searching in the City of Knowledge: Challenges and Recent Developments",
    "authors": [
      {
        "affiliation": "Smarter Cities Technology Centre, IBM Research",
        "location": "Dublin, Ireland",
        "name": "Veli Bicer",
        "email": "velibice@ie.ibm.com"
      },
      {
        "affiliation": "Smarter Cities Technology Centre, IBM Research",
        "location": "Dublin, Ireland",
        "name": "Vanessa Lopez",
        "email": "vanlopez@ie.ibm.com"
      }
    ]
  },
  "tut07": {
    "abstract": "Due to the rapid growth of online multimedia information, the problem of information overload has become more and more serious in recent decades. To address the issue, various recommendation technologies have been developed by different research communities (e.g., multimedia systems, information retrieval and machine learning). Meanwhile, many commercial Web systems (e.g., Flick, YouTube, and Last.fm) have successfully applied recommendation techniques to provide users personalized multimedia content and services in a convenient and flexible way. While several tutorials and courses were dedicated to media search and relevant topics in the last few years, to the best of our knowledge, the tutorial should be the pioneering one solely focusing on multimedia recommendation technologies and their applications on various domains and media contents. We will give an overview of multimedia recommender systems and make some predictions about the road that lies ahead for IR researchers. Over long run, we hope that the tutorial provides an impetus for further research on this important topic.",
    "title": "Multimedia Recommendation: Technology and Techniques",
    "authors": [
      {
        "affiliation": "School of Information Systems, Singapore Management University",
        "location": "Bras Basah, Singapore",
        "name": "Jialie Shen",
        "email": "jlshen@smu.edu.sg"
      },
      {
        "affiliation": "Hefei University of Technology",
        "location": "Anhui, China",
        "name": "Meng Wang",
        "email": "eric.mengwang@gmail.com"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Shuicheng Yan",
        "email": "eleyans@nus.edu.sg"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Peng Cui",
        "email": "cuip@tsinghua.edu.cn"
      }
    ]
  },
  "tut08": {
    "abstract": "Kernel Methods (KMs) are powerful machine learning techniques that can alleviate the data representation problem as they substitute the scalar product between feature vectors with similarity functions (kernels) directly defined between data instances, e.g., syntactic trees, (thus features are not needed any longer). This tutorial aims at introducing essential and simplified theory of Support Vector Machines and KMs for the design of practical applications. It will describe effective kernels for easily engineering automatic classifiers and learning to rank algorithms using structured data and semantic processing. Some examples will be drawn from Question Answering, Passage Re-ranking, Short and Long Text Categorization, Relation Extraction, Named Entity Recognition, Co-Reference Resolution. In particular, state-of-the-art kernel technology currently encoded in the famous IBM deepQA system, Watson, will be described. Finally, some practical demonstrations will be given using the SVM-Light-TK (tree kernel) toolkit.",
    "title": "Kernel-based Learning to Rank with Syntactic and Semantic Structures",
    "authors": [
      {
        "affiliation": "Qatar Computing Research Institute, Qatar Foundation and DISI, University of Trento)",
        "location": "Doha, Qatar and Trento, Italy",
        "name": "Alessandro Moschitti",
        "email": "amoschitti@qf.org.qa"
      }
    ]
  },
  "tut09": {
    "abstract": "Through a stream of active research and experiences, diversity and novelty can be said to have by now consolidated into a significant body of techniques, methodologies, theories, and knowledge in the field of information retrieval. This tutorial aims to provide a unifying account of current research on diversity and novelty in different IR domains. In particular, the tutorial will cover the motivations, as well as the most established approaches for producing and evaluating diverse results in the context of search engines, recommender systems, and data streams. By contrasting the state-of the-art in these multiple domains, this tutorial aims to derive a common understanding of the diversification problem and the existing solutions, their commonalities and differences, as a means to foster new research directions.",
    "title": "Diversity and Novelty Information Retrieval",
    "authors": [
      {
        "affiliation": "University Federal de Minas Gerais",
        "location": "Minas Gerais, Brazil",
        "name": "Rodrygo L.T. Santos",
        "email": "rodrygo@dcc.ufmg.br"
      },
      {
        "affiliation": "University Autonoma de Madrid",
        "location": "Madrid, Spain",
        "name": "Pablo Castells",
        "email": "pablo.castells@uam.es"
      },
      {
        "affiliation": "Middle East Technical University",
        "location": "Ankara, Turkey",
        "name": "Ismail Sengor Altingovde",
        "email": "altingovde@ceng.metu.edu.tr"
      },
      {
        "affiliation": "Bilkent University",
        "location": "Ankara, Turkey",
        "name": "Fazli Can",
        "email": "canf@cs.bilkent.edu.tr"
      }
    ]
  },
  "tut10": {
    "abstract": "Search is not just a box and ten blue links. Search is a journey: an exploration where what we encounter along the way changes what we seek. But in order to guide people along this journey, we must understand both the art and science of search usability. The aim of this tutorial is to deliver a learning experience grounded in good scholarship, integrating the latest research findings with insights derived from the practical experience of designing and optimizing an extensive range of commercial search applications. It focuses on the development of transferable, practical skills that can be learnt and practised within a half-day session.",
    "title": "Designing Search Usability",
    "authors": [
      {
        "affiliation": "UXLabs",
        "location": "London, UK",
        "name": "Tony Russell-Rose",
        "email": "tgr@uxlabs.co.uk"
      }
    ]
  },
  "k01": {
    "abstract": "",
    "title": "Opening Session: Keynote 1:  Celebrating 20 Years of Web Search",
    "authors": [
      {
        "affiliation": "SIGIR",
        "location": "",
        "name": "Opening Panel",
        "email": ""
      }
    ]
  },
  "r1a01": {
    "abstract": "Peoples beliefs, and unconscious biases that arise from those beliefs, influence their judgment, decision making, and actions, as is commonly accepted among psychologists. Biases can be observed in information retrieval in situations where searchers seek or are presented with information that significantly deviates from the truth. There is little understanding of the impact of such biases in search. In this paper we study search-related biases via multiple probes: an exploratory retrospective survey, human labeling of the captions and results returned by a Web search engine, and a large-scale log analysis of search behavior on that engine. Targeting yes-no questions in the critical domain of health search, we show that Web searchers exhibit their own biases and are also subject to bias from the search engine. We clearly observe searchers favoring positive information over negative and more than expected given base rates based on consensus answers from physicians. We also show that search engines strongly favor a particular, usually positive, perspective, irrespective of the truth. Importantly, we show that these biases can be counterproductive and affect search outcomes; in our study, around half of the answers that searchers settled on were actually incorrect. Our findings have implications for search engine design, including the development of ranking algorithms that con-sider the desire to satisfy searchers (by validating their beliefs) and providing accurate answers and properly considering base rates. Incorporating likelihood information into search is particularly important for consequential tasks, such as those with a medical focus.",
    "title": "Beliefs and Biases in Web Search",
    "authors": [
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Ryen White",
        "email": "ryenw@microsoft.com"
      },
    ]
  },
  "r1a02": {
    "abstract": "",
    "title": "Improving Search Result Summaries By Using Searcher Behavior Data",
    "authors": [
      {
        "affiliation": "Lomonosov Moscow State University",
        "location": "Moscow, Russia",
        "name": "Mikhail Ageev",
        "email": "mageev@yandex.ru"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Dmitry Lagun",
        "email": "dlagun@emory.edu"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Eugene Agichtein",
        "email": "eugene@mathcs.emory.edu"
      }
    ]
  },
  "r1a03": {
    "abstract": "affects how users interact with a search system. Microeconomic theory is used to generate the cost-interaction hypothesis that states as the cost of querying increases, users will pose fewer queries and examine more documents per query. A between-subjects laboratory study with 36 undergraduate subjects was conducted, where subjects were randomly assigned to use one of three search interfaces that varied according to the amount of physical cost required to query: Structured (high cost), Standard (medium cost) and Query Suggestion (low cost). Results show that subjects who used the Structured interface submitted significantly fewer queries, spent more time on search results pages, examined significantly more documents per query, and went to greater depths in the search results list.  Results also showed that these subjects spent longer generating their initial queries, saved more relevant documents and rated their queries as more successful. These findings have implications for the usefulness of microeconomic theory as a way to model and explain search interaction, as well as for the design of query facilities.",
    "title": "How Query Cost Affects Search Behavior",
    "authors": [
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Leif Azzopardi",
        "email": "leif.azzopardi@glasgow.ac.uk"
      },
      {
        "affiliation": "University of North Carolina",
        "location": "Chapel Hill, NC, USA",
        "name": "Diane Kelly",
        "email": "dianek@email.unc.edu"
      },
      {
        "affiliation": "University of North Carolina",
        "location": "Chapel Hill, NC, USA",
        "name": "Kathy Brennann",
        "email": "knb11@live.unc.edu"
      }
    ]
  },
  "r1a04": {
    "abstract": "Sometimes, during a search task users may switch from one search engine to another for several reasons, e.g., dissatisfaction with the current search results or desire for broader topic coverage. Detecting the fact of switching is difficult but important for understanding users  satisfaction with the search engine and the complexity of their search tasks, leading to economic significance for search providers. Previous research on switching detection mainly focused on studying different signals useful for the task and particular reasons for switching. Although it is known that switching is a personal choice of a user and different users have different search behavior, little has been done to understand how these differences could be used for switching detection. In this paper we study the effectiveness of learning personal behavior patterns for switching detection and present a personalized approach which uses user s session history containing sessions with and without switches. Experiments show that users  personal habits and behavior patterns are indeed among the most informative signals. Our findings can be used by a search log analyzer for engine switching detection and potentially other log mining problems, thus providing valuable signals for search providers to improve user experience.",
    "title": "Search Engine Switching Detection Based on User Personal Preferences and Behavior Patterns",
    "authors": [
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Denis Savenkov",
        "email": "dsavenk@emory.edu"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Dmitry Lagun",
        "email": "dlagun@emory.edu"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Qiaoling Liu",
        "email": "qiaoling.liu@emory.edu"
      }
    ]
  },
  "r1b01": {
    "abstract": "Microblog services have emerged as an essential way to strengthen the communications among individuals and organizations. These services promote timely and active discussions and comments towards products, markets as well as public events, and have attracted a lot of attentions from organizations. In particular, emerging topics are of immediate concerns to organizations since they signal current concerns of, and feedback by their users. Two challenges must be tackled for effective emerging topic detection. One is the problem of real-time relevant data collection and the other is the ability to model the emerging characteristics of detected topics and identify them before they become hot topics. To tackle these challenges, we first design a novel scheme to crawl the relevant messages related to the designated organization by monitoring multi-aspects of microblog content, including users, the evolving keywords and their temporal sequence. We then develop an incremental clustering framework to detect new topics, and employ a range of content and temporal features to help in promptly detecting hot emerging topics. Extensive evaluations on a representative real-world dataset based on Twitter data demonstrate that our scheme is able to characterize emerging topics well and detect them before they become hot topics.",
    "title": "Emerging Topic Detection for Organizations from Microblogs",
    "authors": [
      {
        "affiliation": "Beihang University",
        "location": "Beijing, China",
        "name": "Yan Chen",
        "email": "chenyan@cse.buaa.edu.cn"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Hadi Amiri",
        "email": "hadi@comp.nus.edu.sg"
      },
      {
        "affiliation": "Beihang University",
        "location": "Beijing, China",
        "name": "Zhoujun Li",
        "email": "lizj@buaa.edu.cn"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Tat-Seng Chua",
        "email": "chuats@comp.nus.edu.sg"
      }
    ]
  },
  "r1b02": {
    "abstract": "Recent years have witnessed a persistent interest in generating pseudo test collections, both for training and evaluation purposes. We describe a method for generating queries and relevance judgments for microblog search in an unsupervised way. Our starting point is this intuition: tweets with a hashtag are relevant to the topic covered by the hashtag and hence to a suitable query derived from the hashtag. Our baseline method selects all commonly used hashtags, and all associated tweets as relevance judgments; we then generate a query from these tweets.  Next, we generate a timestamp for each query, allowing us to use temporal information in the training process. We then enrich the generation process with knowledge derived from an editorial test collection for microblog search. We use our pseudo test collections in two ways.  First, we tune parameters of a variety of well known retrieval methods on them. Correlations with parameter sweeps on an editorial test collection are high on average, with a large variance over retrieval algorithms. Second, we use the pseudo test collections as training sets in a learning to rank scenario. Performance close to training on an editorial test collection is achieved in many cases. Our results demonstrate the utility of tuning and training microblog search algorithms on automatically generated training material.",
    "title": "Pseudo Test Collections for Training and Tuning Microblog Rankers",
    "authors": [
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Richard Berendsen",
        "email": "r.w.berendsen@uva.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Manos Tsagkias",
        "email": "e.tsagkias@uva.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Wouter Weerkamp",
        "email": "w.weerkamp@uva.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Maarten de Rijke ",
        "email": "derijke@uva.nl"
      }
    ]
  },
  "r1b03": {
    "abstract": "It's well known that the transitivity of friendship is a popular sociological principle in social networks. However, it's still unknown that to what extent people's friend-making behaviors follow this principle and to what extent it can benefit the link prediction task. In this paper, we try to adopt this sociological principle to explain the evolution of networks and study the latent friendship propagation. Unlike traditional link prediction approaches, we model link formation as results of individuals' friend-making behaviors combined with personal interests. We propose the Latent Friendship Propagation Network (LFPN), which depicts the evolution progress of one's egocentric network and reveals future growth potentials driven by the transitivity of friendship based on personal interests. We model individuals' social behaviors using the Latent Friendship Propagation Model (LFPM), a probabilistic generative model from which the LFPN can be learned effectively. To evaluate the power of the friendship propagation in link prediction, we design LFPN-RW which models the friend-making behavior as a random walk upon the LFPN naturally and captures the co-influence effect of the friend circles as well as personal interests to provide more accurate prediction. Experimental results on real-world datasets show that LFPN-RW outperforms the state-of-the-art approaches. This convinces that the transitivity of friendship actually plays important roles in the evolution of social networks.",
    "title": "Learning Latent Friendship Propagation Networks with Interest Awareness for Link Prediction",
    "authors": [
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Jun Zhang",
        "email": "zhang-jun10@mails.tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Chaokun Wang",
        "email": "chaokun@tsinghua.edu.cn"
      },
      {
        "affiliation": "University of Illinois at Chicago",
        "location": "Chicago, IL, USA",
        "name": "Philip S. Yu",
        "email": "psyu@uic.edu"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Jianmin Wang",
        "email": "jimwang@tsinghua.edu.cn"
      }
    ]
  },
  "r1b04": {
    "abstract": "Social recommendation problems have drawn a lot of attention recently due to the prevalence of social networking sites. The experiments in previous literature suggest that social information is very effective in improving traditional recommendation algorithms. However, explicit social information is not always available in most of the recommender systems, which limits the impact of social recommendation techniques. In this paper, we study the following two research problems: (1)In some systems without explicit social information, can we still improve recommender systems using implicit social information? (2) In the systems with explicit social information, can the performance of using implicit social information outperform that of using explicit social information? In order to answer these two questions, we conduct comprehensive experimental analysis on three recommendation datasets. The result indicates that: (1)Implicit user and item social information, including similar and dissimilar relationships, can be employed to improve traditional recommendation methods. (2)When comparing implicit social information with explicit social information, the performance of using implicit information is slightly worse. This study provides additional insights to social recommendation techniques, and also greatly widens the utility and spreads the impact of previous and upcoming social recommendation approaches.",
    "title": "An Experimental Study on Implicit Social Recommendation",
    "authors": [
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Hao Ma",
        "email": "haoma@microsoft.com"
      }
    ]
  },
  "r1c01": {
    "abstract": "When generating query recommendations for a user, a natural approach is to try and leverage not only the user's most recently submitted query, or reference query, but also information about the current search context, such as the user's recent search interactions. We focus on two important classes of queries that make up search contexts: those that address the same information need as the reference query (on-task queries), and those that do not (off-task queries). We analyze the effects on query recommendation performance of using contexts consisting of only on-task queries, only off-task queries, and a mix of the two. Using TREC Session Track data for simulations, we demonstrate that on-task context is helpful on average but can be easily overwhelmed when off-task queries are interleaved---a common situation according to several analyses of commercial search logs. To minimize the impact of off-task queries on recommendation performance, we consider automatic methods of identifying such queries using a state of the art search task identification technique. Our experimental results show that automatic search task identification can eliminate the effect of off-task queries in a mixed context. We also introduce a novel generalized model for generating recommendations over a search context. While we only consider query text in this study, the model can handle integration over arbitrary user search behavior, such as page visits, dwell times, and query abandonment. In addition, it can be used for other types of recommendation, including personalized web search.",
    "title": "Task-Aware Query Recommendation",
    "authors": [
      {
        "affiliation": "University of Massachusetts",
        "location": "Boston, MA, USA",
        "name": "Henry Allen Feild",
        "email": "hfeild@cs.umass.edu"
      },
      {
        "affiliation": "University of Massachusetts",
        "location": "Boston, MA, USA",
        "name": "James Allan",
        "email": "allan@cs.umass.edu"
      }
    ]
  },
  "r1c02": {
    "abstract": "Web search queries are often ambiguous or multi-faceted, which makes a simple ranked list of results inadequate. To assist information finding for such faceted queries, we explore a technique that explicitly represents interesting facets of a query using groups of semantically related terms extracted from search results. As an example, for the query baggage allowance, these groups might be different airlines, different flight types (domestic, international), or different travel classes (first, business, economy). We name these groups query facets and the terms in these groups facet terms. We develop a supervised approach based on a graphical model to recognize query facets from the noisy candidates found. The graphical model learns how likely a candidate term is to be a facet term as well as how likely two terms are to be grouped together in a query facet, and captures the dependencies between the two factors. We propose two algorithms for approximate inference on the graphical model since exact inference is intractable. Our evaluation combines recall and precision of the facet terms with the grouping quality. Experimental results on a sample of web queries show that the supervised method significantly outperforms existing approaches, which are mostly unsupervised, suggesting that query facet extraction can be effectively learned.",
    "title": "Extracting Query Facets from Search Results",
    "authors": [
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Weize Kong",
        "email": "wkong@cs.umass.edu"
      },
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "James Allan",
        "email": "allan@cs.umass.edu"
      }
    ]
  },
  "r1c03": {
    "abstract": "Query auto-completion (QAC) is one of the most prominent features of modern search engines. The list of query candidates is generated according to the prex entered by the user in the search box and is updated on each new key stroke. Query prefixes tend to be short and ambiguous, and existing models mostly rely on the past popularity of matching candidates for ranking. However, the popularity of certain queries may vary drastically across different demographics and users. For instance, while instagram and imdb have comparable popularities overall and are both legitimate candidates to show for prex i, the former is noticeably more popular among young female users, and the latter is more likely to be issued by men. In this paper, we present a supervised framework for personalizing auto-completion ranking. We introduce a novel labelling strategy for generating offline training labels that can be used for learning personalized rankers. We compare the effectiveness of several user-specific and demographic-based features and show that among them, the user s long-term search history and location are the most effective for personalizing auto-completion rankers. We perform our experiments on the publicly available AOL query logs, and also on the larger-scale logs of Bing. The results suggest that supervised rankers enhanced by personalization features can significantly outperform the existing popularity-based baselines, in terms of mean reciprocal rank (MRR) by up to 9%.",
    "title": "Learning to Personalize Query Auto-Completion",
    "authors": [
      {
        "affiliation": "Microsoft",
        "location": "Cambridge, UK",
        "name": "Milad Shokouhi",
        "email": "milads@microsoft.com"
      }
    ]
  },
  "r1c04": {
    "abstract": "Patent prior art search is a task in patent retrieval where the goal is to rank documents which describe prior art work related to a patent application. One of the main properties of patent retrieval is that the query topic is a full patent application and does not represent a focused information need. This query by document nature of patent retrieval introduces new challenges and requires new investigations specific to this problem. Researchers have addressed this problem by considering different information resources for query reduction and query disambiguation. However, previous work has not fully studied the effect of using proximity information and exploiting domain specific resources for performing query disambiguation. In this paper, we first reduce the query document by taking the first claim of the document itself. We then build a query-specific patent lexicon based on definitions of the International Patent Classification (IPC). We study how to expand queries by selecting expansion terms from the lexicon that are focused on the query topic. The key problem is how to capture whether an expansion term is focused on the query topic or not. We address this problem by exploiting proximity information. We assign high weights to expansion terms appearing closer to query terms based on the intuition that terms closer to query terms are more likely to be related to the query topic. Experimental results on two patent retrieval datasets show that the proposed method is effective and robust for query expansion, significantly outperforming the standard pseudo relevance feedback (PRF) and existing baselines in patent retrieval.",
    "title": "Leveraging Conceptual Lexicon: Query Disambiguation using Proximity Information for Patent Retrieval",
    "authors": [
      {
        "affiliation": "University of Lugano",
        "location": "Lugano, Switzerland",
        "name": "Parvaz Mahdabi",
        "email": "parvaz.mahdabi@usi.ch"
      },
      {
        "affiliation": "University of Lugano",
        "location": "Lugano, Switzerland",
        "name": "Shima Gerani,",
        "email": "shima.gerani@usi.ch"
      },
      {
        "affiliation": "York University",
        "location": "Toronto, ON, Canada",
        "name": "Jimmy Xiangji Huang",
        "email": "jhuang@yorku.ca"
      },
      {
        "affiliation": "University of Lugano",
        "location": "Lugano, Switzerland",
        "name": "Fabio Crestani",
        "email": "fabio.crestani@usi.ch"
      }
    ]
  },
  "sd101": {
    "abstract": "We develop and make publicly available an entity search test collection based on the DBpedia knowledge base.  This includes a large number of queries and corresponding relevance judgments from previous benchmarking campaigns, covering a broad range of information needs, ranging from short keyword queries to natural language questions.  Further, we present baseline results for this collection with a set of retrieval models based on language modeling and BM25.  Finally, we perform an initial analysis to shed light on certain characteristics that make this data set particularly challenging.",
    "title": "A Test Collection for Entity Search in DBpedia ",
    "authors": [
      {
        "affiliation": "University of Stavanger",
        "location": "Stavanger, Norway",
        "name": "Krisztian Balog",
        "email": "krisztian.balog@uis.no"
      },
      {
        "affiliation": "Norwegian University of Science and Technology",
        "location": "Trondheim, Norway ",
        "name": "Robert Neumayer",
        "email": "robert.neumayer@idi.ntnu.no"
      }
    ]
  },
  "sd102": {
    "abstract": "Entity disambiguation is an important step in many information retrieval applications. This paper proposes new research for entity disambiguation with the focus of name disambiguation in digital libraries. In particular, pairwise similarity is first learned for publications that share the same author name string (ANS) and then a novel Hierarchical Agglomerative Clustering approach with Adaptive Stopping Criterion (HACASC) is proposed to adaptively cluster a set of publications that share a same ANS to individual clusters of publications with different author identities. The HACASC approach utilizes a mixture of kernel ridge regressions to intelligently determine the threshold in clustering. This obtains more appropriate clustering granularity than non-adaptive stopping criterion. We conduct a large scale empirical study with a dataset of more than 2 million publication record pairs to demonstrate the advantage of the proposed HACASC approach.",
    "title": "Author Disambiguation by Hierarchical Agglomerative Clustering with Adaptive Stopping Criterion",
    "authors": [
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA ",
        "name": "Lei Cen",
        "email": "lcen@purdue.edu"
      },
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA ",
        "name": "Eduard C. Dragut",
        "email": "edragut@purdue.edu"
      },
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA ",
        "name": "Luo Si",
        "email": "lsi@purdue.edu"
      },
      {
        "affiliation": "Qatar Computing Research Institute",
        "location": "Doha, Qatar",
        "name": "Mourad Ouzzani",
        "email": "mouzzani@qf.org.qa"
      }
    ]
  },
  "sd103": {
    "abstract": "The notion of relevance differs between assessors, thus giving rise to assessor disagreement.  Although assessor disagreement has been frequently observed, the factors leading to disagreement are still an open problem.  In this paper we study the relationship between assessor disagreement and various topic independent factors such as readability and cohesiveness.   We build a logistic model using reading level and other simple document features to predict assessor disagreement and rank documents by decreasing probability of disagreement.  We compare the predictive power of these document-level features with that of a meta-search feature that aggregates a document's ranking across multiple retrieval runs.  Our features are shown to be on a par with the meta-search feature, without requiring a large and diverse set of retrieval runs to calculate. Surprisingly, however, we find that the reading level features are negatively correlated with disagreement, suggesting that they are detecting some other aspect of document content.",
    "title": "Document Features Predicting Assessor Disagreement ",
    "authors": [
      {
        "affiliation": "University of Delaware",
        "location": "Newark, DE, USA",
        "name": "Praveen Chandar",
        "email": "pcr@udel.edu"
      },
      {
        "affiliation": "University of Maryland",
        "location": "College Park, MD, USA",
        "name": "William Webber",
        "email": "wew@umd.edu"
      },
      {
        "affiliation": "University of Delaware",
        "location": "Newark, DE, USA",
        "name": "Ben Carterette",
        "email": "carteret@cis.udel.edu"
      }
    ]
  },
  "sd104": {
    "abstract": "Building test collections based on nuggets is useful evaluating systems that return documents, answers, or summaries.  However, nugget construction requires a lot of manual work and is not feasible for large query sets. Towards an efficient and scalable nugget-based evaluation, we study the applicability of semi-automatic nugget extraction in the context of the ongoing NTCIR One Click Access (1CLICK) task.  We compare manually-extracted and semi-automatically-extracted Japanese nuggets to demonstrate the coverage and efficiency of the semi-automatic nugget extraction.  Our findings suggest that the manual nugget extraction can be replaced with a direct adaptation of the English semi-automatic nugget extraction system, especially for queries for which the user desires broad answers from free-form text.",
    "title": "Exploring Semi-Automatic Nugget Extraction for Japanese One Click Access Evaluation",
    "authors": [
      {
        "affiliation": "Northeastern University",
        "location": "Boston, MA, USA",
        "name": "Matthew Ekstrand-Abueg",
        "email": "mattea@ccs.neu.edu"
      },
      {
        "affiliation": "Northeastern University",
        "location": "Boston, MA, USA",
        "name": "Virgil Pavlu",
        "email": "vip@ccs.neu.edu"
      },
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": " Makoto Kato",
        "email": "kato@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Microsoft Research Asia",
        "location": "Beijing, China",
        "name": "Tetsuya Sakai",
        "email": "tesakai@microsoft.com"
      },
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": "Takehiro Yamamoto",
        "email": "tyamamot@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Osaka University",
        "location": "Osaka, Japan",
        "name": "Mayu Iwata",
        "email": "iwata.mayu@ist.osaka-u.ac.jp"
      }
    ]
  },
  "sd105": {
    "abstract": "The One Click Access Task (1CLICK) of NTCIR requires systems to return a concise multi-document summary of web pages in response to a query which is assumed to have been submitted in a mobile context. Systems are evaluated based on information units (or iUnits),  and are required to present important pieces of information first and to minimise the amount of text the user has to read. Using the official Japanese results of the second round of the 1CLICK task from NTCIR-10, we discuss our task setting and evaluation framework. Our analyses show that: (1) Simple baseline methods that leverage search engine snippets or Wikipedia are effective for lookup type queries but not necessarily for other query types; (2) There is still a substantial gap between manual and automatic runs; and (3) Our evaluation metrics are relatively robust to the incompleteness of iUnits.",
    "title": "Report from the NTCIR-10 1CLICK-2 Japanese Subtask: Baselines, Upperbounds and Evaluation Robustness",
    "authors": [
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": "Makoto P. Kato",
        "email": "kato@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Microsoft Research Asia",
        "location": "Beijing, China",
        "name": "Tetsuya Sakai",
        "email": "tesakai@microsoft.com"
      },
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": "Takehiro Yamamoto",
        "email": "tyamamot@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Osaka University",
        "location": "Osaka, Japan",
        "name": "Mayu Iwata",
        "email": "iwata.mayu@ist.osaka-u.ac.jp"
      }
    ]
  },
  "sd106": {
    "abstract": "Community Question Answering (CQA) platforms contain a large number of questions and associated answers. Answerers sometimes include URLs as part of the answers to provide further information. This paper describes a novel way of building a test collection for web search by exploiting the link information from this type of social media data. We propose to build the test collection by regarding CQA questions as queries and the associated linked web pages as relevant documents. To evaluate this approach,  we collect approximately ten thousand CQA queries, whose answers contained links to ClueWeb09 documents after spam filtering. Experimental results using this collection show that the relative effectiveness between different retrieval models on the ClueWeb-CQA query set is consistent with that on the TREC Web Track query sets, confirming the reliability of our test collection.  Further analysis shows that the large number of queries generated through this approach compensates for the sparse relevance judgments in determining significant differences.",
    "title": "Building a Web Test Collection using Social Media",
    "authors": [
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Chia-Jung Lee",
        "email": "cjlee@cs.umass.edu"
      },
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Bruce W. Croft",
        "email": "croft@cs.umass.edu"
      }
    ]
  },
  "sd107": {
    "abstract": "The NTCIR INTENT task comprises two subtasks: Subtopic Mining, where systems are required to return a ranked list of subtopic strings for each given query; and Document Ranking, where systems are required to return a diversified web search result for each given query. This paper summarises the novel features of the Second INTENT task at NTCIR-10 and its main findings, and poses some questions for future diversified search evaluation.",
    "title": "Summary of the NTCIR-10 INTENT-2 Task: Subtopic Mining and Search Result Diversification",
    "authors": [
      {
        "affiliation": "Microsoft Research Asia",
        "location": "Beijing, China",
        "name": "Tetsuya Sakai",
        "email": "tetsuyasakai@acm.org"
      },
      {
        "affiliation": "Microsoft Research Asia",
        "location": "Beijing, China",
        "name": "Zhicheng Dou",
        "email": "zhichdou@microsoft.com"
      },
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": "Takehiro Yamamoto",
        "email": "tyamamot@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Yiqun Liu",
        "email": "yiqunliu@tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Min Zhang ",
        "email": "z-m@tsinghua.edu.cn"
      },
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": "Makoto P Kato",
        "email": "kato@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Microsoft Research Asia",
        "location": "Beijing, China",
        "name": "Ruihua Song",
        "email": ""
      },
      {
        "affiliation": "Osaka University",
        "location": "Osaka, Japan",
        "name": "Mayu Iwata",
        "email": "iwata.mayu@ist.osaka-u.ac.jp"
      }
    ]
  },
  "sd108": {
    "abstract": "The judging of relevance has been a subject of study in information retrieval for a long time, especially in the creation of relevance judgments for test collections. While the criteria by which assessors judge relevance has been intensively studied, little work has investigated the process individual assessors go through to judge the relevance of a document. In this paper, we focus on the process by which relevance is judged, and in particular, the degree of effort a user must expend to judge relevance. By better understanding this effort in isolation, we may provide data which can be used to create better models of search. We present the results of an empirical evaluation of the effort users must exert to judge the relevance of document, investigating the effect of relevance level and document size. Results suggest that relevant documents require more effort to judge when compared to highly relevant and not relevant documents, and that effort increases as document size increases.",
    "title": "Is Relevance Hard Work? Evaluating the Effort of Making Relevant Assessments",
    "authors": [
      {
        "affiliation": "University of Sheffield",
        "location": "Sheffield , UK",
        "name": "Robert Villa",
        "email": "r.villa@sheffield.ac.uk"
      },
      {
        "affiliation": "Glasgow Caledonian University",
        "location": "Glasgow, Scotland, UK",
        "name": "Martin Halvey",
        "email": "Martin.halvey@gcu.ac.uk "
      }
    ]
  },
  "sd109": {
    "abstract": "Filtering a time-ordered corpus for documents that are highly relevant to an entity is a task receiving more and more attention over the years. One application is to reduce the delay between the moment an information about an entity is being first observed and the moment the entity entry in a knowledge base is being updated. Current state-of-the-art approaches are highly supervised and require training examples for each entity monitored. We propose an approach which does not require new training data when processing a new entity. To capture intrinsic characteristics of highly relevant documents our approach relies on three types of features: document centric features, entity profile related features and time features. Evaluated within the framework of the Knowledge Base Acceleration track at TREC 2012, it outperforms current state-of-the-art approaches.",
    "title": "A Weakly-Supervised Detection of Entity Central Documents in a Stream",
    "authors": [
      {
        "affiliation": "University of Avignon CERI-LIA / iSmart",
        "location": "Avignon, France",
        "name": "Ludovic Bonnefoy",
        "email": "ludovic.bonnefoy@alumni.univ-avignon.fr"
      },
      {
        "affiliation": "Aix-Marseille University / LSIS CNRS / Kware",
        "location": "Marseille, France",
        "name": "Vincent Bouvier",
        "email": "vincent.bouvier@lsis.org"
      },
      {
        "affiliation": "Aix-Marseille University / LSIS CNRS",
        "location": "Marseille, France",
        "name": "Patrice Bellot",
        "email": "patrice.bellot@lsis.org"
      }
    ]
  },
  "sd110": {
    "abstract": "User-generated texts such as reviews, comments or discussions are valuable indicators of users' preferences. Unlike previous works which focus on labeled data from user-contributed reviews, we focus here on user comments which are not accompanied by explicit rating labels.  We investigate their utility for a one-class collaborative filtering task such as bookmarking, where only the user actions are given as ground truth.  We propose a sentiment-aware nearest neighbor model (SANN) for multimedia recommendations over TED talks, which makes use of user comments.  The model outperforms significantly, by more than 25% on unseen data, several competitive baselines.",
    "title": "Sentiment Analysis of User Comments for One-Class Collaborative Filtering over TED Talks",
    "authors": [
      {
        "affiliation": "Idiap Research Institute",
        "location": "Martigny, Switzerland",
        "name": "Nikolaos Pappas",
        "email": "nikolaos.pappas@idiap.ch"
      },
      {
        "affiliation": "Idiap Research Institute",
        "location": "Martigny, Switzerland",
        "name": "Andrei Popescu-Belis",
        "email": "andrei.popescu-belis@idiap.ch"
      }
    ]
  },
  "sd111": {
    "abstract": "In this paper we propose a novel framework for modeling the uniqueness of the user preferences for recommendation systems. User uniqueness is determined by learning to what extent the user's item preferences deviate from those of an average user in the system. Based on this framework, we suggest three different recommendation strategies that trade between uniqueness and conformity. Using two real item datasets, we demonstrate the effectiveness of our uniqueness based recommendation framework.",
    "title": "Modeling the Uniqueness of the User Preferences for Recommendation Systems",
    "authors": [
      {
        "affiliation": "IBM Research  Haifa",
        "location": "Haifa, Israel",
        "name": "Haggai Roitman",
        "email": "haggai@il.ibm.com"
      },
      {
        "affiliation": "Yahoo! Research",
        "location": "Haifa, Israel",
        "name": "David Carmel",
        "email": "david.carmel@ymail.com"
      },
      {
        "affiliation": "IBM Research  Haifa",
        "location": "Haifa, Israel",
        "name": "Yosi Mass",
        "email": "yosimass@il.ibm.com"
      },
      {
        "affiliation": "IBM Research  Haifa",
        "location": "Haifa, Israel",
        "name": "Iris Eiron",
        "email": "irise@il.ibm.com"
      }
    ]
  },
  "sd112": {
    "abstract": "The purpose of the Contextual Suggestion track, an evaluation task at the TREC 2012 conference, is to suggest personalized tourist activities to an individual, given a certain location and time. In our content-based approach, we collected initial recommendations using the location context as search query in Google Places. We first ranked the recommendations based on their textual similarity to the user profiles. In order to improve the ranking of popular sights, we combined the initial ranking with rankings based on Google Search, popularity and categories. Finally, we performed filtering based on the temporal context. Overall, our system performed well above average and median, and outperformed the baseline - Google Places only - run.",
    "title": "Recommending personalized touristic sights using Google Places",
    "authors": [
      {
        "affiliation": "TNO and Radboud University Nijmegen",
        "location": "Nijmegen, Netherlands",
        "name": "Maya Sappelli",
        "email": "m.sappelli@cs.ru.nl"
      },
      {
        "affiliation": "Radboud University Nijmegen",
        "location": "Nijmegen, Netherlands",
        "name": "Suzan Verberne",
        "email": "s.verberne@cs.ru.nl"
      },
      {
        "affiliation": "TNO and Radboud University Nijmegen",
        "location": "Nijmegen, Netherlands",
        "name": "Wessel Kraaij",
        "email": "w.kraaij@cs.ru.nl"
      }
    ]
  },
  "sd113": {
    "abstract": "Collaborative filtering techniques rely on aggregated user preference data to make personalized predictions. In many cases, users are reluctant to explicitly express their preferences and many recommender systems have to infer them from implicit user behaviors, such as clicking a link in a webpage or playing a music track. The clicks and the plays are good for indicating the items a user liked (i.e., positive training examples), but the items a user did not like (negative training examples) are not directly observed. Previous approaches either randomly pick negative training samples from unseen items or incorporate some heuristics into the learning model, leading to a biased solution and a prolonged training period. In this paper, we propose to dynamically choose negative training samples from the ranked list produced by the current prediction model and iteratively update our model. The experiments conducted on three large-scale datasets show that our approach not only reduces the training time, but also leads to significant performance gains.",
    "title": "Optimizing Top-N Collaborative Filtering via Dynamic Negative Item Sampling",
    "authors": [
      {
        "affiliation": "University College London",
        "location": "London, UK",
        "name": "Weinan Zhang",
        "email": "w.zhang@cs.ucl.ac.uk"
      },
      {
        "affiliation": "Shanghai Jiao Tong University",
        "location": "Shanghai, China",
        "name": "Tianqi Chen",
        "email": "tqchen@apex.sjtu.edu.cn"
      },
      {
        "affiliation": "University College London",
        "location": "London, UK",
        "name": "Jun Wang",
        "email": "j.wang@cs.ucl.ac.uk"
      },
      {
        "affiliation": "Shanghai Jiao Tong University",
        "location": "Shanghai, China",
        "name": "Yong Yu",
        "email": "yyu@apex.sjtu.edu.cn"
      }
    ]
  },
  "sd114": {
    "abstract": "Information retrieval research has made significant progress in the retrieval of text documents and images. However, relatively little attention has been given to the retrieval of information graphics (non-pictorial images such as bar charts and line graphs) despite their proliferation in popular media such as newspapers and magazines.  Our goal is to build a system for retrieving bar charts and line graphs that reasons about the content of the graphic itself in deciding its relevance to the user query.  This paper presents the first steps toward such a system, with a focus on identifying the category of intended message of potentially relevant bar charts and line graphs. Our learned model achieves accuracy higher than 80\% on a corpus of collected user queries.",
    "title": "Towards Retrieving Relevant Information Graphics",
    "authors": [
      {
        "affiliation": "University of Delaware",
        "location": "Newark, Delaware, USA",
        "name": "Zhuo Li",
        "email": "ivanka@udel.edu"
      },
      {
        "affiliation": "University of Delaware",
        "location": "Newark, Delaware, USA",
        "name": "Matthew Stagitis",
        "email": "mattstag@udel.edu"
      },
      {
        "affiliation": "University of Delaware",
        "location": "Newark, Delaware, USA",
        "name": "Sandra Carberry",
        "email": "carberry@udel.edu"
      },
      {
        "affiliation": "University of Delaware",
        "location": "Newark, Delaware, USA",
        "name": "Kathleen F McCoy",
        "email": "mccoy@udel.edu"
      }
    ]
  },
  "sd115": {
    "abstract": "Recent advances in music retrieval and recommendation algorithms highlight the necessity to follow multimodal approaches in order to transcend limits imposed by methods that solely use audio, web, or collaborative filtering data. In this paper, we propose hybrid music recommendation algorithms that combine information on the music content, the music context, and the user context, in particular, integrating location-aware weighting of similarities. Using state-of-the-art techniques to extract audio features and contextual web features, and a novel standardized data set of music listening activities inferred from microblogs (MusicMicro), we propose several multimodal retrieval functions. The main contributions of this paper are (i) a systematic evaluation of mixture coefficients between state-of-the-art audio features and web features, using the first standardized microblog data set of music listening events for retrieval purposes and (ii) novel geospatial music recommendation approaches using location information of microblog users, and a comprehensive evaluation thereof.",
    "title": "Hybrid Retrieval Approaches to Geospatial Music Recommendation",
    "authors": [
      {
        "affiliation": "Johannes Kepler University",
        "location": "Linz, Austria",
        "name": "Markus Schedl",
        "email": "markus.schedl@jku.at"
      },
      {
        "affiliation": "Austrian Research Institute for Artificial Intelligence",
        "location": "Wien, Austria",
        "name": "Dominik Schnitzer",
        "email": "dominik.schnitzer@ofai.at"
      }
    ]
  },
  "sd116": {
    "abstract": "This short paper proposes a method to classify music video clips uploaded to a video sharing service into music mood categories such as cheerful, wistful, and aggressive. The method leverages viewer comments posted to the music video clips for the music mood classification. It extracts specific features from the comments: (1) adjectives in comments, (2) lengthened words in comments, and (3) comments in chorus sections. Our experimental results classifying 695 video clips into six mood categories  showed that our method outperformed the baseline in terms of macro and micro averaged F-measures. In addition, our method outperformed the existing approaches that utilize lyrics and audio signals of songs.",
    "title": "Leveraging Viewer Comments for Mood Classification of Music Video Clips",
    "authors": [
      {
        "affiliation": "Kyoto University",
        "location": "Kyoto, Japan",
        "name": "Takehiro Yamamoto",
        "email": "tyamamot@dl.kuis.kyoto-u.ac.jp"
      },
      {
        "affiliation": "Meiji University",
        "location": "Tokyo, Japan",
        "name": "Satoshi Nakamura",
        "email": "satoshi@snakamura.org"
      }
    ]
  },
  "sd117": {
    "abstract": "Clinical information retrieval (IR) presents several challenges including terminology mismatch and granularity mismatch. One of the main objectives in clinical IR is to fill the semantic gap among the queries and documents and go beyond keywords matching. To address these issues, in this paper we attempt to use semantic information to improve the performance of clinical IR systems by representing queries in an expressive and meaningful context. To model a query context initially we model and develop query domain ontology. The query domain ontology represents concepts closely related with query concepts. Query context represents concepts extracted from query domain ontology and weighted according to their semantic relatedness to query concept(s). The query context is then exploited in query expansion and patients records re-ranking for improving clinical retrieval performance. We evaluate our approach on the TREC Medical Records dataset. Results show that our proposed approach significantly improves the retrieval performance compare to classic keyword-based IR model.",
    "title": "Exploiting Semantics for Improving Clinical Information Retrieval",
    "authors": [
      {
        "affiliation": "York University",
        "location": "Toronto, ON, Canada",
        "name": "Atanaz Babashzadeh",
        "email": "atanaz@yorku.ca"
      },
      {
        "affiliation": "York University",
        "location": "Toronto, ON, Canada",
        "name": "Jimmy Huang",
        "email": "jhuang@yorku.ca"
      },
      {
        "affiliation": "York University",
        "location": "Toronto, ON, Canada",
        "name": "Mariam Daoud",
        "email": "daoud@yorku.ca"
      }
    ]
  },
  "sd118": {
    "abstract": "We investigate interpreting coordinations (e.g. word sequences connected with coordinating conjunctions such as and and or) as logical disjunctions of terms to generate a set of disjunction-free query variants for information retrieval (IR) queries. In addition, so-called hyphen coordinations are resolved by generating full compound forms and rephrasing the original query, e.g. rice im- and export is transformed into rice import and export. Query variants are then processed separately and retrieval results are merged using a standard data fusion technique. We evaluate the approach on German standard IR benchmarking data. The results show that: i) Our proposed approach to generate compounds from hyphen coordinations produces the correct results for all test topics. ii) Our proposed heuristics to identify coordinations and generate query variants based on shallow natural language processing (NLP) techniques is highly accurate on the topics and does not rely on parsing or part-of-speech tagging.  iii) Using query variants to produce multiple retrieval results and merging the results decreases precision at top ranks. However, in combination with blind relevance feedback (BRF), this approach can show significant improvement over the standard BRF baseline using the original queries.",
    "title": "Interpretation of Coordinations, Compound Generation, and Result Fusion for Query Variants",
    "authors": [
      {
        "affiliation": "Dublin City University, CNGL",
        "location": "Dublin, Ireland",
        "name": "Johannes Leveling",
        "email": "johannes.leveling@computing.dcu.ie"
      }
    ]
  },
  "sd119": {
    "abstract": "Most commercial search engines have a query suggestion feature, which is designed to capture various possible search intents behind the user's original query. However, even though different search intents behind a given query may have been popular at different time periods in the past, existing query suggestion methods neither utilize nor present such information. In this study, we propose Time-aware Structured Query Suggestion (TaSQS) which clusters query suggestions along a timeline so that the user can narrow down his search from a temporal point of view. Moreover, when a suggested query is clicked, TaSQS presents web pages from query-URL bipartite graphs after ranking them according to the click counts within a particular time period. Our experiments using data from a commercial search engine log show that the time-aware clustering and the time-aware document ranking features of TaSQS are both effective.",
    "title": "Time-aware Structured Query Suggestion",
    "authors": [
      {
        "affiliation": "Kobe University",
        "location": "Kobe, Japan",
        "name": "Taiki Miyanishi",
        "email": "miyanishi@ai.cs.kobe-u.ac.jp"
      },
      {
        "affiliation": "Microsoft Research Asia",
        "location": "Beijing, China",
        "name": "Tetsuya Sakai",
        "email": "tetsuyasakai@acm.org"
      }
    ]
  },
  "sd120": {
    "abstract": "Although context-independent word-based approaches remain popular for cross-language information retrieval, many recent studies have shown that integrating insights from modern statistical machine translation systems can lead to substantial improvements in effectiveness. In this paper, we compare flat and hierarchical phrase-based translation models for query translation. Both approaches yield significantly better results than either a token-based or a one-best translation baseline on standard test collections. The choice of model manifests interesting tradeoffs in terms of effectiveness, efficiency, and model compactness.",
    "title": "Flat vs. Hierarchical Phrase-Based Translation Models for Cross-Language Information Retrieval",
    "authors": [
      {
        "affiliation": "University of Maryland",
        "location": "College Park, MD, USA",
        "name": "Ferhan Ture",
        "email": "fture@cs.umd.edu"
      },
      {
        "affiliation": "University of Maryland",
        "location": "College Park, MD, USA",
        "name": "Jimmy Lin",
        "email": "jimmylin@umd.edu"
      }
    ]
  },
  "sd121": {
    "abstract": "A significant portion of Web search is performed in mobile settings. We explore the links between users' queries on mobile devices and their locations and movement, with a focus on interpreting queries about addresses. We find that users tend to have a primary location, likely corresponding to home or workplace, and that a user's location relative to this primary location systematically influences the patterns of address searches. We apply our findings to construct a statistical model that can predict with high accuracy whether a user will be soon observed at an address that had been recently retrieved via search. Such an ability to predict that a user will transition to a location can be harnessed for multiple uses including provision of directions and traffic information, the rendering of competitive advertising, and guiding the opportunistic completion of pending tasks that can be accomplished en route to a target location.",
    "title": "Here and There: Goals, Activities, and Predictions about Location from Geotagged Queries",
    "authors": [
      {
        "affiliation": "Stanford University",
        "location": "Stanford, CA, USA",
        "name": "Robert West",
        "email": "west@cs.stanford.edu"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Ryen White",
        "email": "ryenw@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Eric Horvitz (Microsoft Research)",
        "email": "horvitz@microsoft.com"
      }
    ]
  },
  "sd122": {
    "abstract": "Session search is the Information Retrieval (IR) task that performs document retrieval for an entire session. During a session, users often change queries to explore and investigate the information needs. In this paper, we propose to use query change as a new form of relevance feedback for better session search. Evaluation conducted over TREC 2012 Session Track shows that query change is a highly effective form of feedback as compared with existing relevance feedback methods. The proposed method outperforms the state-of-the-art relevance feedback methods for  the TREC 2012 Session Track by a significant improvement of >25%.",
    "title": "Query Change as Relevance Feedback in Session Search",
    "authors": [
      {
        "affiliation": "Georgetown University",
        "location": "Washington, DC, USA",
        "name": "Sicong Zhang",
        "email": "sz303@georgetown.edu"
      },
      {
        "affiliation": "Georgetown University",
        "location": "Washington, DC, USA",
        "name": "Dongyi Guan ",
        "email": "dg372@georgetown.edu"
      },
      {
        "affiliation": "Georgetown University",
        "location": "Washington, DC, USA",
        "name": "Hui Yang",
        "email": "huiyang@cs.georgetown.edu"
      }
    ]
  },
  "sd123": {
    "abstract": "Logic-based Information Retrieval (IR) models represent the retrieval decision as a logical implication d->q between a document d and a query q, where d and q are logical sentences. However, d->q is a binary decision, we thus need a measure to estimate the degree to which d implies q, denoted P(d->q). In this study, we revisit the Van Rijsbergen's assumptions about: 1- the logical implication `->' is not the material one, and 2- P(d->q) could be estimated by the conditional probability P(q|d). More precisely, we claim that the material implication is an appropriate implication for IR, and also we mathematically prove that replacing P(d->q) by P(q|d) is a correct choice. In order to prove the Van Rijsbergen's assumption, we use the Propositional Logic and the Lattice theory. We also exploit the notion of degree of implication that is proposed by Knuth.",
    "title": "Is Uncertain Logical-Matching Equivalent to Conditional Probability?",
    "authors": [
      {
        "affiliation": "Université de Grenoble, LIG laboratory, MRIM group",
        "location": "Grenoble, France",
        "name": "Karam Abdulahhad",
        "email": "karam.abdulahhad@imag.fr"
      },
      {
        "affiliation": "UPMF-Grenoble 2, LIG laboratory, MRIM group",
        "location": "Grenoble, France",
        "name": "Jean-Pierre Chevallet",
        "email": "jean-pierre.chevallet@imag.fr"
      },
      {
        "affiliation": "UPMF-Grenoble 2, LIG laboratory, MRIM group",
        "location": "Grenoble, France",
        "name": "Catherine Berrut",
        "email": "jean-pierre.chevallet@imag.fr"
      }
    ]
  },
  "sd124": {
    "abstract": "In information retrieval, we are interested in the information that is not only relevant but also novel. In this paper, we study how to boost novelty for biomedical information retrieval through probabilistic latent semantic analysis. We conduct the study based on TREC Genomics Track data. In TREC Genomics Track, each topic is considered to have an arbitrary number of aspects, and the novelty of a piece of information retrieved, called a passage, is assessed based on the amount of new aspects it contains. In particular, the aspect performance of a ranked list is rewarded by the number of new aspects reached at each rank and penalized by the amount of irrelevant passages that are rated higher than the novel ones. Therefore, to improve aspect performance, we should reach as many aspects as possible and as early as possible. In this paper, we make a preliminary study on how probabilistic latent semantic analysis can help capture different aspects of a ranked list, and improve its performance by re-ranking. Experiments indicate that the proposed approach can greatly improve the aspect-level performance over baseline algorithm Okapi BM25.",
    "title": "Boosting Novelty for Biomedical Information Retrieval through Probabilistic Latent Semantic Analysis",
    "authors": [
      {
        "affiliation": "York University",
        "location": "Toronto, ON, Canada",
        "name": "Xiangdong An",
        "email": "xan@cse.yorku.ca"
      },
      {
        "affiliation": "York University",
        "location": "Toronto, ON, Canada",
        "name": "Jimmy Xiangji Huang",
        "email": "jhuang@yorku.ca"
      }
    ]
  },
  "sd125": {
    "abstract": "The complexity of medical terminology raises challenges when searching medical records. For example, `cancer', `tumour', and `neoplasms', which are synonyms, may prevent a traditional search system from retrieving relevant records that contain only synonyms of the query terms. Prior works use bag-of-concepts approaches, to deal with this by representing medical terms sharing the same meanings using concepts from medical resources (e.g. MeSH). The relevance scores are then combined with a traditional bag-of-words representation, when inferring the relevance of medical records. Even though the existing approaches are effective, the predicted retrieval effectiveness of either the bag-of-words or bag-of-concepts representation, which may be used to effectively model the score combination and hence improve retrieval performance, is not taken into account. In this paper, we propose a novel learning framework that models the importance of the bag-of-words and the bag-of-concepts representations, combining their scores on a per-query basis. Our proposed framework leverages retrieval performance predictors, such as the clarity score and AvIDF, calculated on both representations as learning features. We evaluate our proposed framework using the TREC Medical Records track's test collections. As our proposed framework can significantly outperform an existing approach that linearly merges the relevance scores, we conclude that retrieval performance predictors can be effectively leveraged when combining the relevance scores.",
    "title": "Learning to Combine Representations for Medical Records Search",
    "authors": [
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Nut Limsopatham",
        "email": "nutli@dcs.gla.ac.uk"
      },
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Craig Macdonald",
        "email": "Craig.Macdonald@glasgow.ac.uk"
      },
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Iadh Ounis",
        "email": "Iadh.Ounis@glasgow.ac.uk"
      }
    ]
  },
  "sd126": {
    "abstract": "The textual context of an element, structurally, contains traces of evidences. Utilizing this context in scoring is called contextualization. In this study we hypothesize that the context of an XML-element originated from its preceding and following elements in the sequential ordering of a document improves the quality of retrieval. In the tree form of the document's structure, kinship contextualization means, contextualization based on the horizontal and vertical elements in the kinship tree, or elements in closer to a wider structural kinship. We have tested several variants of kinship contextualization and verified notable improvements in comparison with the baseline system and gold standards in the retrieval of focused elements.",
    "title": "Kinship Contextualization: Utilizing the Preceding and Following Structural Elements",
    "authors": [
      {
        "affiliation": "Norwegian University of Science and Technology",
        "location": "Trondheim, Norway",
        "name": "Muhammad A Norozi",
        "email": "mnorozi@idi.ntnu.no"
      },
      {
        "affiliation": "University of Tampere",
        "location": "Tampere, Finland",
        "name": "Paavo Arvola",
        "email": "paavo.arvola@uta.fi"
      }
    ]
  },
  "sd127": {
    "abstract": "In this work we study the cluster hypothesis for entity oriented search (EOS). Specifically, we show that the hypothesis can hold to a substantial extent for several entity similarity measures. We also demonstrate the retrieval effectiveness merits of using clusters of similar entities for EOS.",
    "title": "The Cluster Hypothesis for Entity Oriented Search",
    "authors": [
      {
        "affiliation": "Technion",
        "location": "Haifa, Israel",
        "name": "Hadas Raviv",
        "email": "hadasrv@tx.technion.ac.il"
      },
      {
        "affiliation": "Technion",
        "location": "Haifa, Israel",
        "name": "Oren Kurland",
        "email": "kurland@ie.technion.ac.il"
      },
      {
        "affiliation": "Yahoo! Research",
        "location": "Haifa, Israel",
        "name": "David Carmel",
        "email": "david.carmel@ymail.com"
      }
    ]
  },
  "sd128": {
    "abstract": "In general, centrality-based retrieval models treat all elements of the retrieval space equally, which may reduce their effectiveness. In the specific context of extractive summarization (or important passage retrieval), this means that these models do not take into account that information sources often contain lateral issues, which are hardly as important as the description of the main topic, or are composed by mixtures of topics. We present a new two-stage method that starts by extracting a collection of key phrases that will be used to help centrality-as-relevance retrieval model. We explore several approaches to the integration of the key phrases in the centrality model. The proposed method is evaluated using different datasets that vary in noise (noisy vs clean) and language (Portuguese vs English). Results show that the best variant achieves relative performance improvements of about 31% in clean data and 18% in noisy data.",
    "title": "Self Reinforcement for Important Passage Retrieval",
    "authors": [
      {
        "affiliation": "ISCTE-IUL and INESC-ID Lisboa",
        "location": "Lisboa, Portugal",
        "name": "Ricardo Ribeiro",
        "email": "ricardo.ribeiro@inesc-id.pt"
      },
      {
        "affiliation": "INESC ID Lisboa and CMU",
        "location": "Lisboa, Portugal",
        "name": "Luís Marujo",
        "email": "luis.marujo@inesc-id.pt"
      },
      {
        "affiliation": "IST and INESC-ID Lisboa",
        "location": "Lisboa, Portugal",
        "name": "David Martins de Matos",
        "email": "david.matos@inesc-id.pt"
      },
      {
        "affiliation": "IST and INESC-ID Lisboa",
        "location": "Lisboa, Portugal",
        "name": "João P. Neto",
        "email": "joao.neto@inesc-id.pt"
      },
      {
        "affiliation": "CMU",
        "location": "Pittsburgh, PA, USA",
        "name": "Anatole Gershman (CMU),",
        "email": "anatoleg@cs.cmu.edu"
      },
      {
        "affiliation": "CMU",
        "location": "Pittsburgh, PA, USA",
        "name": "Jaime Carbonell ",
        "email": "jgc@cs.cmu.edu"
      }
    ]
  },
  "sd129": {
    "abstract": "Traditional Web search engines do not use the images in the HTML pages to find relevant documents for a given query. Instead, they typically operate by computing a measure of agreement between the keywords provided by the user and only the text portion of each page. In this paper we study whether the content of the pictures appearing in a Web page can be used to enrich the semantic description of an HTML document and consequently boost the performance of a keyword-based search engine. We present a Web-scalable system that exploits a pure text-based search engine to find an initial set of candidate documents for a given query. Then, the candidate set is reranked using semantic information extracted from the images contained in the pages. The resulting system retains the computational efficiency of traditional text-based search engines with only a small additional storage cost needed to encode the visual information. We test our approach on the TREC 2009 Million Query Track, where we show that our use of visual content yields improvement in accuracies for two distinct text-based search engines, including the system with the best reported performance on this benchmark.",
    "title": "What Can Pictures Tell Us About Web Pages? Improving Document Search using Images",
    "authors": [
      {
        "affiliation": "Tecnalia",
        "location": "Zamudio, Spain ",
        "name": "Sergio Rodriguez-Vaamonde",
        "email": "sergio.rodriguez@tecnalia.com"
      },
      {
        "affiliation": "Dartmouth College",
        "location": "Hanover, NH, USA",
        "name": "Lorenzo Torresani",
        "email": "lorenzo@cs.dartmouth.edu"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Cambridge, UK",
        "name": "Andrew Fitzgibbon",
        "email": "awf@microsoft.com"
      }
    ]
  },
  "sd130": {
    "abstract": "The query-performance prediction (QPP) task is estimating retrieval effectiveness with no relevance judgments. We present a novel probabilistic framework for QPP that gives rise to an important aspect that was not addressed in previous work; namely, the extent to which the query effectively represents the information need for retrieval. Accordingly, we devise a few query-representativeness measures that utilize relevance language models. Experiments show that integrating the most effective measures with state-of-the-art predictors in our framework often yields prediction quality that significantly transcends that of using the predictors alone.",
    "title": "Estimating Query Representativeness for Query-Performance Prediction",
    "authors": [
      {
        "affiliation": "Technion IIT",
        "location": "Haifa, Israel",
        "name": "Mor Sondak",
        "email": "mor@tx.technion.ac.il"
      },
      {
        "affiliation": "Technion IIT",
        "location": "Haifa, Israel",
        "name": "Anna Shtok",
        "email": "annabel@tx.technion.ac.il"
      },
      {
        "affiliation": "Technion IIT",
        "location": "Haifa, Israel",
        "name": "Oren Kurland",
        "email": "kurland@ie.technion.ac.il"
      }
    ]
  },
  "sd131": {
    "abstract": "At present, most major app marketplaces perform ranking and recommendation based on search relevance features or marketplace popularity statistics. For instance, they check similarity between app descriptions and user search queries, or rank-order the apps according to statistics such as number of downloads, user ratings etc. Rankings derived from such signals, important as they are, are insufficient to capture the dynamics of the apps ecosystem. Consider for example the questions: In a particular user context, is app A more likely to be launched than app B? Or does app C provide complementary functionality to app D? Answering these questions requires identifying and analyzing the dependencies between apps in the apps ecosystem. Ranking mechanisms that reflect such interdependences are thus necessary. In this paper we introduce the notion of interoperability ranking for mobile applications. Intuitively, apps with high rank are such apps which are inferred to be somehow important to other apps in the ecosystem. We demonstrate how interoperability ranking can help answer the above questions and also provide the basis for solving several problems which are rapidly attracting the attention of both researchers and the industry, such as building personalized real-time app recommender systems or intelligent mobile agents. We describe a set of methods for computing interoperability ranks and analyze their performance on real data from the Windows Phone app marketplace.",
    "title": "Interoperability Ranking for Mobile Applications",
    "authors": [
      {
        "affiliation": "Microsoft",
        "location": "Sunnyvale, CA, USA",
        "name": "Dragomir Yankov ()",
        "email": "dragoy@microsoft.com"
      },
      {
        "affiliation": "Microsoft",
        "location": "Sunnyvale, CA, USA",
        "name": "Pavel Berkhin",
        "email": "pavelbe@microsoft.com"
      },
      {
        "affiliation": "Microsoft",
        "location": "Sunnyvale, CA, USA",
        "name": "Rajen Subba",
        "email": "rasubba@microsoft.com"
      },
      {
        "affiliation": "",
        "location": "",
        "name": "",
        "email": ""
      }
    ]
  },
  "sd132": {
    "abstract": "We present in this paper a contribution to IR modeling by proposing a new ranking function called SoPRa that considers the social dimension of the Web. This social dimension is any social information that surrounds documents along with the social context of users. Currently, our approach relies on folksonomies for extracting these social contexts, but it can be extended to use any social meta-data, e.g. comments, ratings, tweets, etc. The evaluation performed on our approach shows its benefits for personalized search.",
    "title": "SoPRa: A New Social Personalized Ranking Function for Improving Web Search",
    "authors": [
      {
        "affiliation": "PRiSM Laboratory, Versailles University",
        "location": "Versailles, France",
        "name": "Mohamed Reda Bouadjenek",
        "email": "rbouadjenek@gmail.com"
      },
      {
        "affiliation": "SideTrade, France",
        "location": "Boulogne-Billancourt, France",
        "name": "Hakim Hacid",
        "email": "hakim.hacid@gmail.com"
      },
      {
        "affiliation": "PRiSM Laboratory, Versailles University",
        "location": "Versailles, France",
        "name": "Mokrane Bouzeghoub",
        "email": "mokrane.bouzeghoub@prism.uvsq.fr"
      }
    ]
  },
  "sd133": {
    "abstract": "Browse with either web directories or social bookmarks is an important complementation to search by keywords in  web information retrieval. To improve users' browse experiences and facilitate the web directory construction, in this paper, we propose a novel browse system called Social Web Directory (SWD for short) by integrating web directories and social bookmarks. In SWD, (1) web pages are automatically categorized to a hierarchical structure to be retrieved efficiently, and (2) the popular web pages, hottest tags, and expert users in each category are ranked to help users find information more conveniently. Extensive experimental results demonstrate  the effectiveness of our SWD system.",
    "title": "Browse with a Social Web Directory",
    "authors": [
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Hao Huang",
        "email": "huanghao@comp.nus.edu.sg"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Yunjun Gao",
        "email": "gaoyj@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Lu Chen",
        "email": "chenl@zju.edu.cn"
      },
      {
        "affiliation": "University of Illinois at Urbana-Champaign",
        "location": "Champaign, IL, USA",
        "name": "Rui Li",
        "email": "ruili1@uiuc.edu"
      },
      {
        "affiliation": "Tan Tao University",
        "location": "Long An, Vietnam",
        "name": "Kevin Chiew",
        "email": "kevin.chiew@ttu.edu.vn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Qinming He",
        "email": "hqm@zju.edu.cn"
      }
    ]
  },
  "sd134": {
    "abstract": "In general, centrality-based retrieval models treat all elements of the retrieval space equally, which may reduce their effectiveness. In the specific context of extractive summarization (or important passage retrieval), this means that these models do not take into account that information sources often contain lateral issues, which are hardly as important as the description of the main topic, or are composed by mixtures of topics. We present a new two-stage method that starts by extracting a collection of key phrases that will be used to help centrality-as-relevance retrieval model. We explore several approaches to the integration of the key phrases in the centrality model. The proposed method is evaluated using different datasets that vary in noise (noisy vs clean) and language (Portuguese vs English). Results show that the best variant achieves relative performance improvements of about 31% in clean data and 18% in noisy data.",
    "title": "Self Reinforcement for Important Passage Retrieval",
    "authors": [
      {
        "affiliation": "ISCTE-IUL and INESC-ID Lisboa",
        "location": "Lisboa, Portugal",
        "name": "Ricardo Ribeiro",
        "email": "ricardo.ribeiro@inesc-id.pt"
      },
      {
        "affiliation": "INESC ID Lisboa and CMU",
        "location": "Lisboa, Portugal",
        "name": "Luís Marujo",
        "email": "luis.marujo@inesc-id.pt"
      },
      {
        "affiliation": "IST and INESC-ID Lisboa",
        "location": "Lisboa, Portugal",
        "name": "David Martins de Matos",
        "email": "david.matos@inesc-id.pt"
      },
      {
        "affiliation": "IST and INESC-ID Lisboa",
        "location": "Lisboa, Portugal",
        "name": "João P. Neto",
        "email": "joao.neto@inesc-id.pt"
      },
      {
        "affiliation": "CMU",
        "location": "Pittsburgh, PA, USA",
        "name": "Anatole Gershman (CMU),",
        "email": "anatoleg@cs.cmu.edu"
      },
      {
        "affiliation": "CMU",
        "location": "Pittsburgh, PA, USA",
        "name": "Jaime Carbonell ",
        "email": "jgc@cs.cmu.edu"
      }
    ]
  },
  "sd135": {
    "abstract": "An important aspect of communication in Twitter (and other Social Networks) is message propagation -- people creating posts for others to share. Although there has been work on modelling how tweets in Twitter are propagated (retweeted), an untackled problem has been who will retweet a message. Here we consider the task of finding who will retweet a message posted on Twitter. Within a learning-to-rank framework, we explore a wide range of features, such as retweet history, followers status, followers active time and followers interests. We find that followers who retweeted or mentioned the author's tweets frequently before and have common interests are more likely to be retweeters.",
    "title": "Who Will Retweet Me? Finding Retweeters in Twitter",
    "authors": [
      {
        "affiliation": "National University of Defense Technology",
        "location": "Changsha, China",
        "name": "Zhunchen Luo",
        "email": "zhunchenluo@nudt.edu.cn"
      },
      {
        "affiliation": "The University of Edinburgh",
        "location": "Edinburgh, Scotland, UK",
        "name": "Miles Osborne",
        "email": "miles@inf.ed.ac.uk"
      },
      {
        "affiliation": "National University of Defense Technology",
        "location": "Changsha, China",
        "name": "Jintao Tang",
        "email": "tangjintao@nudt.edu.cn"
      },
      {
        "affiliation": "National University of Defense Technology",
        "location": "Changsha, China",
        "name": "Ting Wang",
        "email": "tingwang@nudt.edu.cn"
      }
    ]
  },
  "sd136": {
    "abstract": "Web search engines cache results of frequent and/or recent queries. Result caching strategies can be evaluated using different metrics, hit rate being the most well-known. Recent works take the processing overhead of queries into account when evaluating the performance of result caching strategies and propose cost-aware caching strategies. In this paper, we propose a financial cost metric that goes one step beyond and takes also the hourly electricity prices into account when computing the cost. We evaluate the most well-known static, dynamic, and hybrid result caching strategies under this new metric. Moreover, we propose a financial-cost-aware version of the well-known LRU strategy and show that it outperforms the original LRU strategy in terms of the financial cost metric.",
    "title": "A Financial Cost Metric for Result Caching",
    "authors": [
      {
        "affiliation": "Bilkent University",
        "location": "Ankara, Turkey",
        "name": "Fethi Burak Sazoglu",
        "email": "fethi.sazoglu@bilkent.edu.tr"
      },
      {
        "affiliation": "Yahoo! Labs",
        "location": "Barcelona, Spain",
        "name": "B. Barla Cambazoglu",
        "email": "barla@yahoo-inc.com"
      },
      {
        "affiliation": "Turgut Ozal University",
        "location": "Ankara, Turkey",
        "name": "Rifat Ozcan",
        "email": "rozcan@turgutozal.edu.tr"
      },
      {
        "affiliation": "Middle East Technical University",
        "location": "Ankara, Turkey",
        "name": "Ismail Sengor Altingovde",
        "email": "altingovde@ceng.metu.edu.tr"
      },
      {
        "affiliation": "Bilkent University",
        "location": "Ankara, Turkey",
        "name": "Özgür Ulusoy ",
        "email": "oulusoy@cs.bilkent.edu.tr"
      }
    ]
  },
  "sd137": {
    "abstract": "In this paper, we propose Latent Dirichlet Allocation (LDA) based document classification algorithm which does not require any labeled dataset. In our algorithm, we construct a topic model using LDA, assign one topic to one of the class labels, aggregate all the same class label topics into a single topic using the aggregation property of the Dirichlet distribution and then automatically assign a class label to each unlabeled document depending on its closeness to one of the aggregated topics. We present an extension to our algorithm based on the combination of Expectation-Maximization (EM) algorithm and a naive Bayes classifier. We show effectiveness of our algorithm on three real world datasets.",
    "title": "Document Classification by Topic Labeling",
    "authors": [
      {
        "affiliation": "Tata Consultancy Services",
        "location": "Pune, India",
        "name": "Swapnil Hingmire",
        "email": "swapnil.hingmire@tcs.com"
      },
      {
        "affiliation": "Tata Consultancy Services",
        "location": "Pune, India",
        "name": "Sandeep Chougule",
        "email": "sandeep.chougule@tcs.com"
      },
      {
        "affiliation": "Tata Consultancy Services",
        "location": "Pune, India",
        "name": "Girish Palshikar ",
        "email": "gk.palshikar@tcs.com"
      },
      {
        "affiliation": "IIT Madras",
        "location": "Chennai, India",
        "name": "Sutanu Chakrabori",
        "email": "sutanuc@cse.iitm.ac.in"
      }
    ]
  },
  "sd138": {
    "abstract": "Mining the latent topics from web search data and capturing their spatiotemporal patterns have many applications in information retrieval. As web search is heavily influenced by the spatial and temporal factors, the latent topics usually demonstrate a variety of spatiotemporal patterns. In the face of the diversity of these patterns, existing models are increasingly ineffective, since they capture only one dimension of the spatiotemporal patterns (either the spatial or temporal dimension) or simply assume that there exists only one kind of spatiotemporal patterns. Such oversimplification risks distorting the latent data structure and hindering the downstream usage of the discovered topics. In this paper, we introduce the Spatiotemporal Search Topic Model (SSTM) to discover the latent topics from web search data with capturing their diverse spatiotemporal patterns simultaneously. The SSTM can flexibly support diverse spatiotemporal patterns and seamlessly integrate the unique features in web search such as query words, URLs, timestamps and search sessions. The SSTM is demonstrated as an effective exploratory tool for large-scale web search data and it performs superiorly in quantitative comparisons to several state-of-the-art topic models.",
    "title": "Mining Web Search Topics With Diverse Spatiotemporal Patterns",
    "authors": [
      {
        "affiliation": "Hong Kong University of Science and Technolog",
        "location": "Hong Kong, Hong Kong",
        "name": "Di Jiang",
        "email": "dijiang@cse.ust.hk"
      },
      {
        "affiliation": "Hong Kong University of Science and Technolog",
        "location": "Hong Kong, Hong Kong",
        "name": "Wilfred Ng",
        "email": "wilfred@cse.ust.hk"
      }
    ]
  },
  "sd139": {
    "abstract": "Automatic term extraction (ATE) aims at extracting domain-specific terms from a corpus of a certain domain. Termhood is one essential measure for judging whether a phrase is a term. Previous researches on termhood mainly depend on the word frequency information. In this paper, we propose to compute termhood based on semantic representation of words. A novel topic model, namely i-SWB, is developed to map the domain corpus into a latent semantic space, which is composed of some general topics, a background topic and a documents-specific topic. Experiments on four domains demonstrate that our approach outperforms the state-of-the-art ATE approaches. ",
    "title": "A Novel Topic Model for Automatic Term Extraction",
    "authors": [
      {
        "affiliation": "Instititute of Computational Linguistics, Peking University",
        "location": "Beijing, China",
        "name": "Sujian Li",
        "email": "lisujian@pku.edu.cn"
      },
      {
        "affiliation": "Instititute of Computational Linguistics, Peking University",
        "location": "Beijing, China",
        "name": "Jiwei Li",
        "email": "bdlijiwei@163.com"
      },
      {
        "affiliation": "Instititute of Computational Linguistics, Peking University",
        "location": "Beijing, China",
        "name": "Tao Song",
        "email": "stao_86@163.com"
      },
      {
        "affiliation": "The Hong Kong Polytechnic University, Shenzhen Research Institute",
        "location": "Shenzhen, China",
        "name": "Wenjie Li",
        "email": "cswjli@comp.polyu.edu.hk"
      },
      {
        "affiliation": "Instititute of Computational Linguistics, Peking University",
        "location": "Beijing, China",
        "name": "Baobao Chang",
        "email": "chbb@pku.edu.cn"
      }
    ]
  },
  "sd140": {
    "abstract": "Twitter, or the world of 140 characters poses serious challenges to the efficacy of topic models on short, messy text. While topic models such as Latent Dirichlet Allocation (LDA) have a long history of successful application to news articles and academic abstracts, they are often less coherent when applied to microblog content like Twitter. In this paper, we investigate methods to improve topics learned from Twitter content without modifying the basic machinery of LDA; we achieve this through various pooling schemes that aggregate tweets in a data preprocessing step for LDA. We empirically establish that a novel method of tweet pooling by hashtags leads to a vast improvement in a variety of measures for topic coherence across three diverse Twitter datasets in comparison to an unmodified LDA baseline and a variety of pooling schemes. An additional contribution of automatic hashtag labeling further improves on the hashtag pooling results for a subset of metrics. Overall, these two novel schemes lead to significantly improved LDA topic models on Twitter content.",
    "title": "Improving LDA Topic Models for Microblogs via Tweet Pooling and Automatic Labeling",
    "authors": [
      {
        "affiliation": "BITS Pilani",
        "location": "Pilani, India",
        "name": "Rishabh Mehrotra",
        "email": "erishabh@gmail.com"
      },
      {
        "affiliation": "NICTA & ANU",
        "location": "Canberra, Australia",
        "name": "Scott Sanner",
        "email": "Scott.Sanner@nicta.com.au "
      },
      {
        "affiliation": "NICTA & ANU",
        "location": "Canberra, Australia",
        "name": "Wray Buntine",
        "email": "Wray.Buntine@nicta.com.au"
      },
      {
        "affiliation": "ANU & NICTA",
        "location": "Canberra, Australia",
        "name": "Lexing Xie",
        "email": "lexing.xie@anu.edu.au"
      }
    ]
  },
  "sd141": {
    "abstract": "Many on-line services allow users to describe their opinions about a product or a service through a review. In order to help other users to find out the major opinion about a given topic, without the effort to read several reviews, multi-document summarisation is required. This research proposes an approach for extractive summarisation, supporting different scoring techniques, such as cosine similarity or divergence, as a method for finding representative sentences. The main contribution of this paper is the definition of an algorithm for sentence removal, developed to maximise the score between the summary and the original document. Instead of ranking the sentences and selecting the most important ones, the algorithm iteratively removes unimportant sentences until a desired compression rate is reached. Experimental results show that variations of the sentence removal algorithm provide good performance.",
    "title": "Extractive Summarisation via Sentence Removal: Condensing Relevant Sentences into a Short Summary",
    "authors": [
      {
        "affiliation": "Queen Mary University of London",
        "location": "London, UK",
        "name": "Marco Bonzanini",
        "email": "marcob@eecs.qmul.ac.uk"
      },
      {
        "affiliation": "Queen Mary University of London",
        "location": "London, UK",
        "name": "Miguel Martinez-Alvarez",
        "email": "miguel@eecs.qmul.ac.uk"
      },
      {
        "affiliation": "Queen Mary University of London",
        "location": "London, UK",
        "name": " Thomas Roelleke",
        "email": "thor@eecs.qmul.ac.uk"
      }
    ]
  },
  "sd142": {
    "abstract": "Search systems use context to effectively satisfy a users information need as expressed by a query. Tasks are important factors in determining user context during search and many studies have been conducted that identify tasks and task stages through users interaction behavior with search systems. The type of interaction available to users, however, depends on the type of search interface features available. Queries are the most pervasive input from users to express their information need regardless of the input method, e.g., typing keywords or clicking facets. Instead of characterizing interaction behavior in terms of interface specific components, we propose to characterize users search behavior in terms of two types of query modification: (i) direct modification, which refers to reformulations of queries; and (ii) indirect modification, which refers to user operations on additional input components provided by various search interfaces. We investigate the utility of characterizing task stages through direct and indirect query reformulations in a case study and find that it is possible to effectively differentiate subsequent stages of the search task. We found that describing user interaction behavior in such a generic form allowed us to relate user actions to search task stages independent from the specific search interface deployed. The next step will then be to validate this idea in a setting with a wider palette of search tasks and tools.",
    "title": "Characterizing Stages of a Multi-session Complex Search Task through Direct and Indirect Query Modifications",
    "authors": [
      {
        "affiliation": "Centrum Wiskunde & Informatica",
        "location": "Amsterdam, Netherlands",
        "name": "Jiyin He",
        "email": "j.he@cwi.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Marc Bron",
        "email": "m.m.bron@uva.nl"
      },
      {
        "affiliation": "Centrum Wiskunde & Informatica",
        "location": "Amsterdam, Netherlands",
        "name": "Arjen P. de Vries ",
        "email": "arjen.de.vries@cwi.nl"
      }
    ]
  },
  "sd143": {
    "abstract": "Internet search engines typically compute a relevance score for webpages given the query terms, and then rank the pages by decreasing relevance scores. The popular search engines do not, however, present the relevance scores that were computed during this process. We suggest that these relevance scores may contain information that can help users make conscious decisions. In this paper we evaluate in a user study how users react to the display of such scores. The results indicate that users understand graphical displays of relevance, and make decisions based on these scores. Our results suggest that in the context of exploratory search, relevance scores may cause users to explore more search results.",
    "title": "Displaying Relevance Scores for Search Results",
    "authors": [
      {
        "affiliation": "Ben Gurion University",
        "location": "Beer Sheva, Israel",
        "name": "Guy Shani",
        "email": "shanigu@bgu.ac.il"
      },
      {
        "affiliation": "Ben Gurion University",
        "location": "Beer Sheva, Israel",
        "name": "Noam Tractinsky",
        "email": "noamt@bgu.ac.il"
      }
    ]
  },
  "sd144": {
    "abstract": "With the ever-increasing speed of content turnover on the web, it is particularly important to understand the patterns that pages' popularity follows. This paper focuses on the dynamical part of the web, i.e. pages that have a limited lifespan and experience a short popularity outburst within it. We classify these pages into five patterns based on how quickly they gain popularity and how quickly they lose it. We study the properties of pages that belong to each pattern and determine content topics that contain disproportionately high fractions of particular patterns. These developments are utilized to create an algorithm that approximates with reasonable accuracy the expected popularity pattern of a web page based on its URL and, if available, prior knowledge about its domain's topics.",
    "title": "Studying Page Life Patterns in Dynamical Web",
    "authors": [
      {
        "affiliation": "Yandex, LLC",
        "location": "Moscow, Russia",
        "name": "Alexey Tikhonov",
        "email": "altsoph@yandex-team.ru"
      },
      {
        "affiliation": "Yandex, LLC",
        "location": "Moscow, Russia",
        "name": "Ivan Bogatyy",
        "email": "loken17@yandex-team.ru"
      },
      {
        "affiliation": "Yandex, LLC",
        "location": "Moscow, Russia",
        "name": "Pavel Burangulov",
        "email": "burangulov@yandex-team.ru"
      },
      {
        "affiliation": "Yandex, LLC",
        "location": "Moscow, Russia",
        "name": "Liudmila Ostroumova",
        "email": "ostroumova-la@yandex-team.ru"
      },
      {
        "affiliation": "Yandex, LLC",
        "location": "Moscow, Russia",
        "name": "Vitaliy Koshelev",
        "email": "vakoshelev@yandex-team.ru"
      },
      {
        "affiliation": "Yandex, LLC",
        "location": "Moscow, Russia",
        "name": "Gleb Gusev",
        "email": "gleb57@yandex-team.ru"
      }
    ]
  },
  "r2a01": {
    "abstract": "Aggregated search interfaces provide users with an overview of results from various sources.  Two general types of display exist: tabbed, with access to each source in a separate tab, and blended, which combines multiple sources into a single result page.  Multi-session search tasks, e.g., a research project, consist of multiple stages, each with its own sub-tasks.  Several factors involved in multi-session search tasks have been found to influence user search behavior.  We investigate whether user preference for source presentation changes during a multi-session search task. The dynamic nature of multi-session search tasks makes the design of a controlled experiment a non-trivial challenge.  We adopt a methodology based on triangulation and conduct two types of observational study: a longitudinal study and a laboratory study.  In the longitudinal study we follow the use of tabbed and blended displays by 25 students during a project. We find that while a tabbed display is used more than a blended display, subjects repeatedly switch between displays during the project. Use of the tabbed display is motivated by a need to zoom in on a specific source, while the blended display is used to explore available material across sources whenever the information need changes. In a laboratory study 44 students completed a multi-session search task composed of three sub-tasks, the first with a tabbed display, the second and third with blended displays. The tasks were manipulated by either providing three task about the same topic or about three different topics. We find that a stable information need over multiple sub-tasks negatively influences perceived usability of the blended displays, while we do not find an influence when the information need changes.",
    "title": "Aggregated Search Interface Preferences in Multi-Session Search Tasks",
    "authors": [
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Marc Bron",
        "email": "m.m.bron@uva.nl"
      },
      {
        "affiliation": "Utrecht University",
        "location": "Utrecht, Netherlands",
        "name": "Jasmijn van Gorp",
        "email": "j.vangorp@uu.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Frank Nack",
        "email": "nack@uva.nl"
      },
      {
        "affiliation": "Netherlands Institute for Sound & Vision",
        "location": "Hilversum, Netherlands",
        "name": "Lotte Belice Baltussen",
        "email": "lbbaltussen@beeldengeluid.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Maarten de Rijke ",
        "email": "derijke@uva.nl"
      }
    ]
  },
  "r2a02": {
    "abstract": "The effectiveness of various behavioural signals for implicit relevance feedback models has been exhaustively studied. Despite the advantages of such techniques for a real time information retrieval system, most of the behavioural signals are noisy and therefore not reliable enough to be employed. Among many, a combination of dwell time and task information has been shown to be effective for relevance judgement prediction. However, the task information might not be available to the system at all times. Thus, there is a need for other sources of information which can be used as a substitute for task information. Recently, affective and physiological signals have shown promise as a potential source of information for relevance judgement prediction. However, their accuracy is not high enough to be applicable on their own. This paper investigates whether affective and physiological signals can be used as a complementary source of information for behavioural signals (i.e. dwell time) to create a reliable signal for relevance judgement prediction. Using a video retrieval system as a use case, we study and compare the effectiveness of the affective and physiological signals on their own, as well as in combination with behavioural signals for the relevance judgment prediction task across four different search intentions: seeking information, re-finding a particular information object, and two different entertainment intentions (i.e. entertainment by adjusting arousal level, and entertainment by adjusting mood). Our experimental results show that the effectiveness of studied signals varies across different search intentions, and when affective and physiological signals are combined with dwell time, a significant improvement can be achieved. Overall, these findings will help to implement better search engines in the future.",
    "title": "An Effective Implicit Relevance Feedback Technique Using Affective, Physiological and Behavioural Features",
    "authors": [
      {
        "affiliation": "The University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Yashar Moshfeghi",
        "email": "Yashar.Moshfeghi@glasgow.ac.uk"
      },
      {
        "affiliation": "The University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Joemon M. Jose",
        "email": "Joemon.Jose@glasgow.ac.uk"
      }
    ]
  },
  "r2a03": {
    "abstract": "Voice search offers users with a new search experience: instead of typing, users can vocalize their search queries. However, due to voice input errors (such as speech recognition errors and improper system interruptions), users need to frequently reformulate queries to handle the incorrectly recognized queries. We conducted user experiments with native English speakers on their query reformulation behaviors in voice search and found that users often reformulate queries with both lexical and phonetic changes to previous queries. In this paper, we first characterize and analyze typical voice input errors in voice search and users corresponding reformulation strategies. Then, we evaluate the impacts of typical voice input errors on users search progress and the effectiveness of different reformulation strategies on handling these errors. This study provides a clearer picture on how to further improve current voice search systems.",
    "title": "How Do Users Respond to Voice Input Errors? Lexical and Phonetic Query Reformulation in Voice Search",
    "authors": [
      {
        "affiliation": "University of Pittsburgh",
        "location": "Pittsburgh, PA, USA",
        "name": "Jiepu Jiang",
        "email": "jiepu.jiang@gmail.com"
      },
      {
        "affiliation": "University of Pittsburgh",
        "location": "Pittsburgh, PA, USA",
        "name": "Wei Jeng",
        "email": "wej9@pitt.edu"
      },
      {
        "affiliation": "University of Pittsburgh",
        "location": "Pittsburgh, PA, USA",
        "name": "Daqing He",
        "email": "dah44@pitt.edu"
      }
    ]
  },
  "r2a04": {
    "abstract": "Fine-grained search interactions in the desktop setting, such as mouse cursor movements and scrolling, have been shown valuable for understanding user intent, attention, and their preferences for Web search results. As web search on smart phones and tablets becomes increasingly popular, previously validated desktop interaction models have to be adapted for the available touch interactions such as pinching and swiping, and for the different device form factors. In this paper, we present, to our knowledge, the first in-depth study of modeling interactions on touch-enabled device for improving Web search ranking. In particular, we evaluate a variety of touch interactions on a smart phone as implicit relevance feedback, and compare them with the corresponding fine-grained interactions on a desktop computer with mouse and keyboard as the primary input devices. Our experiments are based on a dataset collected from two user studies with 56 users in total, using a specially instrumented version of a popular mobile browser to capture the interaction data. We report a detailed analysis of the similarities and differences of fine-grained search interactions between the desktop and the smart phone modalities, and identify novel patterns of touch interactions indicative of result relevance. Finally, we demonstrate significant improvements to search ranking quality by mining touch interaction data.",
    "title": "Mining Touch Interaction Data on Mobile Devices to Predict Web Search Result Relevance",
    "authors": [
      {
        "affiliation": "Microsoft",
        "location": "Redmond, WA, USA",
        "name": "Qi Guo",
        "email": "qiguo@microsoft.com"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Haojian Jin",
        "email": "haojian.jin@emory.edu"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Dmitry Lagun",
        "email": "dlagun@emory.edu"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Shuai Yuan",
        "email": "syuan3@emory.edu"
      },
      {
        "affiliation": "Emory University",
        "location": "Atlanta, GA, USA",
        "name": "Eugene Agichtein",
        "email": "eugene@mathcs.emory.edu"
      }
    ]
  },
  "r2b01": {
    "abstract": "In this paper, we recast static index pruning as a model induction problem under the framework of Kullback's principle of minimum cross-entropy.  We show that static index pruning has an approximate analytical solution in the form of convex integer program.  Further analysis on computation feasibility suggests that one of its surrogate model can be solved efficiently.  This result has led to the rediscovery of \emph{uniform pruning}, a simple yet powerful pruning method proposed in 2001 and later easily ignored by many of us.  To empirically verify this result, we conducted experiments under a new design in which prune ratio is strictly controlled.  Our result on standard ad-hoc retrieval benchmarks has confirmed that uniform pruning is robust to high prune ratio and its performance is currently state of the art.",
    "title": "An Information-Theoretic Account of Static Index Pruning",
    "authors": [
      {
        "affiliation": "National Taiwan University",
        "location": "Taipei, Taiwan",
        "name": "Ruey-Cheng Chen",
        "email": "rueycheng@turing.csie.ntu.edu.tw"
      },
      {
        "affiliation": "University of Massachusetts",
        "location": "Amherst, MA, USA",
        "name": "Chia-Jung Lee",
        "email": "cjlee@cs.umass.edu"
      }
    ]
  },
  "r2b02": {
    "abstract": "Text search engines are a fundamental tool nowadays. Their efficiency relies on a popular and simple data structure: the inverted indexes. Currently, inverted indexes can be represented very efficiently using index compression schemes. Recent investigations also study how an optimized document ordering can be used to assign document identifiers (docIDs) to the document database. This yields important improvements in index compression and query processing time. In this paper we follow this line of research, yet from a different perspective. We propose a docID reassignment method that allows one to focus on a given subset of inverted lists to improve their performance. We then use run-length encoding to compress these lists (as many consecutive 1s are generated). We show that by using this approach, not only the performance of the particular subset of inverted lists is improved, but also that of the whole inverted index. Our experimental results  indicate a reduction of about 10\% in the space usage of the whole index (just regarding docIDs), and up to 30\% if we regard only the particular subset of list on which the \docid~reassignment was focused. Also, decompression speed is up to 1.22 times faster if the runs must be explicitly decompressed and up to 4.58 times faster if implicit decompression of runs is allowed. Finally, we also improve the Document-at-a-Time query processing time of AND queries (by up to 12%), WAND queries (by up to 23%) and full (non-ranked) OR queries (by up to 86%).",
    "title": "Document Identifier Reassignment and Run-Length-Compressed Inverted Indexes for Improved Search Performance",
    "authors": [
      {
        "affiliation": "niversidad Técnica Federico Santa María & Yahoo! Labs Santiago",
        "location": "Santiago, Chile",
        "name": "Diego Arroyuelo",
        "email": "darroyue@inf.utfsm.cl"
      },
      {
        "affiliation": "University of Chile & Yahoo! Labs Santiago",
        "location": "Santiago, Chile",
        "name": "enén González",
        "email": "sgonzale@dcc.uchile.cl"
      },
      {
        "affiliation": "University of Santiago & Yahoo! Labs Santiago",
        "location": "Santiago, Chile",
        "name": "Mauricio Oyarzún",
        "email": "mauricio.silvaoy@usach.cl"
      },
      {
        "affiliation": "Yahoo! Labs Santiago",
        "location": "Santiago, Chile",
        "name": "Victor Sepulveda",
        "email": "vsepulve@dcc.uchile.cl"
      }
    ]
  },
  "r2b03": {
    "abstract": "In this paper we present two new algorithms designed to reduce the overall time required to process top-k queries. These algorithms are based on the document-at-a-time approach and modify the best baseline we found in the literature, Blockmax WAND (BMW), to take advantage of a two-tiered index, in which the first tier is a small index containing only the higher impact entries of each inverted list.  This small index is used to pre-process the query before accessing a larger index in the second tier, resulting in considerable speeding up  the whole process. The first algorithm we propose, named BMW-CS, achieves higher performance, but may result in small changes in the top results provided in the final ranking. The second algorithm, named BMW-t, preserves the top results and, while slower than BMW-CS, it  is  faster than BMW. In our experiments, BMW-CS was more than 40 times faster than BMW when computing top 10 results, and, while it does not guarantee preserving the top results, it preserved all ranking results evaluated at this level.",
    "title": "Fast Document-at-a-time Query Processing using Two-tier Indexes",
    "authors": [
      {
        "affiliation": "Federal University of Amazonas",
        "location": "Manaus, Brazil",
        "name": "Cristian Rossi",
        "email": "cristian.infor@gmail.com"
      },
      {
        "affiliation": "Federal University of Amazonas",
        "location": "Manaus, Brazil",
        "name": "Edleno S Moura",
        "email": "edleno@icomp.ufam.edu.br"
      },
      {
        "affiliation": "Federal University of Amazonas",
        "location": "Manaus, Brazil",
        "name": "Andre L Carvalho",
        "email": "andre@icomp.ufam.edu.br"
      },
      {
        "affiliation": "Federal University of Amazonas",
        "location": "Manaus, Brazil",
        "name": "Altigran S Silva",
        "email": "alti@icomp.ufam.edu.br"
      }
    ]
  },
  "r2b04": {
    "abstract": "We introduce a new representation of the inverted index that performs faster ranked unions and intersections while using less space. Our index is based on the treap data structure, which allows us to intersect/merge the document identifiers while simultaneously thresholding by frequency, instead of the costlier two-step classical processing methods. To achieve compression we represent the treap topology using compact data structures. Further, the treap invariants allow us to elegantly encode differentially both document identifiers and frequencies. Results show that our index uses about 20% less space, and performs queries up to three times faster, than state-of-the-art compact representations. ",
    "title": "Faster and Smaller Inverted Indices with Treaps",
    "authors": [
      {
        "affiliation": "University of Chile",
        "location": "Santiago, Chile",
        "name": "Roberto Konow",
        "email": "rkonow@dcc.uchile.cl"
      },
      {
        "affiliation": "University of Chile",
        "location": "Santiago, Chile",
        "name": "Gonzalo Navarro",
        "email": "gnavarro@dcc.uchile.cl"
      },
      {
        "affiliation": "University of Waterloo",
        "location": "Waterloo, ON, Canada",
        "name": " Charles L.A. Clarke",
        "email": "claclark@plg.uwaterloo.ca"
      },
      {
        "affiliation": "University of Waterloo",
        "location": "Waterloo, ON, Canada",
        "name": "Alejandro López-Ortíz",
        "email": "alopez-o@uwaterloo.ca"
      }
    ]
  },
  "r2c01": {
    "abstract": "We present a new unsupervised topic discovery model for a collection of text documents. In contrast to the majority of the state-of-the-art topic models, our model does not break the document's structure such as paragraphs and sentences. In addition, it preserves word order in the document. As a result, it can generate two levels of topics of different granularity, namely, segment-topics and word-topics. In addition, it can generate n-gram words in each topic. We also develop an approximate inference scheme using Gibbs sampling method. We conduct extensive experiments using publicly available data from different collections and show that our model improves the quality of several text mining tasks such as the ability to support fine grained topics with n-gram words in the correlation graph, the ability to segment a document into topically coherent sections, document classification, and document likelihood estimation.",
    "title": "An Unsupervised Topic Segmentation Model Incorporating Word Order",
    "authors": [
      {
        "affiliation": "The Chinese University of Hong Kong",
        "location": "Hong Kong, Hong Kong",
        "name": "Shoaib Jameel",
        "email": "msjameel@se.cuhk.edu.hk"
      },
      {
        "affiliation": "The Chinese University of Hong Kong",
        "location": "Hong Kong, Hong Kong",
        "name": "Wai Lam",
        "email": "wlam@se.cuhk.edu.hk"
      }
    ]
  },
  "r2c02": {
    "abstract": "It is an important research problem to design efficient and effective solutions for large scale similarity search. One popular strategy is to represent data examples as compact binary codes through semantic hashing, which has produced promising results with fast search speed and low storage cost. Many existing semantic hashing methods generate binary codes for documents by modeling document relationships based on similarity in a keyword feature space. Two major limitations in existing methods are: (1) Tag information is often associated with documents in many real world applications, but has not been fully exploited yet; (2) The similarity in keyword feature space does not fully reflect semantic relationships that go beyond keyword matching. This paper proposes a novel hashing approach, Semantic Hashing using Tags and Topic Modeling (SHTTM), to incorporate both the tag information and the similarity information from probabilistic topic modeling. In particular, a unified framework is designed for ensuring hashing codes to be consistent with tag information by a formal latent factor model and preserving the document topic/semantic similarity that goes beyond keyword matching. An iterative coordinate descent procedure is proposed for learning the optimal hashing codes. An extensive set of empirical studies on four different datasets has been conducted to demonstrate the advantages of the proposed SHTTM approach against several other state-of-the-art semantic hashing techniques. Furthermore, experimental results indicate that the modeling of tag information and utilizing topic modeling are beneficial for improving the effectiveness of hashing separately, while the combination of these two techniques in the unified framework obtains even better results.",
    "title": "Semantic Hashing using Tags and Topic Modeling",
    "authors": [
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA",
        "name": "Qifan Wang",
        "email": "wang868@purdue.edu"
      },
      {
        "affiliation": "Facebook Incorporation",
        "location": "Menlo Park, CA, USA",
        "name": "Dan Zhang",
        "email": "danzhang@fb.com"
      },
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA",
        "name": "Luo Si",
        "email": "lsi@purdue.edu"
      }
    ]
  },
  "r2c03": {
    "abstract": "Topic models are used to group words in a text dataset into a set of relevant topics. Unfortunately, when a few words frequently appear in a dataset, the topic groups identified by topic models become noisy because these frequent words repeatedly appear in irrelevant topic groups. This noise has not been a serious problem in a text dataset because the frequent words (e.g., the and is) do not have much meaning and have been simply removed before a topic model analysis. However, in a social network dataset we are interested in, they correspond to popular persons (e.g., Barack Obama and Justin Bieber) and cannot be simply removed because most people are interested in them. To solve this popularity problem, we explicitly model the popularity of nodes (words) in topic models. For this purpose, we first introduce a notion of a popularity component and propose topic model extensions  that effectively accommodate the popularity component. We evaluate the effectiveness of our models with a real-world Twitter dataset. Our proposed models achieve significantly lower perplexity (i.e., better prediction power) compared to the state-of-the-art baselines. In addition to the popularity problem caused by the nodes with high incoming edge degree, we also investigate the effect of the outgoing edge degree with another topic model extensions. We show that considering outgoing edge degree does not help much in achieving lower perplexity.",
    "title": "Incorporating Popularity in Topic Models for Social Network Analysis",
    "authors": [
      {
        "affiliation": "UCLA",
        "location": "Los Angeles, CA, USA",
        "name": "Youngchul Cha",
        "email": "youngcha@cs.ucla.edu"
      },
      {
        "affiliation": "UCLA",
        "location": "Los Angeles, CA, USA",
        "name": "Bin Bi",
        "email": "bbi@cs.ucla.edu"
      },
      {
        "affiliation": "UCLA",
        "location": "Los Angeles, CA, USA",
        "name": "Chu-Cheng Hsieh",
        "email": "chucheng@cs.ucla.edu"
      },
      {
        "affiliation": "UCLA",
        "location": "Los Angeles, CA, USA",
        "name": "Junghoo Cho",
        "email": "cho@cs.ucla.edu"
      }
    ]
  },
  "r2c04": {
    "abstract": "User generated contents (UGCs) carry a huge amount of high quality information. However, the information overload and diversity of UGC sources limit their potential uses. In this research, we propose a framework to organize information from multiple UGC sources by a topic hierarchy which is automatically generated and updated using the UGCs. We explore the unique characteristics of UGCs like blogs, cQAs, microblogs, etc., and introduce a novel scheme to combine them. We also propose a graph-based method to enable incremental update of the generated topic hierarchy. Using the hierarchy, users can easily obtain a comprehensive, in-depth and up-to-date picture of their topics of interests. The experiment results demonstrate how information from multiple heterogeneous sources improves the resultant topic hierarchies. It also shows that the proposed method achieves better F1 scores in hierarchy generation as compared to the state-of-the-art methods.",
    "title": "Topic Hierarchy Construction for the Organization of Multi-source User Generated Contents",
    "authors": [
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": "Xingwei Zhu",
        "email": "etzhu192@hotmail.com"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Zhao-Yan Ming",
        "email": "mingzhaoyan@nus.edu.sg"
      },
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": " Xiaoyan Zhu",
        "email": "zxy-dcs@tsinghua.edu.cn"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Tat-Seng Chua",
        "email": "chuats@nus.edu.sg"
      }
    ]
  },
  "k02": {
    "abstract": "In this talk we present a perspective across multiple industry problems, including safety and security, medical, Web, social and mobile media, and motivate the need for large-scale analysis and retrieval of multimedia data.  We describe a multi-layer architecture that incorporates capabilities for audio-visual feature extraction, machine learning and semantic modeling and provides a powerful framework for learning and classifying contents of multimedia data.  We discuss the role semantic ontologies for representing audio-visual concepts and relationships, which are essential for training semantic classifiers.  We discuss the importance of using faceted classification schemes in particular for organizing multimedia semantic concepts in order to achieve effective learning and retrieval.  We also show how training and scoring of multimedia semantics can be implemented on big data distributed computing platforms to address both massive-scale analysis and low-latency processing.  We describe multiple efforts at IBM on image and video analysis and retrieval, including IBM Multimedia Analysis and Retrieval System (IMARS), and show recent results for semantic-based classification and retrieval.  We conclude with future directions for improving analysis of multimedia through interactive and curriculum-based techniques for multimedia semantics-based learning and retrieval.",
    "title": "Keynote 2: Riding the Multimedia Big Data Wave",
    "authors": [
      {
        "affiliation": "IBM T. J. Watson",
        "location": "Yorktown Heights, NY, USA",
        "name": "John R. Smith",
        "email": "jsmith@us.ibm.com"
      }
    ]
  },
  "r3a01": {
    "abstract": "Exploratory search is a complex, iterative information seeking activity that involves running multiple queries and finding and examining many documents. We designed a query preview control that visualizes the distribution of newly-retrieved and re-retrieved documents prior to running the query. When evaluating the preview control with a control condition, we found effects on both peoples information seeking behavior and improved retrieval performance. People spent more time formulating a query and were more likely to explore search results more deeply, retrieved a more diverse set of documents, and found more different relevant documents when using the preview.",
    "title": "Looking Ahead: Query Preview in Exploratory Search",
    "authors": [
      {
        "affiliation": "FX Palo Alto Laboratory, Inc.",
        "location": "Palo Alto, CA, USA",
        "name": "Pernilla Qvardfordt",
        "email": "pernilla@fxpal.com"
      },
      {
        "affiliation": "FX Palo Alto Laboratory, Inc.",
        "location": "Palo Alto, CA, USA",
        "name": "Gene Golovchinsky",
        "email": "gene@fxpal.com"
      },
      {
        "affiliation": "FX Palo Alto Laboratory, Inc.",
        "location": "Palo Alto, CA, USA",
        "name": "Tony Dunnigan",
        "email": "tonyd@fxpal.com"
      },
      {
        "affiliation": "Harvard University",
        "location": "Cambridge, MA, USA",
        "name": "Elena Agapie",
        "email": "eagapie@seas.harvard.edu"
      }
    ]
  },
  "r3a02": {
    "abstract": "News reporting has seen a shift toward fast-paced online reporting in new sources such as social media. Web Search engines that support a news vertical have historically relied upon articles published by major newswire providers when serving news-related queries. In this paper, we investigate to what extent real-time content from newswire, blogs, Twitter and Wikipedia sources are useful to return to the user in the current fast-paced news search setting. In particular, we perform a detailed user study using the emerging medium of crowdsourcing to determine when and where integrating news-related content from these various sources can better serve the user's news need. We sampled approximately 300 news-related search queries using Google Trends and Bitly data in real-time for two time periods. For these queries, we have crowdsourced workers compare Web search rankings for each, with similar rankings integrating real-time news content from sources such as Twitter or the blogosphere. Our results show that users exhibited a preference for rankings integrating newswire articles for only half of our queries, indicating that relying solely on newswire providers for news-related content is now insufficient. Moreover, our results show that users preferred rankings that integrate tweets more often than those that integrate newswire articles, showing the potential of using social media to better serve news queries. ",
    "title": "News Vertical Search: When and What to Display to Users",
    "authors": [
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Richard McCreadie",
        "email": "richard.mccreadie@glasgow.ac.uk"
      },
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Craig Macdonald",
        "email": "craig.macdonald@glasgow.ac.uk"
      },
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Iadh Ounis",
        "email": "iadh.ounis@glasgow.ac.uk"
      }
    ]
  },
  "r3a03": {
    "abstract": "Web search engines frequently show the same documents repeatedly for different queries within the same search session, in essence forgetting when the same documents were already shown to users. Depending on previous user interaction with the repeated results, and the details of the session, we show that sometimes the repeated results should be promoted, while some other times they should be demoted. Analysing search logs from two different commercial search engines, we find that results are repeated in about 40% of multi-query search sessions, and that users engage differently with repeats than with results shown for the first time. We demonstrate how statistics about result repetition within search sessions can be incorporated into ranking for personalizing search results. Our results on query logs of two large-scale commercial search engines suggest that we successfully promote documents that are more likely to be clicked by the user in the future while maintaining performance over standard measures of non-personalized relevance.",
    "title": "Fighting Search Engine Amnesia: Reranking Repeated Results",
    "authors": [
      {
        "affiliation": "Microsoft",
        "location": "Cambridge, UK",
        "name": "Milad Shokouhi",
        "email": "milads@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Ryen White",
        "email": "ryenw@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Paul Bennett ",
        "email": "pauben@microsoft.com"
      },
      {
        "affiliation": "Microsoft",
        "location": "Cambridge, UK",
        "name": "Filip Radlinski",
        "email": "filiprad@microsoft.com"
      }
    ]
  },
  "r3a04": {
    "abstract": "Search engines receive queries with a broad range of different search intents. However, they do not perform equally well for all queries. Understanding where search engines perform poorly is critical for improving their performance. In this paper, we present a method for automatically identifying poorly-performing query groups where a search engine may not meet searcher needs. This allows us to create coherent query clusters that help system design-ers generate actionable insights about necessary changes and helps learning-to-rank algorithms better learn relevance signals via spe-cialized rankers. The result is a framework capable of estimating dissatisfaction from Web search logs and learning to improve per-formance for dissatisfied queries. Through experimentation, we show that our method yields good quality groups that align with established retrieval performance metrics. We also show that we can significantly improve retrieval effectiveness via specialized rankers, and that coherent grouping of underperforming queries generated by our method is important in improving each group.",
    "title": "Toward Self-Correcting Search Engines: Using Underperforming Queries to Improve Search",
    "authors": [
      {
        "affiliation": "Microsoft Research Redmond",
        "location": "Redmond, WA, USA",
        "name": "Ahmed Hassan",
        "email": "hassanam@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research Redmond",
        "location": "Redmond, WA, USA",
        "name": "Ryen White",
        "email": "ryenw@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research Redmond",
        "location": "Redmond, WA, USA",
        "name": "Yi-Min Wang",
        "email": "ymwang@microsoft.com"
      }
    ]
  },
  "r3b01": {
    "abstract": "As a tremendous number of mobile applications (apps) are readily available, users have difficulty in identifying apps that are relevant to their interests. Recommender systems that depend on previous user ratings (i.e., collaborative filtering, or CF) can address this problem for apps that have sufficient ratings from past users. But for apps that are newly released, CF does not have any user ratings to base recommendations on, which leads to the cold-start problem. In this paper, we describe a method that accounts for nascent information culled from Twitter to provide relevant recommendation in such cold-start situations. We use Twitter handles to access an app's Twitter account and extract the IDs of their Twitter-followers. We create pseudo-documents that contain the IDs of Twitter users interested in an app and then apply latent Dirichlet allocation to generate latent groups. At test time, a target user seeking recommendations is mapped to these latent groups. By using the transitive relationship of latent groups to apps, we estimate the probability of the user liking the app. We show that by incorporating information from Twitter, our approach overcomes the difficulty of cold-start app recommendation and significantly outperforms other state-of-the-art recommendation techniques by up to 33%.",
    "title": "Addressing Cold-Start in App Recommendation: Latent User Models Constructed from Twitter Followers",
    "authors": [
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Jovian Lin",
        "email": "jovian.lin@gmail.com"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Kazunari Sugiyama",
        "email": "sugiyama@comp.nus.edu.sg"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Min-Yen Kan",
        "email": "kanmy@comp.nus.edu.sg"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Tat-Seng Chua",
        "email": "chuats@comp.nus.edu.sg"
      }
    ]
  },
  "r3b02": {
    "abstract": "The interest of users in handheld devices is strongly related to their location. Therefore, the user location is important, as a user context, for news article recommendation in a mobile environment. This paper proposes a novel news article recommendation that reflects the geographical context of the user. For this purpose, we propose the Explicit Localized Semantic Analysis (ELSA), an ESA-based topical representation of documents. Every location has its own geographical topics, which can be captured from the geo-tagged documents related to the location. Thus, not only news articles but locations are also represented as topic vectors. The main advantage of ELSA is that it stresses only the topics that are relevant to a given location, whereas all topics are equally important in ESA. As a result, geographical topics have different importance according to the user location in ELSA, even if they come from the same article. Another advantage of ELSA is that it allows a simple comparison of the user location and news articles, because it projects both locations and articles onto an identical space composed of Wikipedia topics. In the evaluation of ELSA with the New York Times corpus, it outperformed two simple baselines of Bag-Of-Words and LDA as well as two ESA-based methods. Rt10 of ELSA was improved up to 46.25% over other methods, and its NDCG@k was always higher than those of the others regardless of k.",
    "title": "A Location-Based News Article Recommendation with Explicit Localized Semantic Analysis",
    "authors": [
      {
        "affiliation": "Kyungpook National University",
        "location": "Daegu, South Korea",
        "name": " Jeong-Woo Son",
        "email": "jwson@sejong.knu.ac.kr"
      },
      {
        "affiliation": "Kyungpook National University",
        "location": "Daegu, South Korea",
        "name": "A-Yeong Kim",
        "email": "aykim@sejong.knu.ac.kr"
      },
      {
        "affiliation": "Kyungpook National University",
        "location": "Daegu, South Korea",
        "name": "Seong-Bae Park",
        "email": "sbpark@sejong.knu.ac.kr"
      }
    ]
  },
  "r3b03": {
    "abstract": "Most of existing e-commerce recommender systems aim to recommend the right product to a user, based on whether the user is likely to purchase or like a product. On the other hand, the effectiveness of recommendations also depends on the time of the recommendation. Let us take a user who just purchased a laptop as an example. She may purchase a replacement battery in 2 years (assuming that the laptop's original battery often fails to work around that time) and purchase a new laptop in another 2 years. In this case, it is not a good idea to recommend a new laptop or a replacement battery right after the user purchased the new laptop. It could hurt the user's satisfaction of the recommender system if she receives a potentially right product recommendation at the wrong time. We argue that a system should not only recommend the most relevant item, but also recommend at the right time. This paper studies the new problem: how to recommend the right product at the right time? We adapt the proportional hazards modeling approach in survival analysis to the recommendation research field and propose a new \textit{opportunity model} to explicitly incorporate time in an e-commerce recommender system. The new model estimates the joint probability of a user making a follow-up purchase of a particular product at a particular time. This joint purchase probability can be leveraged by recommender systems in various scenarios, including the zero-query pull-based recommendation scenario (e.g.  recommendation on an e-commerce web site) and a proactive push-based promotion scenario (e.g. email or text message based marketing). We evaluate the opportunity modeling approach with multiple metrics. Experimental results on a data collected by a real-world e-commerce website(shop.com) show that it can predict a user's follow-up purchase behavior at a particular time with descent accuracy. In addition, the opportunity model significantly improves the conversion rate in pull-based systems and the user satisfaction/utility in push-based systems.",
    "title": "Opportunity Model for E-commerce Recommendation: Right Product; Right Time",
    "authors": [
      {
        "affiliation": "University of California, Santa Cruz",
        "location": "Santa Cruz, CA, USA",
        "name": "Jian Wang",
        "email": "wheaty1202@gmail.com"
      },
      {
        "affiliation": "University of California, Santa Cruz",
        "location": "Santa Cruz, CA, USA",
        "name": "Yi Zhang",
        "email": "yiz@soe.ucsc.edu"
      }
    ]
  },
  "r3b04": {
    "abstract": "Collaborative Filtering-based recommendation algorithms have achieved widespread success on the Web, but little work has been performed to investigate appropriate user-item relationship structures of rating matrices. This paper presents a novel and general collaborative filtering framework based on (Approximate) Bordered Block Diagonal Form structure of user-item rating matrices. We show formally that matrices in (A)BBDF structures correspond to community detection on the corresponding bipartite graphs, and they reveal relationships among users and items intuitionally in recommendation tasks. By this framework, general and special interests of a user are distinguished, which helps to improve prediction accuracy in collaborative filtering tasks. Experimental results on four real-world datasets, including the Yahoo! Music dataset, which is currently the largest, show that the proposed framework helps many traditional collaborative filtering algorithms, such as User-based, Item-based, SVD and NMF approaches, to make more accurate rating predictions. Moreover, by leveraging smaller and denser submatrices to make predictions, this framework contributes to the scalability of recommender systems.",
    "title": "Improve Collaborative Filtering Through Bordered Block Diagonal Form Matrices",
    "authors": [
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Yongfeng Zhang",
        "email": "zhangyf07@gmail.com"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Min Zhang",
        "email": "z-m@tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Yiqun Liu",
        "email": "yiqunliu@tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua University",
        "location": "Beijing, China",
        "name": "Shaoping Ma",
        "email": "msp@tsinghua.edu.cn"
      }
    ]
  },
  "r3c01": {
    "abstract": "Search engines train and apply a single ranking model across all users, but searchers' information needs are diverse and cover a broad range of topics. Hence, a single user-independent ranking model is insufficient to satisfy different users' result preferences. Conventional personalization methods learn separate models of user interests and use those to re-rank the results from the generic model. Those methods require significant user history information to learn user preferences, have low coverage in the case of memory-based methods that learn direct associations between query-URL pairs, and have limited opportunity to markedly affect the ranking given that they only re-order top-ranked items. In this paper, we propose a general ranking model adaptation framework for personalized search. Using a given user-independent ranking model trained offline and limited number of adaptation queries from individual users, the framework quickly learns to apply a series of linear transformations, e.g., scaling and shifting, over the parameters of the given global ranking model such that the adapted model can better fit each individual user's search preferences. Extensive experimentation based on a large set of search logs from a major commercial Web search engine confirms the effectiveness of the proposed method compared to several state-of-the-art ranking model adaptation methods.",
    "title": "Personalized Ranking Model Adaptation for Web Search",
    "authors": [
      {
        "affiliation": "University of Illinois at Urbana-Champaign",
        "location": "Urbana, IL, USA",
        "name": "Hongning Wang",
        "email": "wang296@illinois.edu"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Xiaodong He",
        "email": "xiaohe@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Ming-Wei Chang",
        "email": "minchang@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Yang Song",
        "email": "yangsong@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Ryen W. White",
        "email": "ryenw@microsoft.com"
      },
      {
        "affiliation": "Microsoft Bing",
        "location": "Bellevue, WA, USA",
        "name": "Wei Chu",
        "email": "wechu@microsoft.com"
      }
    ]
  },
  "r3c02": {
    "abstract": "An important challenge in cluster-based document retrieval is ranking document clusters by their relevance to the query. We present a novel cluster ranking approach that utilizes Markov Random Fields (MRFs). MRFs enable the integration of various types of cluster-relevance evidence; e.g., the query-similarity values of the clusters documents and query-independent measures of the cluster. We use our method to re-rank an initially retrieved document list by ranking clusters that are created from the documents most highly ranked in the list. The resultant retrieval effectiveness is substantially better than that of the initial list for several lists that are produced by effective retrieval methods. Furthermore, our cluster ranking approach significantly outperforms state-of- the-art cluster ranking methods. We also show that our method can be used to improve the performance of (state-of- the-art) results-diversification methods.",
    "title": "Ranking Document Clusters Using Markov Random Fields",
    "authors": [
      {
        "affiliation": "Technion - Israel Institute of Technology",
        "location": "Haifa, Israel",
        "name": "Fiana Raiber",
        "email": "fiana@tx.technion.ac.il"
      },
      {
        "affiliation": "Technion - Israel Institute of Technology",
        "location": "Haifa, Israel",
        "name": "Oren Kurland",
        "email": "kurland@ie.technion.ac.il"
      }
    ]
  },
  "r3c03": {
    "abstract": "Term  weighting  schemes  are  central  to the  study  of  information retrieval  systems. This  article proposes  a  novel TF-IDF  term weighting  scheme that  employs two  different within  document term frequency  normalizations to capture two different aspects of  term saliency. One  component of the term frequency is  effective for  shortqueries,  while  the  other  performs  better on  long  queries.   The final weight is then measured  by taking a weighted combination of these  components, which is  determined  on the basis of the length of the corresponding query. Experiments conducted on  a large number of  TREC news  and  web collections demonstrate that the proposed scheme  almost always  outperforms  five state of  the art  retrieval models   with    remarkable   significance  and consistency.   The experimental  results  also  show  that the  proposed model achieves significantly better precision than the existing models.",
    "title": "A Novel TF-IDF Weighting Scheme for Effective Ranking",
    "authors": [
      {
        "affiliation": "Indian Statistical Institute",
        "location": "Kolkata, India",
        "name": "Jiaul H. Paik",
        "email": "jia.paik@gmail.com"
      }
    ]
  },
  "r3c04": {
    "abstract": "Many documents with mathematical content are published on the Web, but conventional search engines that rely on keyword search only cannot fully exploit their mathematical information. In particular, keyword search is insufficient when expressions in a document are not annotated with natural keywords or the user cannot describe her query with keywords. Retrieving documents by querying their mathematical content directly is very appealing in various domains such as education, digital libraries, engineering, patent documents, medical sciences, etc. Capturing the relevance of mathematical expressions also greatly enhances document classification in such domains. Unlike text retrieval, where keywords carry enough semantics to distinguish text documents and rank them, math symbols do not contain much semantic information on their own. In fact, mathematical expressions typically consist of few alphabetical symbols organized in rather complex structures. Hence, the structure of an expression, which describes the way such symbols are combined, should also be considered. Unfortunately, there is no standard testbed with which to evaluate the effectiveness of a mathematics retrieval algorithm. In this paper we study the fundamental and challenging problems in mathematics retrieval, that is how to capture the relevance of mathematical expressions, how to query them, and how to evaluate the results. We describe various search paradigms and propose retrieval systems accordingly. We discuss the benefits and drawbacks of each approach, and further compare them through an extensive empirical study.",
    "title": "Retrieving Documents with Mathematical Content",
    "authors": [
      {
        "affiliation": "University of Waterloo",
        "location": "Waterloo, ON, Canada",
        "name": "Shahab Kamali",
        "email": "skamali@cs.uwaterloo.ca"
      },
      {
        "affiliation": "University of Waterloo",
        "location": "Waterloo, ON, Canada",
        "name": "Frank Wm. Tompa",
        "email": "fwtompa@cs.uwaterloo.ca"
      }
    ]
  },


"sd201": {

		 "abstract": "High quality relevance judgments are essential for the evaluation of information retrieval systems. Traditional methods of collecting relevance judgments are based on collecting binary or graded nominal judgments, but such judgments are limited by factors such as inter-assessor disagreement and the arbitrariness of grades. Previous research has shown that it is easier for assessors to make pairwise preference judgments. However, unless the preferences collected are largely transitive, it is not clear how to combine them in order to obtain document relevance scores. Another difficulty is that the number of pairs that need to be assessed is quadratic in the number of documents. In this work, we consider the problem of inferring document relevance scores from pairwise preference judgments by analogy to tournaments using the Elo rating system. We show how to combine a linear number of pairwise preference judgments from multiple assessors to compute relevance scores for every document.",

		"title": "A Document Rating System for Preference Judgements",

		 "authors": [

		           {

		            	 "affiliation": "Northeastern University",

		           	 "location": "Boston Massachusetts USA",

		            	 "name": "Maryam Bashir",

		           	 "email": "maryam@ccs.neu.edu"

		            },

		           {

		            	 "affiliation": "Northeastern University",

		           	 "location": "Boston Massachusetts US",

		            	 "name": "Jesse Anderton",

		           	 "email": "jesse@ccs.neu.edu"

		            },

		           {

		            	 "affiliation": "Northeastern University",

		           	 "location": "Boston Massachusetts US",

		            	 "name": "Jie Wu",

		           	 "email": "evawujie@ccs.neu.edu"

		            },

		           {

		            	 "affiliation": "Northeastern University",

		           	 "location": "Boston Massachusetts US",

		            	 "name": "Peter B. Golbus",

		           	 "email": "pgolbus@ccs.neu.edu"

		            },

		           {

		            	 "affiliation": "Northeastern University",

		           	 "location": "Boston Massachusetts US",

		            	 "name": "Virgil Pavlu",

		           	 "email": "vip@ccs.neu.edu"

		            },

		           {

		            	 "affiliation": "Northeastern University",

		           	 "location": "Boston Massachusetts US",

		            	 "name": "Javed A. Aslam",

		           	 "email": "jaa@ccs.neu.edu"

		            }

		           ]

	 },

	 "sd202": {

		 "abstract": "Evaluation of information retrieval (IR) systems has recently been exploring the use of preference judgments over two search result lists. Unlike the traditional method of collecting relevance labels per single result, this method allows to consider the interaction between search results as part of the judging criteria. For example, one result list may be preferred over another if it has a more diverse set of relevant results, covering a wider range of user intents. In this paper, we investigate how assessors determine their preference for one list of results over another with the aim to understand the role of various relevance dimensions in preference-based evaluation. We run a series of experiments and collect preference judgments over different relevance dimensions in side-by-side comparisons of two search result lists, as well as relevance judgments for the individual documents. Our analysis of the collected judgments reveals that preference judgments combine multiple dimensions of relevance that go beyond the traditional notion of relevance centered on topicality. Measuring performance based on single document judgments and NDCG aligns well with topicality based preferences, but shows misalignment with judges' overall preferences, largely due to the diversity dimension. As a judging method, dimensional preference judging is found to lead to improved judgment quality.",

		"title": "Relevance Dimensions in Preference-based IR Evaluation",

		 "authors": [

		           {

		            	 "affiliation": "Microsoft",

		           	 "location": "Bellevue WA USA ",

		            	 "name": "Jinyoung Kim",

		           	 "email": "jink@microsoft.com"

		            },

		           {

		            	 "affiliation": "Microsoft Research",

		           	 "location": "Cambridge  United Kingdom ",

		            	 "name": "Gabriella Kazai",

		           	 "email": "a-gabkaz@microsoft.com"

		            },

		           {

		            	 "affiliation": "Microsoft ",

		           	 "location": "Bellevue WA USA ",

		            	 "name": "Imed Zitouni",

		           	 "email": "izitouni@microsoft.com"

		            }

		           ]

	 },

	 "sd203": {

		 "abstract": "Previous papers in ad hoc IR reported that scoring functions should satisfy a set of heuristic retrieval constraints, providing a mathematical justification for the normalizations historically applied to the term frequency (TF). In this paper, we propose a further level of abstraction, claiming that the successive normalizations are carried out through composition. Thus we introduce a principled framework that fully explains BM25 as a variant of TF-IDF with an inverse order of function composition. Our experiments over standard datasets indicate that the respective orders of composition chosen in the original papers for both TF-IDF and BM25 are the most effective ones. Moreover, since the order is different between the two models, they also demonstrated that the order is instrumental in the design of weighting models. In fact, while considering more complex scoring functions such as BM25+, we discovered a novel weighting model in terms of order of composition that consistently outperforms all the rest. Our contribution here is twofold: we provide a unifying mathematical framework for IR and a novel scoring function discovered using this framework.",

		"title": "Composition of TF Normalizations: New Insights on Scoring Functions for Ad Hoc IR",

		 "authors": [

		           {

		            	 "affiliation": "École Polytechnique",

		           	 "location": "Palaiseau  France LIX",

		            	 "name": "François Rousseau",

		           	 "email": "rousseau@lix.polytechnique.fr"

		           },

		            {

		            	 "affiliation": "Athens University of Economics and Business & École Polytechnique & Télécom ParisTech",

		           	 "location": "Athens  Greece Department of Informatics",

		            	 "name": "Michalis Vazirgiannis",

		           	 "email": "mvazirg@aueb.gr"

		            }

		           ]

	 },

	 "sd204": {

		 "abstract": "To construct a diversified search test collection, a set of possible subtopics (or intents) needs to be determined for each topic, in one way or another, and per-intent relevance assessments need to be obtained. In the TREC Web Track Diversity Task, subtopics are manually developed at NIST, based on results of automatic click log analysis; in the NTCIR INTENT Task, intents are determined by manually clustering subtopics strings returned by participating systems. In this study, we address the following research question: Does the choice of intents for a test collection affect relative performances of diversified search systems? To this end, we use the TREC 2012 Web Track Diversity Task data and the NTCIR-10 INTENT-2 Task data, which share a set of 50 topics but have different intent sets. Our initial results suggest that the choice of intents may affect relative performances, and that this choice may be far more important than how many intents are selected for each topic.",

		"title": "The Impact of Intent Selection on Diversified Search Evaluation",

		 "authors": [

		           {

		            	 "affiliation": "MSRA",

		           	 "location": "Beijing  China",

		            	 "name": "Tetsuya Sakai",

		           	 "email": "tetsuyasakai@acm.org"

		            },

		           {

		            	 "affiliation": "MSRA",

		           	 "location": "Beijing  China",

		            	 "name": "Zhicheng Dou",

		           	 "email": "zhichdou@microsoft.com"

		            },

		           {

		            	 "affiliation": "University of Waterloo",

		           	 "location": "Waterloo  Canada",

		            	 "name": "Charles L.A. Clarke",

		           	 "email": "tetsuyasakai@acm.org"

		            }

		           ]

	 },

	 "sd205": {

		 "abstract": "Previous research has suggested the permutation test as the theoretically optimal statistical significance test for IR evaluation, and advocated for the discontinuation of the Wilcoxon and sign tests. We present a large-scale study comprising nearly 60 million system comparisons showing that in practice the bootstrap, t-test and Wilcoxon test outperform the permutation test under different optimality criteria. We also show that actual error rates seem to be lower than the theoretically expected 5%, further confirming that we may actually be underestimating significance.",

		"title": "A Comparison of the Optimality of Statistical Significance Tests for Information Retrieval Evaluation",

		 "authors": [

		           {

		            	 "affiliation": "University Carlos III of Madrid",

		           	 "location": "Leganés  Spain",

		            	 "name": "Julián Urbano",

		           	 "email": "jurbano@inf.uc3m.es"

		            },

		           {

		            	 "affiliation": "University Carlos III of Madrid",

		           	 "location": "Leganés  Spain",

		            	 "name": "Mónica Marrero",

		           	 "email": "mmarrero@inf.uc3m.es"

		            },

		           {

		            	 "affiliation": "Technical University of Madrid",

		           	 "location": "Madrid  Spain",

		            	 "name": "Diego Martín",

		           	 "email": "dmartin@dit.upm.es"

		            }

		           ]

	 },

	 "sd206": {

		 "abstract": "Text classifiers are frequently used for high-yield retrieval from large corpora, such as in e-discovery.  The classifier is trained by annotating example documents for relevance.  These examples may, however, be assessed by people other than those whose conception of relevance is authoritative.  In this paper, we examine the impact that disagreement between actual and authoritative assessor has upon classifier effectiveness, when evaluated against the authoritative conception. We find that using alternative assessors leads to a significant decrease in binary classification quality, though less so ranking quality.  A ranking consumer would have to go on average 25% deeper in the ranking produced by alternative-assessor training to achieve the same yield as for authoritative-assessor training.",

		"title": "Assessor Disagreement and Text Classifier Accuracy",

		 "authors": [

		           {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA College of Information Studies",

		            	 "name": "William Webber",

		           	 "email": "wew@umd.edu"

		            },

		           {

		            	 "affiliation": "Catalyst Repository Systems",

		           	 "location": "Denver CO USA ",

		            	 "name": "Jeremy Pickens",

		           	 "email": "jpickens@catalystsecure.com"

		           }

		            ]

	 },

	 "sd207": {

		"abstract": "It is common to develop and validate classifiers through a process of repeated testing, with nested training and/or test sets of increasing size. We demonstrate in this paper that such repeated testing leads to biased estimates of classifier effectiveness. Experiments on a range of text classification tasks under three sequential testing frameworks show all three lead to optimistic estimates of effectiveness. We calculate empirical adjustments to unbias estimates on our data set, and identify directions for research that could lead to general techniques for avoiding bias while reducing labeling costs.",

		"title": "Sequential Testing in Classifier Evaluation Yields Biased Estimates of Effectiveness",

		 "authors": [

		           {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA College of Information Studies",

		            	 "name": "William Webber",

		           	 "email": "wew@umd.edu"

		            },

		           {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA Department of Computer Science",

		            	 "name": "Mossaab Bagdouri",

		           	 "email": "mossaab@umd.edu"

		            },

		           {

		            	 "affiliation": "David D. Lewis Consulting",

		           	 "location": "Chicago IL USA ",

		            	 "name": "David D. Lewis",

		           	 "email": "sigir2013pap@DavidDLewis.com"

		            },

		           {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA College of Information Studies and Institute for Advanced Computer Studies",

		           	 "name": "Douglas W. Oard",

		            	 "email": "oard@umd.edu"

		           }

		            ]

	 },

	 "sd208": {

		"abstract": "Retrievability provides a different way to evaluate an Information Retrieval (IR) system as it focuses on how easily documents can be found. It is intrinsically related to retrieval performance because a document needs to be retrieved before it can be judged relevant. In this paper, we undertake an empirical investigation into the relationship between the retrievability of documents, the retrieval bias imposed by a retrieval system, and the retrieval performance, across different amounts of document length normalization. To this end, two standard IR models are used on three TREC test collections to show that there is a useful and practical link between retrievability and performance. Our findings show that minimizing the bias across the document collection leads to good performance (though not the best performance possible). We also show that past a certain amount of document length normalization the retrieval bias increases, and the retrieval performance significantly and rapidly decreases. These findings suggest that the relationship between retrievability and effectiveness may offer a way to automatically tune systems.",

		"title": "Relating Retrievability, Performance and Length",

		 "authors": [

 		           {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  Scotland Uk School of Computing Science",

		            	 "name": "Colin Wilkie",

		           	 "email": "Colin.Wilkie@glasgow.ac.uk"

		           },

		            {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  Scotland Uk School of Computing Science",

		            	 "name": "Leif Azzopardi",

		           	 "email": "Leif.Azzopardi@glasgow.ac.uk"

		           }

		            ]

	 },

	 "sd209": {

		"abstract": "Cumulative citation recommendation refers to the task of filtering a time-ordered corpus for documents that are highly relevant to a predefined set of entities.  This task has been introduced at the TREC Knowledge Base Acceleration track in 2012, where two main families of approaches emerged: classification and ranking.  In this paper we perform an experimental comparison of these two strategies using supervised learning with a rich feature set.  Our main finding is that ranking outperforms classification on all evaluation settings and metrics.  Our analysis also reveals that a ranking-based approach has more potential for future improvements.",

		"title": "Cumulative Citation Recommendation: Classification vs. Ranking",

		 "authors": [

		           {

		            	 "affiliation": "University of Stavanger",

		           	 "location": "Stavanger  Norway ",

		            	 "name": "Krisztian Balog",

		           	 "email": "krisztian.balog@uis.no"

		            },

		           {

		            	 "affiliation": "Norwegian University of Science and Technology",

		           	 "location": "Trondheim  Norway ",

		            	 "name": "Heri Ramampiaro",

		           	 "email": "heri.ramampiaro@idi.ntnu.no"

		           }

		            ]

	 },

	 "sd210": {

		"abstract": "Personalized recommender systems aim to push only the relevant items and information directly to the users without requiring them to browse through millions of web resources. The challenge of these systems is to achieve a high user acceptance rate on their recommendations. In this paper, we aim to increase the user acceptance of recommendations by providing more intuitive tag-based explanations of why the items are recommended. Tags are used as intermediary entities that not only relate target users to the recommended items but also understand users' intents. Our system also allows tag-based online relevance feedback. Experiment results on the Movielens dataset show that the proposed approach is able to increase the acceptance rate of recommendations and improve user satisfaction.",

		"title": "Tagcloud-based Explanation with Feedback for Recommender Systems",

		 "authors": [

		           {

		            	 "affiliation": "National University of Singapore",

		           	 "location": "Singapore  Singapore School of Computing",

		            	 "name": "Wei Chen",

		           	 "email": "weichen@comp.nus.edu.sg"

 		           },

		            {

		            	 "affiliation": "National University of Singapore",

		           	 "location": "Singapore  Singapore School of Computing",

		            	 "name": "Wynne Hsu",

		           	 "email": "whsu@comp.nus.edu.sg"

		            },

		           {

		            	 "affiliation": "National University of Singapore",

		           	 "location": "Singapore  Singapore School of Computing",

		            	 "name": "Mong Li Lee",

		           	 "email": "leeml@comp.nus.edu.sg"

		            }

		           ]

	 },

	 "sd211": {

		 "abstract": "Recommender system has become an effective tool for information filtering, which usually provides the most useful items to users by a top-k ranking list. Traditional recommendation techniques such as Nearest Neighbors (NN) and Matrix Factorization (MF) have been widely used in real recommender systems. However, neither approaches can well accomplish recommendation task since that: (1) most NN methods leverage the neighbor's behaviors for prediction, which may suffer the severe data sparsity problem; (2) MF methods are less sensitive to sparsity, but neighbors' influences on latent factors are not fully explored, since the latent factors are often used independently. To overcome the above problems, we propose a new framework for recommender systems, called collaborative factorization. It expresses the user as the combination of his own factors and those of the neighbors', called collaborative latent factors, and a ranking loss is then utilized for optimization. The advantage of our approach is that it can both enjoy the merits of NN and MF methods. In this paper, we take the logistic loss in RankNet and the likelihood loss in ListMLE as examples, and the corresponding collaborative factorization methods are called CoF-Net and CoF-MLE. Our experimental results on three benchmark datasets show that they are more effective than several state-of-the-art recommendation methods.",

		"title": "Collaborative Factorization for Recommender Systems",

		 "authors": [

		           {

		            	 "affiliation": "Peking University",

		           	 "location": "Beijing  China",

		            	 "name": "Chaosheng Fan",

		           	 "email": "fcs@pku.edu.cn"

		            },

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Yanyan Lan",

		           	 "email": "lanyanyan@ict.ac.cn"

		            },

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Jiafeng Guo",

		           	 "email": "guojiafeng@ict.ac.cn"

		            },

		           {

		            	 "affiliation": "Peking University",

		           	 "location": "Beijing  China",

		            	 "name": "Zuoquan Lin",

		           	 "email": "lz@pku.edu.cn"

		            },

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Xueqi Cheng",

		           	 "email": "cxq@ict.ac.cn"

		            }

		           ]

	 },

	 "sd212": {

		 "abstract": "Distributed events are collections of events taking place within a small area over the same time period and relating to a single topic. There are often a large number of events on offer and the times in which they can be visited are heavily constrained, therefore the task of choosing events to visit and in which order can be very difficult. In this work we investigate how visitors can be assisted by means of a recommender system via 2 large-scale naturalistic studies (n=860 and n=1047). We show that a recommender system can influence users to select events that result in tighter and more compact routes, thus allowing users to spend less time travelling and more time visiting events.",

		"title": "RecSys for Distributed Events: Investigating the influence of recommendations on visitor plans",

		 "authors": [

		           {

		            	 "affiliation": "University of Erlangen-Nuremberg",

		           	 "location": "Erlangen  Germany Computer Science (AI Group)",

		            	 "name": "Richard Schaller",

		           	 "email": "richard.schaller@fau.de"

 		           },

		            {

		            	 "affiliation": "University of Lugano",

		           	 "location": "Lugano  Switzerland Faculty of Informatics",

		            	 "name": "Morgan Harvey",

		           	 "email": "morgan.harvey@usi.ch"

		            },

		           {

		            	 "affiliation": "University of Regensburg",

		           	 "location": "Regensburg  Germany I:IMSK",

		            	 "name": "David Elsweiler",

		           	 "email": "david@elsweiler.co.uk"

		            }

		           ]

	 },

	 "sd213": {

		 "abstract": "Automatic image annotation plays a critical role in keyword-based image retrieval systems. Recently, the nearest-neighbor based scheme has been proposed and achieved good performance for image annotation. Given a new image, the scheme is to first find its most similar neighbors from labeled images, and then propagate the keywords associated with the neighbors to it. Many studies focused on designing a suitable distance metric between images so that all labeled images can be ranked by their distance to the given image. However, higher accuracy in distance prediction does not necessarily lead to better ordering of labeled images. In this paper, we propose a ranking-oriented neighbor search mechanism to rank labeled images directly without going through the intermediate step of distance prediction. In particular, a new learning to rank algorithm is developed, which exploits the implicit preference information of labeled images and underlines the accuracy of the top-ranked results. Experiments on two benchmark datasets demonstrate the effectiveness of our approach for image annotation.",

		"title": "Ranking-Oriented Nearest-Neighbor Based Method for Automatic Image Annotation",

		 "authors": [

		           {

		            	 "affiliation": "School of Computer Science and Technology, Shandong University",

		           	 "location": "Jinan  China ",

		            	 "name": "Chaoran Cui",

		           	 "email": "bruincui@gmail.com"

		            },

		           {

		            	 "affiliation": "School of Computer Science and Technology, Shandong University",

		           	 "location": "Jinan  China ",

		            	 "name": "Jun Ma",

		           	 "email": "majun@sdu.edu.cn"

		            },

		           {

		            	 "affiliation": "School of Computer Science and Technology, Shandong University",

		           	 "location": "Jinan  China ",

		            	 "name": "Tao Lian",

		           	 "email": "liantao1988@gmail.com"

		            },

		           {

		            	 "affiliation": "School of Computer Science and Technology, Shandong University",

		           	 "location": "Jinan  China ",

		            	 "name": "Xiaofang Wang",

		           	 "email": "ise_wangxf@ujn.edu.cn"

		            },

		           {

		            	 "affiliation": "Intelligent Systems Lab Amsterdam, University of Amsterdam",

		           	 "location": "Amsterdam  Netherlands ",

		            	 "name": "Zhaochun Ren",

		           	 "email": "z.ren@uva.nl"

		            }

		           ]

	 },

	 "sd214": {

		 "abstract": "As large collections of historically significant recorded speech become increasingly available, scholars are faced with the challenge of making sense of what they hear.  This paper proposes automatically linking conversational speech to related resources as one way of supporting that sense-making task.  Experiment results with transcribed conversations suggest that this kind of linking has promise for helping to contextualize recordings of detail-oriented conversations, and that simple sliding-window bag-of-words techniques can identify some useful links.",

		"title": "Linking Transcribed Conversational Speech",

		 "authors": [

		            {

		           	 "affiliation": "Eleanor Roosevelt High School",

		            	 "location": "Greenbelt MD USA",

		           	 "name": "Joseph Malionek",

		            	 "email": "jmalionek@gmail.com"

		           },

		            {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA College of Information Studies",

		            	 "name": "Douglas W. Oard",

		           	 "email": "oard@umd.edu"

		            },

		           {

		            	 "affiliation": "The University of Texas at Dallas",

		           	 "location": "Richardson TX USA Electrical Engineering Department",

		            	 "name": "Abhijeet Sangwan",

		           	 "email": "abhijeet.sangwan@utdallas.edu"

		           },

		            {

		            	 "affiliation": "The University of Texas at Dallas",

		           	 "location": "Richardson TX USA Electrical Engineering Department",

		            	 "name": "John H.L. Hansen",

		           	 "email": "john.hansen@utdallas.edu"

 		           }

		            ]

	 },

	 "sd215": {

		"abstract": "Image tagging is a growing application on social media websites, however, the performance of many auto-tagging methods are often poor. Recent work has exploited an image's context (e.g. time and location) in the tag recommendation process, where tags which co-occur highly within a given time interval or geographical area are promoted. These models, however, fail to address how and when different image contexts can be combined. In this paper, we propose a weighted tag recommendation model, building on an existing state-of-the-art, which varies the importance of time and location in the recommendation process, based on a given set of input tags. By retrieving more temporally and geographically relevant tags, we achieve statistically significant improvements to recommendation accuracy when testing on 519k images collected from Flickr. The result of this paper is an important step towards more effective image annotation and retrieval systems.",

		"title": "On Contextual Photo Tag Recommendation",

		 "authors": [

		            {

		           	 "affiliation": "The University of Glasgow",

		            	 "location": "Glasgow  United Kingdom School of Computing Science",

		           	 "name": "Philip J McParlane",

		            	 "email": "p.mcparlane.1@research.gla.ac.uk"

		           },

		            {

		            	 "affiliation": "The University of Glasgow",

		           	 "location": "Glasgow  United Kingdom School of Computing Science",

		            	 "name": "Yashar Moshfeghi",

		           	 "email": "Yashar.Moshfeghi@glasgow.ac.uk"

		           },

		            {

		            	 "affiliation": "The University of Glasgow",

		           	 "location": "Glasgow  United Kingdom School of Computing Science",

		            	 "name": "Joemon M Jose",

		           	 "email": "Joemon.Jose@glasgow.ac.uk"

		           }

		            ]

	 },

	 "sd216": {

		"abstract": "This paper presents a framework called Knowing Camera for real-time recognizing places-of-interest in smartphone photos, with the availability of online geotagged images of such places. We propose a probabilistic field-of-view model which captures the uncertainty in camera sensor data. This model can be used to retrieve a set of candidate images. The visual similarity computation of the candidate images relies on the sparse coding technique. We also propose an ANN filtering technique to speedup the sparse coding. The final ranking combines an uncertain geometric relevance with the visual similarity. Our preliminary experiments conducted in an urban area of a large city show promising results. The most distinguishing feature of our framework is its ability to perform well in contaminated, real-world online image database. Besides, our framework is highly scalable as it does not incur any complex data structure.",

		"title": "The Knowing Camera: Recognizing Places-of-Interest in Smartphone Photos",

		 "authors": [

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China ",

		            	 "name": "Pai Peng",

		           	 "email": "pengpai_sh@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Lidan Shou",

		           	 "email": "should@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Ke Chen",

		           	 "email": "chenk@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Gang Chen",

		           	 "email": "cg@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Sai Wu",

		           	 "email": "wusai@zju.edu.cn"

		            }

		           ]

	 },

	 "sd217": {

		 "abstract": "Community Question Answering (CQA) services, such as Yahoo! Answers and WikiAnswers, have become popular with users as one of the central paradigms for satisfying users' information needs. The task of question retrieval in CQA aims to resolve one's query directly by finding the most relevant questions (together with their answers) from an archive of past questions. However, as users can ask any question that they like, a large number of questions in CQA  are not about objective (factual) knowledge, but about subjective (sentiment-based) opinions or social interactions. The inhomogeneous nature of CQA leads to reduced performance of standard retrieval models. To address this problem, we present a hybrid approach that blends several language modelling techniques for question retrieval, namely, the classic (query-likelihood) language model, the state-of-the-art translation-based language model, and our proposed intent-based language model. The user intent of each candidate question (objective/subjective/social) is given by a probabilistic classifier which makes use of both textual features and metadata features. Our experiments on two real-world datasets show that our approach can significantly outperform existing ones.",

		"title": "Question Retrieval with User Intent",

		 "authors": [

		            {

		           	 "affiliation": "Birkbeck, University of London",

		            	 "location": "London  United Kingdom ",

		           	 "name": "Long Chen",

		            	 "email": "long@dcs.bbk.ac.uk"

		           },

		            {

		            	 "affiliation": "Birkbeck, University of London",

		           	 "location": "London  United Kingdom ",

		            	 "name": "Dell Zhang",

		           	 "email": "dell@dcs.bbk.ac.uk"

		            },

		           {

		            	 "affiliation": "Birkbeck, University of London",

		           	 "location": "London  United Kingdom ",

		            	 "name": "Mark Levene",

		           	 "email": "mark@dcs.bbk.ac.uk"

		            }

		           ]

	 },

	 "sd218": {

		 "abstract": "In this paper, for the first time, we study the problem of mapping keyword queries to questions on community-based question answering (CQA) sites. Mapping general web queries to questions enables search engines not only to discover explicit and specific information needs (questions) behind keywords queries, but also to find high quality information (answers) for answering keyword queries. In order to map queries to questions, we propose a ranking algorithm containing three steps: Candidate Question Selection, Candidate Question Ranking, and Candidate Question Grouping. Preliminary experimental results using 60 queries from search logs of a commercial engine show that the presented approach can efficiently find the questions which capture user???s information needs explicitly. ",

		"title": "Mapping Queries to Questions: Towards Understanding Users' Information Needs",

		 "authors": [

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China College of Computer Science",

		            	 "name": "Yunjun Gao",

		           	 "email": "gaoyj@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China College of Computer Science",

		            	 "name": "Lu Chen",

		           	 "email": "chenl@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "University of Illinois at Urbana-Champaign",

		           	 "location": "Urbana IL USA Department of Computer Science",

		            	 "name": "Rui Li",

		           	 "email": "xruili1@uiuc.edu"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China College of Computer Science",

		            	 "name": "Gang Chen",

		           	 "email": "cg@zju.edu.cn"

		            }

		           ]

	 },

	 "sd219": {

		 "abstract": "We introduce the concept of keyqueries as dynamic content descriptors for documents. Keyqueries are defined implicitly by the index and the retrieval model of a reference search engine: keyqueries for a document are the minimal queries that return the document in the top result ranks. Besides applications in the fields of information retrieval and data mining, keyqueries have the potential to form the basis of a dynamic classification system for future digital libraries---the modern version of keywords for content description. To determine the keyqueries for a document, we present an exhaustive search algorithm along with effective pruning strategies. For applications where a small number of diverse keyqueries is sufficient, two tailored search strategies are proposed. Our experiments emphasize the role of the reference search engine and show the potential of keyqueries as innovative document descriptors for large, fast evolving bodies of digital content such as the web.",

		"title": "From Keywords to Keyqueries: Content Descriptors for the Web",

		 "authors": [

		           {

		            	 "affiliation": "Bauhaus-Universität",

		           	 "location": "Weimar  Germany ",

		            	 "name": "Tim Gollub",

		           	 "email": "tim.gollub@uni-weimar.de"

 		           },

		            {

		            	 "affiliation": "Bauhaus-Universität",

		           	 "location": "Weimar  Germany ",

		            	 "name": "Matthias Hagen",

		           	 "email": "matthias.hagen@uni-weimar.de"

		           },

		            {

		            	 "affiliation": "Bauhaus-Universität",

		           	 "location": "Weimar  Germany ",

		            	 "name": "Maximilian Michel",

		           	 "email": "maximilian.michel@uni-weimar.de"

		           },

		            {

		            	 "affiliation": "Bauhaus-Universität",

		           	 "location": "Weimar  Germany ",

		            	 "name": "Benno Stein",

		           	 "email": "benno.stein@uni-weimar.de"

		           }

		            ]

	 },

	 "sd220": {

		"abstract": "Commodity information such as prices and public reviews is always the concern of consumers. Helping them conveniently acquire these information as an instant reference is often of practical significance for their purchase activities. Nowadays, Web 2.0, linked data clouds, and the pervasiveness of smart hand held devices have created opportunities for this demand, i.e., users could just snap a photo of any commodity that is of interest at anytime and anywhere, and retrieve the relevant information via their Internet-linked mobile devices. Nonetheless, compared with the traditional keyword-based information retrieval, extracting the hidden information related to the commodities in photos is a much more complicated and challenging task, involving techniques such as pattern recognition, knowledge base construction, semantic comprehension, and statistic deduction. In this paper, we propose a framework to address this issue by leveraging on various techniques, and evaluate the effectiveness and efficiency of this framework with experiments on a prototype.",

		"title": "Commodity Query by Snapping",

		 "authors": [

		            {

		           	 "affiliation": "National University of Singapore",

		            	 "location": "Singapore  Singapore",

		           	 "name": "Hao Huang",

		            	 "email": "huanghao@comp.nus.edu.sg"

		           },

		            {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Yunjun Gao",

		           	 "email": "gaoyj@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Tan Tao University",

		           	 "location": "Long An  Vietnam",

		            	 "name": "Kevin Chiew",

		           	 "email": "kevin.chiew@ttu.edu.vn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Qinming He",

		           	 "email": "hqm@zju.edu.cn"

		            },

		           {

		            	 "affiliation": "Zhejiang University",

		           	 "location": "Hangzhou  China",

		            	 "name": "Lu Chen",

		           	 "email": "chenl@zju.edu.cn"

		            }

		           ]

	 },

	 "sd221": {

		 "abstract": "Time is often important for understanding user intent during search activity, especially for information needs related to event-driven topics. Diversity for multi-faceted information needs ensures that ranked documents optimally cover multiple facets when a user's intent is uncertain. Effective diversity is reliant on methods to (i) discover and represent facets, and (ii) determine how likely each facet is the user's intent (i.e., its popularity). Past work has developed several techniques addressing these issues, however, they have concentrated on static approaches which do not consider the temporal nature of new and evolving intents and their popularity. In many cases, what a user expects may change dramatically over time as events develop. In this work we study the temporal variance of search intents for event-driven information needs using Wikipedia. First, we model intents based upon the structure represented by the section hierarchy of Wikipedia articles closely related to the information need. Using this technique, we investigate whether temporal changes in the content structure, i.e. in a section's text, reflect the temporal popularity of the intent. We map intents taken from a query-log (as ground-truth) to Wikipedia article sections and found that a large proportion are indeed reflected in topic-related article structure. By correlating the change activity of each section with the use of the intent query over time, we found that section change activity does reflect temporal popularity of many intents. Furthermore, we show that popularity between intents changes over time for event-driven topics.",

		"title": "Temporal Variance of Intents in Multi-faceted Event-driven Information Needs",

		 "authors": [

		           {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  United Kingdom School of Computing Science",

		            	 "name": "Stewart Whiting",

		           	 "email": "stewh@dcs.gla.ac.uk"

		            },

		           {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  United Kingdom School of Computing Science",

		            	 "name": "Ke Zhou",

		           	 "email": "zhouke@dcs.gla.ac.uk"

		            },

		           {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  United Kingdom School of Computing Science",

		            	 "name": "Joemon Jose",

		           	 "email": "jj@dcs.gla.ac.uk"

		            },

		           {

		            	 "affiliation": "Yahoo! Labs",

		           	 "location": "Barcelona  Spain",

		            	 "name": "Mounia Lalmas",

		           	 "email": "mounia@acm.org"

		            }

		           ]

	 },

	 "sd222": {

		 "abstract": "Mobile devices provide people with a conduit to the rich infor-mation resources of the Web. With consent, the devices can also provide streams of information about search activity and location that can be used in population studies and real-time assistance. We analyzed geotagged mobile queries in a privacy-sensitive study of potential transitions from health information search to in-world healthcare utilization. We note differences in people???s health infor-mation seeking before, during, and after the appearance of evidence that a medical facility has been visited. We find that we can accu-rately estimate statistics about such potential user engagement with healthcare providers. The findings highlight the promise of using geocoded search for sensing and predicting activities in the world.",

		"title": "Pursuing Insights about Healthcare Utilization via Geocoded Search Queries",

		 "authors": [

		           {

		            	 "affiliation": "Twitter Inc",

		           	 "location": "San Francisco CA USA",

		            	 "name": "Shuang-Hong Yang",

		           	 "email": "syang@twitter.com"

		            },

		           {

		            	 "affiliation": "Microsoft Research",

		           	 "location": "Redmond WA USA",

		            	 "name": "Ryen W White",

		           	 "email": "ryenw@microsoft.com"

		            },

		           {

		            	 "affiliation": "Microsoft Research",

		           	 "location": "Redmond WA USA",

		            	 "name": "Eric Horvitz",

		           	 "email": "horvitz@microsoft.com"

		            }

		           ]

	 },

	 "sd223": {

		 "abstract": "This paper examines a multi-stage retrieval architecture consisting of a candidate generation stage, a feature extraction stage, and a reranking stage using machine-learned models.  Given a fixed set of features and a learning-to-rank model, we explore effectiveness/efficiency tradeoffs with three candidate generation approaches: postings intersection with SvS, conjunctive query evaluation with WAND, and disjunctive query evaluation with WAND. We find no significant differences in end-to-end effectiveness as measured by NDCG between conjunctive and disjunctive WAND, but conjunctive query evaluation is substantially faster. Postings intersection with SvS, while fast, yields substantially lower end-to-end effectiveness, suggesting that document and term frequencies remain important in the initial ranking stage. These findings show that conjunctive WAND is the best overall candidate generation strategy of those we examined.",

		"title": "Effectiveness/Efficiency Tradeoffs for Candidate Generation in Multi-Stage Retrieval Architectures",

		 "authors": [

		           {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA",

		            	 "name": "Nima Asadi",

		           	 "email": "nima@cs.umd.edu"

		            },

		           {

		            	 "affiliation": "University of Maryland",

		           	 "location": "College Park MD USA",

		            	 "name": "Jimmy Lin",

		           	 "email": "jimmylin@umd.edu"

		            }

		           ]

	 },

	 "sd224": {

		 "abstract": "Improving query understanding is crucial for providing the user with information that suits her needs. To this end, the retrieval system must be able to deal with several sources of knowledge from which it could infer a topical context. The use of external sources of information for improving document retrieval has been extensively studied. Improvements with either structured or large sets of data have been reported. However, in these studies resources are often used separately and rarely combined together. We experiment in this paper a method that discounts documents based on their weighted divergence from a set of external resources. We present an evaluation of the combination of four resources on two standard TREC test collections. Our proposed method significantly outperforms a state-of-the-art Mixture of Relevance Models on one test collection, while no significant differences are detected on the other one.",

		"title": "Estimating Topical Context by Diverging from External Resources",

		 "authors": [

		           {

		            	 "affiliation": "University of Avignon",

		           	 "location": "Avignon  France LIA",

		            	 "name": "Romain Deveaud",

		           	 "email": "romain.deveaud@univ-avignon.fr"

		           },

		            {

		            	 "affiliation": "University of Avignon",

		           	 "location": "Avignon  France LIA",

		            	 "name": "Eric SanJuan",

		           	 "email": "eric.sanjuan@univ-avignon.fr"

		           },

		            {

		            	 "affiliation": "Aix-Marseille University",

		           	 "location": "Marseille  France LSIS",

		            	 "name": "Patrice Bellot",

		           	 "email": "patrice.bellot@lsis.org"

 		           }

		            ]

	 },

	 "sd225": {

		"abstract": "The task of finding groups is a natural extension of search tasks aimed at retrieving individual entities.  We introduce a group finding task: given a query topic, find knowledgeable groups that have expertise on that topic.  We present four general strategies to this task.  The models are formalized using generative language models.  Two of the models aggregate expertise scores of the experts in the same group for the task, one locates documents associated with experts in the group and then determines how closely the documents are associated with the topic, whilst the remaining model directly estimates the degree to which a group is a knowledgeable group for a given topic.  We construct a test collections based on the TREC 2005 and 2006 Enterprise collections.  We find significant differences between different ways of estimating the association between a topic and a group. Experiments show that our knowledgeable group finding models achieve high absolute scores.",

		"title": "Finding Knowledgeable Groups in Enterprise Corpora",

		 "authors": [

		           {

		            	 "affiliation": "University of Amsterdam",

		           	 "location": "Amsterdam  Netherlands ISLA",

		            	 "name": "Shangsong Liang",

		           	 "email": "s.liang@uva.nl"

		            },

		           {

		            	 "affiliation": "University of Amsterdam",

		           	 "location": "Amsterdam  Netherlands ISLA",

		            	 "name": "Maarten de Rijke",

		           	 "email": "derijke@uva.nl"

		            }

		           ]

	 },

	 "sd226": {

		 "abstract": "We introduce a scheme for optimally allocating multiple bits per hyperplane for Locality Sensitive Hashing (LSH). Existing approaches binarise LSH projections by thresholding at zero yielding a single bit per dimension. We demonstrate that this is a sub-optimal bit allocation approach that can easily destroy the neighbourhood structure in the original feature space. Our proposed method, dubbed Neighbourhood Preserving Quantization (NPQ), assigns multiple bits per hyperplane based upon adaptively learned thresholds. NPQ exploits a pairwise affinity matrix to discretise each dimension such that nearest neighbours in the original feature space fall within the same quantisation thresholds and are therefore assigned identical bits. NPQ is not only applicable to LSH, but can also be applied to any low-dimensional projection scheme. Despite using half the number of hyperplanes, NPQ is shown to improve LSH-based retrieval accuracy by up to 65% compared to the state-of-the-art.",

		"title": "Neighbourhood Preserving Quantisation for LSH",

		 "authors": [

 		           {

		            	 "affiliation": "The University of Edinburgh",

		           	 "location": "Edinburgh  United Kingdom School of Informatics",

		            	 "name": "Sean Moran",

		           	 "email": "sean.moran@ed.ac.uk"

		            },

		           {

		            	 "affiliation": "The University of Edinburgh",

		           	 "location": "Edinburgh  United Kingdom School of Informatics",

		            	 "name": "Victor Lavrenko",

		           	 "email": "vlavrenk@inf.ed.ac.uk"

		            },

		           {

		            	 "affiliation": "The University of Edinburgh",

		           	 "location": "Edinburgh  United Kingdom School of Informatics",

		            	 "name": "Miles Osborne",

		           	 "email": "miles@inf.ed.ac.uk"

		            }

		           ]

	 },

	 "sd227": {

		 "abstract": "We present an initial study identifying a form of content-based grey hat search engine optimization, in which a Web page contains both potentially relevant content and manipulated content: we call such pages sham documents, because they lie in the grey area between 'ham' (clearly normal) and 'spam' (clearly fake). Sham documents are often ranked artificially high in response to certain queries, but also may contain some useful information and cannot be considered as absolute spam. We report a novel annotation effort performed with the ClueWeb09 benchmark where pages were labeled as being spam, sham, or legitimate content. Significant inter-annotator agreement rates support the claim that there are sham documents that are highly ranked by a very effective retrieval approach, yet are not spam. We also present an initial study of predictors that may indicate whether a query is the target of shamming.",

		"title": "Shame to be Sham: Addressing Content-Based Grey Hat Search Engine Optimization",

		 "authors": [

		           {

		            	 "affiliation": "Technion - Israel Institute of Technology",

		           	 "location": "Haifa  Israel",

		            	 "name": "Fiana Raiber",

		           	 "email": "fiana@tx.technion.ac.il"

 		           },

		            {

		            	 "affiliation": "Microsoft Research",

		           	 "location": "Redmond  USA",

		            	 "name": "Kevyn Collins-Thompson",

		           	 "email": "kevynct@microsoft.com"

		            },

		           {

		            	 "affiliation": "Technion - Israel Institute of Technology",

		           	 "location": "Haifa  Israel",

		            	 "name": "Oren Kurland",

		           	 "email": "kurland@ie.technion.ac.il"

		           }

		            ]

	 },

	 "sd228": {

		"abstract": "Random Walk with Restart (RWR) has become an appealing measure of node proximities in emerging applications recommender systems and automatic image captioning. In practice, a real graph is typically large, and is frequently updated with small changes. It is often cost-inhibitive to recompute proximities from scratch via algorithms when the graph is updated. This paper focuses on the incremental computations of RWR in a dynamic graph, whose edges often change over time. The prior attempt of RWR deploys to find highest proximity nodes for a given query, which involves a strategy to incrementally estimate upper proximity bounds. However, due to its aim to prune needless calculation, such an incremental strategy is approximate: in time for each node. The main contribution of this paper is to devise an exact and fast incremental algorithm of RWR for edge updates. Our solution, IRWR!, can incrementally compute any node proximity in time for each edge update without loss of exactness. The empirical evaluations show the high efficiency and exactness of IRWR for computing proximities on dynamic networks against its batch counterparts.",

		"title": "IRWR: Incremental Random Walk with Restart",

		 "authors": [

		            {

		           	 "affiliation": "The University of New South Wales",

		            	 "location": "Sydney  Australia School of Computer Science & Engineering",

		           	 "name": "Weiren Yu",

		            	 "email": "weirenyu@cse.unsw.edu.au"

		           },

		            {

		            	 "affiliation": "The University of New South Wales",

		           	 "location": "Sydney  Australia School of Computer Science & Engineering",

		            	 "name": "Xuemin Lin",

		           	 "email": "lxue@cse.unsw.edu.au"

		            }

		           ]

	 },

	 "sd229": {

		 "abstract": "It has been recognized that, when an information retrieval (IR) system achieves improvement in mean retrieval effectiveness (e.g. mean average precision (MAP)) over all the queries, the performance (e.g., average precision (AP)) of some individual queries could be hurt, resulting in retrieval instability. Some stability/robustness metrics have been proposed. However, they are often defined separately from the mean effectiveness metric. Consequently, there is a lack of a unified formulation of effectiveness, stability and overall retrieval quality (considering both). In this paper, we present a unified formulation based on the bias-variance decomposition. Correspondingly, a novel evaluation methodology is developed to evaluate the effectiveness and stability in an integrated manner. A case study applying the proposed methodology to evaluation of query language modeling illustrates the usefulness and analytical power of our approach.",

		"title": "Bias-Variance Decomposition of IR Evaluation",

		 "authors": [

 		           {

		            	 "affiliation": "Tianjin University",

		           	 "location": "Tianjin  China Tianjin Key Laboratory of Cognitive Computing and Application, School of Computing",

		           	 "name": "Peng Zhang",

		            	 "email": "darcyzzj@gmail.com"

		           },

		            {

		            	 "affiliation": "Tianjin University",

		           	 "location": "Tianjin  China Tianjin Key Laboratory of Cognitive Computing and Application, School of Computing",

		           	 "name": "Dawei Song",

		            	 "email": "dawei.song2010@gmail.com"

		           },

		            {

		            	 "affiliation": "University College London",

		           	 "location": "London  United Kingdom Department of Computer Science",

		            	 "name": "Jun Wang",

		           	 "email": "jun_wang@acm.org"

		            },

		           {

		            	 "affiliation": "Tianjin University",

		           	 "location": "Tianjin  China Tianjin Key Laboratory of Cognitive Computing and Application, School of Computing",

		           	 "name": "Yuexian Hou",

		            	 "email": "yxhou@tju.edu.cn"

		           }

		            ]

	 },

	 "sd230": {

		"abstract": "In this paper, we present a medical record search system which is useful for identifying cohorts required in clinical studies. In particular, we propose a query-adaptive weighting method that can dynamically aggregate and score evidence in multiple medical reports (from different hospital departments or from different tests within the same department) of a patient. Furthermore, we explore several informative features for learning our retrieval model.",

		"title": "An Adaptive Evidence Weighting Method for Medical Record Search",

		 "authors": [

		           {

		            	 "affiliation": "University of Delaware",

		           	 "location": "Newark Delaware USA ",

		            	 "name": "Dongqing Zhu",

		           	 "email": "zhu@cis.udel.edu"

		            },

		           {

		            	 "affiliation": "University of Delaware",

		           	 "location": "Newark Delaware USA ",

		            	 "name": "Ben Carterette",

		           	 "email": "carteret@cis.udel.edu"

		            }

		           ]

	 },

	 "sd231": {

		 "abstract": "In the last years, a lot of attention was attracted by the problem of page authority computation based on user browsing behavior. However, the proposed methods have a number of limitations. In particular, they run on a single snapshot of a user browsing graph ignoring substantially dynamic nature of user browsing activity, which makes such methods recency unaware. This paper proposes a new method for computing page importance, referred to as Fresh BrowseRank. The score of a page by our algorithm equals to the weight in a stationary distribution of a flexible random walk, which is controlled by recency-sensitive weights of vertices and edges. Our method generalizes some previous approaches, provides better capability for capturing the dynamics of the Web and users behavior, and overcomes essential limitations of BrowseRank. The experimental results demonstrate that our method enables to achieve more relevant and fresh ranking results than the classic BrowseRank.",

		"title": "Fresh BrowseRank",

		 "authors": [

		            {

		           	 "affiliation": "Yandex",

		            	 "location": "Moscow  Russian Fed.",

		           	 "name": "Maxim Zhukovskiy",

		            	 "email": "zhukmax@yandex-team.ru"

		           },

		            {

		            	 "affiliation": "Yandex",

		           	 "location": "Moscow  Russian Fed.",

		            	 "name": "Andrei Khropov",

		           	 "email": "akhropov@yandex-team.ru"

 		           },

		            {

		            	 "affiliation": "Yandex",

		           	 "location": "Moscow  Russian Fed.",

		            	 "name": "Gleb Gusev",

		           	 "email": "gleb57@yandex-team.ru"

		            },

		           {

		            	 "affiliation": "Yandex",

		           	 "location": "Moscow  Russian Fed.",

		            	 "name": "Pavel Serdyukov",

		           	 "email": "pavser@yandex-team.ru"

		            }

		           ]

	 },

	 "sd232": {

		 "abstract": "Finding experts in question answering platforms has important applications, such as question routing or identification of best answers. Addressing the problem of ranking users with respect to their expertise, we propose Competition-Based Expertise Networks (CBEN), a novel community expertise network structure based on the principle of competition among the answerers of a question. We evaluate our approach on a very large dataset from Yahoo! Answers using a variety of centrality measures. We show that it outperforms state-of-the-art network structures and, unlike previous methods, is able to consistly outperform simple metrics like best answer count. We also analyse question answering forums in Yahoo! Answers, and show that they can be characterised by factual or subjective information seeking behavior, social discussions and the conducting of polls or surveys. We find that the ability to identify experts greatly depends on the type of forum, which is directly reflected in the structural properties of the expertise networks.",

		"title": "Competition-Based Networks for Expert Finding",

		 "authors": [

 		           {

		            	 "affiliation": "UPF Web Research Group",

		           	 "location": "Barcelona  Spain",

		            	 "name": "Cigdem Aslay",

		           	 "email": "aslayci@acm.org"

		            },

		           {

		            	 "affiliation": "Yahoo! Research Barcelona",

		           	 "location": "Barcelona  Spain",

		            	 "name": "Neil O'Hare",

		           	 "email": "nohare@yahoo-inc.com"

		            },

		           {

		            	 "affiliation": "Yahoo! Research Barcelona",

		           	 "location": "Barcelona  Spain",

		            	 "name": "Luca Maria Aiello",

		           	 "email": "alucca@yahoo-inc.com"

		            }

		           ]

	 },

	 "sd233": {

		 "abstract": "Obtaining geographically tagged multimedia items from social Web platforms such as Flickr is beneficial for a variety of applications including the automatic creation of travelogues and personalized travel recommendations. In order to take advantage of the large number of photos and videos that do not contain (GPS-based) latitude/longitude coordinates, a number of approaches have been proposed to estimate the geographic location where they were taken. Such location estimation methods rely on existing geotagged multimedia items as training data. Across application and usage scenarios, it is commonly assumed that the available geotagged items contain (reasonably) accurate latitude/longitude coordinates. Here, we consider this assumption and investigate how accurate the provided location data is. We conduct a study of Flickr images and videos and find that the accuracy of the geotag information is highly dependent on the popularity of the location: images/videos taken at popular (unpopular) locations, are likely to be geotagged with a high (low) degree of accuracy with respect to the ground truth.",

		"title": "A Study on the Accuracy of Flickr's Geotag Data",

		 "authors": [

		           {

		            	 "affiliation": "Web Information Systems",

		           	 "location": "Delft  Netherlands Delft University of Technology",

		            	 "name": "Claudia Hauff",

		           	 "email": "c.hauff@tudelft.nl"

		            }

		           ]

	 },

	 "sd234": {

		 "abstract": "We propose a method for finding impressive creators in online social network sites (SNSs). Many users are actively engaged in publishing their own works, sharing visual content on sites such as YouTube or Flickr. In this paper, we focus on the Japanese illustration-sharing SNS, Pixiv. We implement an illustrator search system based on user impression categories. The impressions of illustrators are estimated from clues in the crowdsourced social-tag annotations on their illustrations. We evaluated our system in terms of normalized discounted cumulative gain and found that using feedback on motifs and impressions for illustrations of relevant illustrators improved illustrator search by 11%.",

		"title": "Finding Impressive Social Content Creators",

		 "authors": [

		            {

		           	 "affiliation": "University of Tsukuba",

		            	 "location": "Ibaraki  Japan Faculty of Library, Information and Media Science",

		           	 "name": "Yohei Seki",

		            	 "email": "yohei@slis.tsukuba.ac.jp"

		           },

		            {

		            	 "affiliation": "University of Tsukuba",

		           	 "location": "Ibaraki  Japan Faculty of Library, Information and Media Science",

 		           	 "name": "Kiyoto Miyajima",

		            	 "email": "miyaji132@gmail.com"

		           }

		            ]

	 },

	 "sd235": {

		"abstract": "It is well recognized that users rely on social media (e.g. Twitter or Digg) to fulfill two common needs (i.e. social need and informational need) that is to keep in touch with their friends in the real world and to have access to information they are interested in. Traditional friend recommendation methods in social media mainly focus on a user's social need, but seldom address their informational need (i.e. suggesting friends that can provide information one may be interested in but have not been able to obtain so far). In this paper, we propose to recommend friends according to the informational utility, which stands for the degree to which a friend satisfies the target user's unfulfilled informational need, called informational friend recommendation. In order to capture users' informational need, we view a post in social media as an item and utilize collaborative filtering techniques to predict the rating for each post. The candidate friends are then ranked according to their informational utility for recommendation. In addition, we also show how to further consider diversity in such recommendations. Experiments on benchmark datasets demonstrate that our approach can significantly outperform the traditional friend recommendation methods under informational evaluation measures.",

		"title": "Informational Friend Recommendation in Social Media",

		 "authors": [

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Shengxian Wan",

		           	 "email": "wanshengxian@software.ict.ac.cn"

		           },

		            {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Yanyan Lan",

		           	 "email": "lanyanyan@ict.ac.cn"

		            },

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Jiafeng Guo",

		           	 "email": "guojiafeng@ict.ac.cn"

		            },

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Chaosheng Fan",

		           	 "email": "fcs@pku.edu.cn"

		            },

		           {

		            	 "affiliation": "Institute of Computing Technology, Chinese Academy of Sciences",

		           	 "location": "Beijing  China",

		            	 "name": "Xueqi Cheng",

		           	 "email": "cxq@ict.ac.cn"

		            }

		           ]

	 },

	 "sd236": {

		 "abstract": "In this paper, we present a contribution to IR modeling. We propose an approach that computes on the fly, a Personalized Social Document Representation (PSDR) of each document per user based on his social activities. The PSDRs are used to rank documents with respect to a query. This approach has been intensively evaluated on a large public dataset, showing significant benefits for personalized search.",

		"title": "Using Social Annotations to Enhance Document Representation for Personalized Search",

		 "authors": [

		           {

		            	 "affiliation": "PRiSM Laboratory, Versailles University",

		           	 "location": "Versailles  France Computer Science",

		            	 "name": "Mohamed Reda Bouadjenek",

		           	 "email": "rbouadjenek@gmail.com"

		            },

		           {

		            	 "affiliation": "SideTrade, France",

		           	 "location": "Boulogne-Billancourt  France Computer Science",

		            	 "name": "Hakim Hacid",

		           	 "email": "hakim.hacid@gmail.com"

		            },

		           {

		            	 "affiliation": "PRiSM Laboratory, Versailles University",

		           	 "location": "Versailles  France Computer Science",

		            	 "name": "Mokrane Bouzeghoub",

		           	 "email": "mokrane.bouzeghoub@prism.uvsq.fr"

		           },

		            {

		            	 "affiliation": "Aristotle University of Thessaloniki",

		           	 "location": "Thessaloniki  Greece Computer Science",

		            	 "name": "Athena Vakali",

		           	 "email": "avakali@csd.auth.gr"

		            }

		           ]

	 },

	 "sd237": {

		 "abstract": "n-gram representations of documents may improve over a simple bag-of-word representation by relaxing the independence assumption of word and introducing context. However, this comes at a cost of adding features which are non-descriptive, and increasing the dimension of the vector space model exponentially.  We present new representations that avoid both pitfalls. They are based on sound theoretical notions of stringology, and can be computed in optimal asymptotic time with algorithms using data structures from the suffix family. While maximal repeats have been used in the past for similar tasks, we show how another equivalence class of repeats -- largest-maximal repeats -- obtain similar or better results, with only a fraction of the features. This class acts as a minimal generative basis of all repeated substrings. We also report their use for topic modeling, showing easier to interpret models.",

		"title": "The Bag-of-Repeats Representation of Documents",

		 "authors": [

 		           {

		            	 "affiliation": "Xerox Research Centre Europe",

		           	 "location": "Meylan  France",

		            	 "name": "Matthias Gallé",

		           	 "email": "mgalle@gmail.com"

		            }

		           ]

	 },

	 "sd238": {

		 "abstract": "Document expansion (DE) in information retrieval (IR) involves modifying each document in the collection by introducing additional terms into the document. It is particularly useful to improve retrieval of short and noisy documents where the additional terms can improve the description of the document content. Existing approaches to DE assume that documents to be expanded are from a single topic. In the case of multi-topic documents this can lead to a topic bias in terms selected for DE and hence may result in poor retrieval quality due to the lack of coverage of the original document topics in the expanded document. This paper proposes a new DE technique providing a more uniform selection and weighting of DE terms from all constituent topics. We show that our proposed method significantly outperforms the most recently reported relevance model based DE method on a spoken document retrieval task for both manual and automatic speech recognition transcripts.",

		"title": "An LDA-smoothed Relevance Model for Document Expansion: A Case Study for Spoken Document Retrieval",

		 "authors": [

		           {

		            	 "affiliation": "Dublin City University",

		           	 "location": "Dublin  Ireland School of Computing",

		            	 "name": "Debasis Ganguly",

		           	 "email": "dganguly@computing.dcu.ie"

		           },

		            {

		            	 "affiliation": "Dublin City University",

		           	 "location": "Dublin  Ireland School of Computing",

		            	 "name": "Johannes Leveling",

		           	 "email": "jleveling@computing.dcu.ie"

		           },

		            {

		            	 "affiliation": "Dublin City University",

		           	 "location": "Dublin  Ireland School of Computing",

		            	 "name": "Gareth J. F. Jones",

		           	 "email": "gjones@computing.dcu.ie"

 		           }

		            ]

	 },

	 "sd239": {

		"abstract": "Timeline generation is an important research task which can help users to have a quick understanding of the overall evolution of any given topic. It thus attracts much attention from research communities in recent years. Nevertheless, existing work on timeline generation often ignores an important factor, the attention attracted to topics of interest (hereafter termed ???social attention???). Without taking into consideration social attention, the generated timelines may not reflect users??? collective interests. In this paper, we study how to incorporate social attention in the generation of timeline summaries. In particular, for a given topic, we capture social attention by learning users??? collective interests in the form of word distributions from Twitter, which are subsequently incorporated into a unified framework for timeline summary generation. We construct four evaluation sets over six diverse topics. We demonstrate that our proposed approach is able to generate both informative and interesting timelines. Our work sheds light on the feasibility of incorporating social attention into traditional text mining tasks.",

		"title": "Timeline Generation with Social Attention",

		 "authors": [

		            {

		           	 "affiliation": "PKU",

		            	 "location": "Beijing  China",

		           	 "name": "Xin Wayne Zhao",

		            	 "email": "batmanfly@gmail.com"

		           },

		            {

		            	 "affiliation": "PKU",

		           	 "location": "Beijing  China",

		            	 "name": "Yanwei Guo",

		           	 "email": "pkuguoyw@gmail.com"

		            },

		           {

		            	 "affiliation": "PKU",

		           	 "location": "Beijing  China",

		            	 "name": "Rui Yan",

		           	 "email": "rui.yan.peking@gmail.com"

 		           },

		            {

		            	 "affiliation": "Aston University",

		           	 "location": "Birmingham  England UK",

		            	 "name": "Yulan He",

		           	 "email": "y.he@cantab.net"

		            },

		           {

		            	 "affiliation": "PKU",

		           	 "location": "Beijing  China",

		            	 "name": "Xiaoming Li",

		           	 "email": "lxm@pku.edu.cn"

		            }

		           ]

	 },

	 "sd240": {

		 "abstract": "Modern search engines make extensive use of people's contextual information to finesse result rankings. Using a searcher's location provides an especially strong signal for adjusting results for certain classes of queries where people may have clear preference for local results, without explicitly specifying the location in the query direct-ly. However, if the location estimate is inaccurate or searchers want to obtain many results from a particular location, they have limited control on the location focus in the search results returned. In this paper we describe a user study that examines the effect of offering searchers more control over how local preferences are gathered and used. We studied providing users with functionality to offer explicit relevance feedback (ERF) adjacent to results automatically identi-fied as location-dependent (i.e., more from this location). They can use this functionality to indicate whether they are interested in a particular search result and desire more results from that result???s location. We compared the ERF system against a baseline (NoERF) that used the same underlying mechanisms to retrieve and rank results, but did not offer ERF support. User performance was as-sessed across 12 experimental participants over 12 location-sensitive topics, in a fully counter-balanced design. We found that participants interacted with ERF frequently, and there were signs that ERF has the potential to improve success rates and lead to more efficient searching for location-sensitive search tasks than NoERF.",

		"title": "Explicit Feedback in Local Search Tasks",

		 "authors": [

		            {

		           	 "affiliation": "Emory University",

		            	 "location": "Atlanta GA USA",

		           	 "name": "Dmitry Lagun",

		            	 "email": "dlagun@mathcs.emory.edu"

		           },

		            {

		            	 "affiliation": "Microsoft",

		           	 "location": "Redmond WA USA Bing",

		            	 "name": "Avneesh Sud",

		           	 "email": "avnsud@microsoft.com"

		            },

		           {

		            	 "affiliation": "Microsoft",

		           	 "location": "Redmond WA USA Bing",

		            	 "name": "Ryen W White",

		           	 "email": "ryenw@microsoft.com"

		            },

		           {

		            	 "affiliation": "Microsoft",

		           	 "location": "Redmond WA USA Bing",

		            	 "name": "Peter Bailey",

		           	 "email": "pbailey@microsoft.com"

		            },

		           {

		            	 "affiliation": "Microsoft",

		           	 "location": "Redmond WA USA Bing",

		            	 "name": "Georg Buscher",

		           	 "email": "georgbu@mcirosoft.com"

		            }

		           ]

	 },

	 "sd241": {

		 "abstract": "We introduce a novel sentence ranking problem called explanatory sentence extraction (ESE) which aims to rank sentences in opinionated text based on their usefulness for helping users understand the detailed reasons of sentiments (i.e., explanatoriness). We propose and study several general methods for scoring the explanatoriness of a sentence. We create new data sets and propose a new measure for evaluation. Experiment results show that the proposed methods are effective, outperforming a state of the art sentence ranking method for standard text summarization. ",

		"title": "Ranking Explanatory Sentences for Opinion Summarization",

		 "authors": [

		           {

		            	 "affiliation": "University of Illinois at Urbana-Champaign",

		           	 "location": "Urbana IL USA Dept. of Computer Science",

		            	 "name": "Hyun Duk Kim",

		           	 "email": "hkim277@illinois.edu"

		            },

		           {

		            	 "affiliation": "HP Laboratories",

		           	 "location": "Palo Alto CA USA Information Analytics Lab",

		            	 "name": "Malu G Castellanos",

		           	 "email": "malu.castellanos@hp.com"

 		           },

		            {

		            	 "affiliation": "HP Laboratories",

		           	 "location": "Palo Alto CA USA Information Analytics Lab",

		            	 "name": "Meichun Hsu",

		           	 "email": "meichun.hsu@hp.com"

		            },

		           {

		            	 "affiliation": "University of Illinois at Urbana-Champaign",

		           	 "location": "Urbana IL USA Dept. of Computer Science",

		            	 "name": "ChengXiang Zhai",

		           	 "email": "czhai@illinois.edu"

		            },

		           {

		            	 "affiliation": "HP Laboratories",

		           	 "location": "Palo Alto CA USA Information Analytics Lab",

		            	 "name": "Umeshwar Dayal",

		           	 "email": "umeshwar.dayal@hp.com"

		            },

		           {

		            	 "affiliation": "HP Laboratories",

		           	 "location": "Palo Alto CA USA Information Analytics Lab",

		            	 "name": "Riddhiman Ghosh",

		           	 "email": "riddhiman.ghosh@hp.com"

		            }

		           ]

	 },

	 "sd242": {

		 "abstract": "Social media provides a new and potentially rich source of information for emergency management services. However, extracting the relevant information from such streams poses a number of difficult challenges. In this short paper, we survey emergency management professionals to ascertain how social media is used when responding to incidents, the search strategies that they undertake, and the challenges that they face when using social media streams. This research indicates that emergency management professionals employ two main strategies when searching social media streams: keyword-centric and account-centric search strategies. Furthermore, current search interfaces are inadequate regarding the requirements of command and control environments in the emergency management domain, where the process of information seeking is collaborative in nature and needs to support multiple information seekers.",

		"title": "#trapped! Social Media Search System Requirements for Emergency Management Professionals",

		 "authors": [

		           {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  Scotland Uk School of Computing Science",

		            	 "name": "Stefan Raue",

		           	 "email": "stefan.raue@glasgow.ac.uk"

		           },

		            {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  Scotland Uk School of Computing Science",

		            	 "name": "Leif Azzopardi",

		           	 "email": "leif.azzopardi@glasgow.ac.uk"

		           },

		            {

		            	 "affiliation": "University of Glasgow",

		           	 "location": "Glasgow  Scotland Uk School of Computing Science",

		            	 "name": "Chris W Johnson",

		           	 "email": "christopher.johnson@glasgow.ac.uk"

		           }

		            ]

	 },
  
  "r4a01": {
    "abstract": "The availability of user check-in data in large volume from the rapid growing location-based social networks (LBSNs) enables many important location-aware services to users. Point-of-interest (POI) recommendation is one of such services, which is to recommend places where users have not visited before. Several techniques have been recently proposed for the recommendation service. However, no existing work has considered the temporal information for POI recommendations in LBSNs. We believe that time plays an important role in POI recommendations because most users tend to visit different places at different time in a day, e.g. visiting a restaurant at noon and visiting a bar at night. In this paper, we define a new problem, namely, the time-aware POI recommendation, to recommend POIs for a given user at a specified time in a day. To solve the problem, we develop a collaborative recommendation model that is able to incorporate temporal information. Moreover, based on the observation that users tend to visit nearby POIs, we further enhance the recommendation model by considering geographical information. Our experimental results on two real-world datasets show that the proposed approach outperforms the state-of-the-art POI recommendation methods substantially.",
    "title": "Time-Aware Point-of-interest Recommendation",
    "authors": [
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Quan Yuan",
        "email": "qyuan1@e.ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Gao Cong",
        "email": "gaocong@ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Zongyang Ma",
        "email": "zma4@e.ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Aixin Sun",
        "email": "axsun@ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Nadia Magnenat-Thalmann",
        "email": "nadiathalmann@ntu.edu.sg"
      }
    ]
  },
"r4a02": {
    "abstract": "Existing recommender systems model user interests and the social influences independently. In reality, user interests may change over time, and as the interests change, new friends may be added while old friends grow apart and the new friendships formed may cause further interests change. This complex interaction requires the joint modeling of user interest and social relationships over time.  In this paper, we propose a probabilistic generative model, called Receptiveness over Time Model (RTM), to capture this interaction. We design a Gibbs sampling algorithm to learn the receptiveness and interest distributions among users over time. The results of experiments on a real world dataset demonstrate that RTM-based recommendation outperforms the state-of-the-art recommendation methods. Case studies also show that RTM is able to discover the user interest shift and receptiveness change over time",
    "title": "Modeling Users Receptiveness Over Time For Recommendation",
    "authors": [
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Wei Chen",
        "email": "weichen@comp.nus.edu.sg"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Wynne Hsu",
        "email": "whsu@comp.nus.edu.sg"
      },
      {
        "affiliation": "National University of Singapore",
        "location": "Singapore, Singapore",
        "name": "Mong Li Lee ",
        "email": "leeml@comp.nus.edu.sg"
      }
    ]
  },
"r4a03": {
    "abstract": "This paper addresses the problem of long-term language change in information retrieval (IR) systems. IR research has often ignored lexical drift.  But in the emerging domain of massive digitized book collections, the risk of vocabulary mismatch due to language change is high.  Collections such as Google Books and the Hathi Trust contain text written in the vernaculars of many centuries.  With respect to IR, changes in vocabulary and orthography make 14th-Century English qualitatively different from  21st-Century English. This challenges retrieval models that rely on keyword matching.  With this challenge in mind, we ask: given a query written in contemporary English, how can we retrieve relevant documents that were written in early English?  We argue that search in historically diverse corpora is similar to cross-language retrieval (CLIR).  By considering modern English and archaic English as distinct languages, CLIR techniques can improve what we call cross-temporal IR (CTIR).  We focus on ways to combine evidence to improve CTIR effectiveness,  proposing and testing several ways to handle language change during book search.  We find that a principled combination of three sources of evidence during relevance feedback yields strong CTIR performance.",
    "title": "Query Representation for Cross-Temporal Information Retrieval",
    "authors": [
      {
        "affiliation": "University of Illinois",
        "location": "Champaign, IL, USA",
        "name": "Miles Efron",
        "email": "mefron@illinois.edu"
      }
    ]
  },
"r4b01": {
    "abstract": "The reliability of a test collection is proportional to the number of queries it contains. But building a collection with many queries is expensive, so researchers have to find a balance between reliability and cost. Previous work on the measurement of test collection reliability relied on data-based approaches that contemplated random what if scenarios, and provided indicators such as swap rates and Kendall tau correlations. Generalizability Theory was proposed as an alternative founded on analysis of variance that provides reliability indicators based on statistical theory. However, these reliability indicators are hard to interpret in practice, because they do not correspond to well known indicators like Kendall tau correlation. We empirically established these relationships based on data from over 40 TREC collections, thus filling the gap in the practical interpretation of Generalizability Theory. We also review the computation of these indicators, and show that they are extremely dependent on the sample of systems and queries used, so much that the required number of queries to achieve a certain level of reliability can vary in orders of magnitude. We discuss the computation of confidence intervals for these statistics, providing a much more reliable tool to measure test collection reliability. Reflecting upon all these results, we review a wealth of TREC test collections, arguing that they are possibly not as reliable as generally accepted and that the common choice of 50 queries is insufficient even for stable rankings.",
    "title": "On the Measurement of Test Collection Reliability",
    "authors": [
      {
        "affiliation": "University Carlos III of Madrid",
        "location": "Leganés, Spain",
        "name": "Julián Urbano",
        "email": "jurbano@inf.uc3m.es"
      },
      {
        "affiliation": "University Carlos III of Madrid",
        "location": "Leganés, Spain",
        "name": "Mónica Marrero",
        "email": "mmarrero@inf.uc3m.es"
      },
      {
        "affiliation": "University Carlos III of Madrid",
        "location": "Leganés, Spain",
        "name": "Diego Martín",
        "email": "dmartin@dit.upm.es"
      }
    ]
  },
"r4b02": {
    "abstract": "We evaluate statistical inference procedures for small-scale IR experiments that involve multiple comparisons against the baseline. These procedures adjust for multiple comparisons by ensuring that the probability of observing at least one false positive in the experiment is below a given threshold. We use only publicly available test collections and make our software available for download. In particular, we employ the TREC runs and runs constructed from the Microsoft learning-to-rank (MSLR) data set. Our focus is on non-parametric statistical procedures that include the Holm-Bonferroni adjustment of the permutation test p-values, the MaxT permutation test, and the permutation-based closed testing. In TREC-based simulations, these procedures retain from 66% to 92% of individually significant results (i.e., those obtained without taking other comparisons into account). Similar retention rates are observed in the MSLR simulations. For the largest evaluated query set size (i.e., 6400), procedures that adjust for multiplicity find at most 5% fewer true differences compared to unadjusted tests. At the same time, unadjusted tests produce many more false positives.",
    "title": "Deciding on an Adjustment for Multiplicity in IR Experiments",
    "authors": [
      {
        "affiliation": "Carnegie Mellon University",
        "location": "Pittsburgh, PA, USA",
        "name": "Leonid Boytsov",
        "email": "leo@boytsov.info"
      },
      {
        "affiliation": "Abt Associates Inc",
        "location": "Bethesda, MD, USA",
        "name": "Anna Belova",
        "email": "anna@belova.org"
      },
      {
        "affiliation": "Texas Tech University",
        "location": "Lubbock, TX, USA",
        "name": "Peter Westfall",
        "email": "peter.westfall@ttu.edu"
      }
    ]
  },
"r4b03": {
    "abstract": "Novel and diverse document ranking is an effective strategy that involves reducing redundancy in a ranked list to maximize the amount of novel and relevant information available to users. Evaluation for novelty and diversity typically involves an assessor judging each document for relevance against a set of pre-identified subtopics, which may be disambiguations of the query, facets of an information need, or nuggets of information. Alternately, when expressing a preference for document A or document B, users may implicitly take subtopics into account, but may also take into account other factors such as recency, readability, length, and so on, each of which may have more or less importance depending on user. A user profile contains information about the extent to which each factor, including subtopic relevance, plays a role in the user's preference for one document over another. A preference-based evaluation can then take this user profile information into account to better model utility to the space of users. In this work, we propose an evaluation framework that not only can consider implicit factors but also handles differences in user preference due to varying underlying information need. Our proposed framework is based on the idea that a user scanning a ranked list from top to bottom and stopping at rank $k$ gains some utility from every document that is relevant  their information need. Thus, we model the expected utility of a ranked list by estimating the utility of a document at a given rank using preference judgments and define evaluation measures based on the same. We validate our framework by comparing it to existing measures such as alpha-nDCG, ERR-IA, and subtopic recall that require explicit subtopic judgments We show that our proposed measures correlate well with existing measures while having the potential to capture various other factors when real data is used. We also show that the proposed measures can easily handle relevance assessments against multiple user profiles, and that they are robust to noisy and incomplete judgments.",
    "title": "Preference Based Evaluation Measures for Novelty and Diversity",
    "authors": [
      {
        "affiliation": "University of Delaware",
        "location": "Newark, DE, USA",
        "name": "Praveen Chandar",
        "email": "pcr@udel.edu"
      },
      {
        "affiliation": "University of Delaware",
        "location": "Newark, DE, USA",
        "name": "Ben Carterette",
        "email": "carteret@cis.udel.edu"
      }
    ]
  },
"r4c01": {
    "abstract": "Singing is a popular social activity and a good way of expressing one's feelings. One important reason for unsuccessful singing performance is because the singer fails to choose a suitable song. In this paper, we propose a novel singing competence-based song recommendation framework. It is distinguished from most existing music recommendation systems which rely on the computation of listeners' interests or similarity. We model a singer's vocal competence as singer profile, which takes voice pitch, intensity, and quality into consideration. Then we propose techniques to acquire singer profiles. We also present a song profile model which is used to construct a human annotated song database. Finally, we propose a learning-to-rank scheme for recommending songs by singer profile. The experimental study on real singers demonstrates the effectiveness of our approach and its advantages over two baseline methods. To the best of our knowledge, our work is the first to study competence-based song recommendation.",
    "title": "Competence-Based Song Recommendation",
    "authors": [
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Lidan Shou",
        "email": "should@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Kuang Mao",
        "email": ""
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Xinyuan Luo",
        "email": ""
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Ke Chen",
        "email": "chenk@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Gang Chen",
        "email": "cg@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Tianlei Hu",
        "email": "htl@zju.edu.cn"
      }
    ]
  },
"r4c02": {
    "abstract": "Cross-modal retrieval is a classic research topic in multimedia information retrieval. The traditional approaches study the problem as a pairwise similarity function problem. In this paper, we consider this problem from a new perspective as a listwise ranking problem and propose a general cross-modal ranking algorithm to optimize the listwise ranking loss with a low rank embedding, which we call Latent Semantic Cross-Modal Ranking (LSCMR). The latent low-rank embedding space is discriminatively learned by structural large margin learning to optimize for certain ranking criteria directly. We evaluate LSCMR on the Wikipedia and NUS-WIDE dataset. Experimental results show that this method obtains significant improvements over the state-of-the-art methods.",
    "title": "A Low Rank Structural Large Margin Method for Cross-Modal Ranking",
    "authors": [
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Xinyan Lu",
        "email": "xinyanlu@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Fei Wu",
        "email": "wufei@cs.zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Siliang Tang ",
        "email": "siliang@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Zhongfei Zhang",
        "email": "zhongfei@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Xiaofei He",
        "email": "xiaofeihe@cad.zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Yueting Zhuang ",
        "email": "yzhuang@zju.edu.cn"
      }
    ]
  },
"r4c03": {
    "abstract": "Automated face annotation aims to automatically detect human faces from a photo and further name the faces with the corresponding human names. In this paper, we tackle this open problem by investigating a search-based face annotation (SBFA) paradigm for mining large amounts of web facial images freely available on the WWW. Given a query facial image for annotation, the idea of SBFA is to first search for top-$n$ similar facial images from a web facial image database and then exploit these top-ranked similar facial images and their weak labels for naming the query facial image. To fully mine those information, this paper proposes a novel framework of Learning to Name Faces (L2NF) -- a unified multimodal learning approach for search-based face annotation, which consists of the following major components: (i) we enhance the weak labels of top-ranked similar images by exploiting the label smoothness assumption; (ii) we construct the multimodal representations of a facial image by extracting different types of features; (iii) we optimize the distance measure for each type of features using distance metric learning techniques; and finally (iv) we learn the optimal combination of multiple modalities for annotation through a \emph{learning to rank} scheme. We conduct a set of extensive empirical studies on two real-world facial image databases, in which encouraging results show that the proposed algorithms significantly boost the naming accuracy of search-based face annotation task.",
    "title": "Learning to Name Faces: A Multimodal Learning Scheme for Search-Based Face Annotation",
    "authors": [
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Dayong Wang",
        "email": "s090023@ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Steven C.H. Hoi",
        "email": "chhoi@ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Pengcheng Wu",
        "email": "wupe0003@ntu.edu.sg"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Jianke Zhu",
        "email": "jkzhu@zju.edu.cn"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Ying He",
        "email": "yhe@ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Chunyan Miao",
        "email": "ascymiao@ntu.edu.sg"
      }
    ]
  },
  "i101": {
    "abstract": "It's the classic innovators dilemma: companies have built empires on the web of yesterday, matching keywords to ads and providing organic results. The challenge to which search companies must adapt is the makeup of the changing web  aspects relating to social, multimedia, device input, and geospatial  and how both IR models and the financial models that enable them must undergo a revolution. What will it take to reboot consumers' expectations and demands of search and what are some roads the industry must take to get there?",
    "title": "Industry Keynote 1: Web of Confusion",
    "authors": [
      {
        "affiliation": "Bing Search, Microsoft Corporation",
        "location": "Seattle, WA, USA",
        "name": "Stefan Weitz",
        "email": ""
      }
    ]
  },
  "i102": {
    "abstract": "A good search engine is one when users come very regularly, type their queries, get their results, and leave quickly. With user engagement metrics from web analytics, these translate to a low dwell time, often low CTR, but a very high return rate. But user engagement is not just about this. User engagement is a multifaceted, complex phenomenon, giving rise to a number of approaches for its measurement: self-reporting (e.g. questionnaires); observational methods (e.g., facial expression analysis, desktop actions); and of course web analytics using online behavior metrics. These methods represent various trade-offs between the scale of the data analyzed and the depth of understanding. For instance, surveys are hardly scalable but offer rich, qualitative insights, whereas click data can be collected on a large-scale but are more difficult to analyze. This talk will present various efforts aiming at combining approaches to measure engagement and seeking to provide insights into what makes an engaging experience. The talk will focus of what makes users click or not click, and what this means in terms of user engagement. This is joint work mainly with Mounia Lalmas and Janette Lehmann.",
    "title": "Industry Keynote 2: An Engaging Click",
    "authors": [
      {
        "affiliation": "Yahoo! Research Europe & Latin America",
        "location": "Barcelona, Spain",
        "name": "Ricardo Baeza-Yates",
        "email": "rbaeza@acm.org"
      }
    ]
  },
  "i201": {
    "abstract": "LinkedIn has a unique data collection: the 200M+ members who use LinkedIn are also the most valuable entities in our corpus, which consists of people, companies, jobs, and a rich content ecosystem. Our members use LinkedIn to satisfy a diverse set of navigational and exploratory information needs, which we address by leveraging semi-structured and social content to understanding their query intent and deliver a personalized search experience. In this talk, we will discuss some of the unique challenges we face in building the LinkedIn search platform, the solutions we've developed so far, and the open problems we see ahead of us.",
    "title": "Find and be Found: Information Retrieval at LinkedIn",
    "authors": [
      {
        "affiliation": "Linked In",
        "location": "",
        "name": "Shakti Sinha",
        "email": ""
      },
      {
        "affiliation": "Linked In",
        "location": "",
        "name": "Daniel Tunkelang",
        "email": ""
      }
    ]
  },
  "i202": {
    "abstract": "There is a clash between openly available Web information and information secured inside Apps. The problem of siloed information, well known from the world of database, poses similar problems for Enteprise Search engines. In this talk, we will discuss some of the problems we have encountered trying to bridge these information sources, what works, and what remains to be done.",
    "title": "Current and Future Needs for Commercial Search Engines",
    "authors": [
      {
        "affiliation": "Exalead, Dassault Systèmes",
        "location": "",
        "name": "Gregory Grefenstette",
        "email": ""
      }
    ]
  },
  "i203": {
    "abstract": "Changes in the US Federal Rules of Civil Procedure in December 2006 led to an explosion in electronic discovery (e-discovery): the finding of electronically stored information to be turned over to parties in legal cases. Traditional manual review approaches (rooms full of low paid lawyers and paralegals reading documents one at a time) have collapsed under this burden, spawning a multi-billion dollar e-discovery software and services industry. Information retrieval technology, particularly supervised machine learning for text classification (referred to as predictive coding in e-discovery), plays a pivotal role. I will review the major technological and process challenges in e-discovery, the ways in which information retrieval has been brought to bear on these challenges, and results from benchmarking efforts (in particular the NIST TREC Legal Track) in this area. I will also briefly discuss open information research questions whose solutions might have a substantial impact on e-discovery practice.",
    "title": "Information Retrieval for Electronic Discovery in Legal Cases",
    "authors": [
      {
        "affiliation": "David D. Lewis Consulting",
        "location": "Chicago, IL, USA",
        "name": "Dave Lewis",
        "email": "dacelewis@daviddlewis.com"
      }
    ]
  },
  "i301": {
    "abstract": "With the massive amount of data being generated by social media networks like Twitter, organizations are exploring new and impactful ways to use the information. In this session, you'll hear from Rod Smith, IBM Fellow and Vice President of IBM's Emerging Internet Technologies group, and learn how IBM has been working on big data analytic projects that can benefit the public. Rod will discuss various solutions his group has created which analyze social media in various ways, ranging from helping disaster relief workers identify the areas most affected and route emergency supplies to those areas, to helping police departments identify potential crimes before they happen. Rod will also discuss how analytics can be used to find value and insight in big data and share lessons his team has learned while building first-of-a-kind solutions around big data analytics.",
    "title": "From Pre-Crime to Disaster Relief: Discovering the Power of Social Media Analytics",
    "authors": [
      {
        "affiliation": "IBM",
        "location": "",
        "name": "Rod Smith",
        "email": ""
      }
    ]
  },
  "i302": {
    "abstract": "The web provides an unprecedented opportunity to accelerate innovation by evaluating ideas quickly and accurately using controlled experiments (e.g., A/B tests and their generalizations). From front-end user-interface changes to backend algorithms, online controlled experiments are now utilized to make data-driven decisions at Amazon, eBay, Facebook, Google, Intuit, LinkedIn, Microsoft, Netflix, Yahoo, Zynga, and at many other companies. While the theory of a controlled experiment is simple, and dates back to Sir Ronald A. Fisher's experiments at the Rothamsted Agricultural Experimental Station in England in the 1920s, and to Gosset's t-test at Guinness in Dublin Ireland (where SIGIR this year is held), running online controlled experiments at scalehundreds of concurrent experiments on a given day at Bing---has taught us many lessons. We provide an introduction, share real examples, key insights, cultural challenges, scaling challenges, and humbling statistics.",
    "title": "Online Controlled Experiments: Introduction, Insights, Scaling and Humbling Statistics",
    "authors": [
      {
        "affiliation": "Microsoft",
        "location": "",
        "name": "Ronny Kohavi",
        "email": ""
      }
    ]
  },
  "i401": {
    "abstract": "Apache Lucene and Solr are the most widely deployed search technology on the planet, powering sites like Twitter, Wikipedia, Zappos and countless applications across a large array of domains. They are also free, open source, extensible and extremely scalable. Lucene and Solr also contain a large number of features for solving common information retrieval problems ranging from pluggable posting list compression and scoring algorithms to faceting and spell checking. Increasingly, Lucene and Solr also are being (ab)used to power applications going way beyond the search box. In this talk, we'll explore the features and capabilities of Lucene and Solr 4.x, as well as look at how to (ab)use your search engine technology for fun and profit.",
    "title": "Open Source Search FTW!",
    "authors": [
      {
        "affiliation": "LucidWorks",
        "location": "",
        "name": "Grant Ingersoll",
        "email": ""
      }
    ]
  },
  "i402": {
    "abstract": "Five years ago Fast Search and Transfer (FAST), one of the leading enterprise search providers, was acquired by Microsoft. During the years before and continuing after the acquisition, the team has done extensive research and development to combine database technologies with search engines. The work has been done both internally in FAST and as part of the research programs like Pharos and iAD and in collaboration with several universities. This effort has been driven by requirements from customers wanting consistency, flexibility, extensibility, extreme scale and a wide span of other novel features without compromising the usual treats of search engines like query speed, scalability, ad-hoc query capability and relevancy ordering. The talk will cover how the team brought database logs, transactional consistency, column stores and a relational query engine into a search engine. The presentation will also discuss how these mechanisms enabled real-time indexing, a flexible relevancy model, distributed joins and an extensible evaluation engine that powers both content processing, query processing and query evaluation. We will in addition include a section on how it is possible to index both unstructured, semi-structured and structured data in the same index without predefining a schema and still provide efficient and flexible query capabilities.",
    "title": "Uniting Enterprise Search with Database Technology",
    "authors": [
      {
        "affiliation": "Microsoft Development Center Norway",
        "location": "Norway",
        "name": "Øystein Torbjørnsen",
        "email": ""
      }
    ]
  },
  "i403": {
    "abstract": "Websays strives to provide the best possible analysis of online conversation to marketing and social media analysts. One of the obsessions of Websays is to provide near-man-made data quality at marginal costs. I will discuss how we approach this problem using innovative machine learning and UI approaches.",
    "title": "Some of the Problems and Applications of Opinion Analysis",
    "authors": [
      {
        "affiliation": "Websays",
        "location": "",
        "name": "Hugo Zaragoza",
        "email": ""
      }
    ]
  },
  "r5a01": {
    "abstract": "Session search is the Information Retrieval (IR) task that performs document retrieval for a search session. During a session, a user constantly modifies queries in order to find relevant documents that fulfill the information need. This paper proposes a novel query change retrieval model (QCM), which utilizes syntactic editing changes between adjacent queries as well as the relationship between query change and previously retrieved documents to enhance session search. We propose to model session search as a Markov Decision Process (MDP). We consider two agents in this MDP: the user agent and the search engine agent. The user agent's actions are query changes that we observe and the search agent's  actions are proposed in this paper. Experiments show that our approach is highly effective and outperforms top session search systems in TREC 2011 and 2012.",
    "title": "Utilizing Query Change for Session Search",
    "authors": [
      {
        "affiliation": "Georgetown University",
        "location": "Washington, DC, USA",
        "name": "Dongyi Guan",
        "email": "dg372@georgetown.edu"
      },
      {
        "affiliation": "Georgetown University",
        "location": "Washington, DC, USA",
        "name": "Sicong Zhang",
        "email": "sz303@georgetown.edu"
      },
      {
        "affiliation": "Georgetown University",
        "location": "Washington, DC, USA",
        "name": "Hui Yang",
        "email": "huiyang@cs.georgetown.edu"
      }
    ]
  },
  "r5a02": {
    "abstract": "Current research on web search has focused on optimizing and evaluating single queries. However, a significant fraction of user queries are part of more complex tasks which span multiple queries across one or more search sessions. An ideal search engine would not only retrieve relevant results for a user's particular query but also be able to identify when the user is engaged in a more complex task and aid the user in completing that task. Toward optimizing whole-session or task relevance, we characterize and address the problem of intrinsic diversity (ID) in retrieval, a type of complex task that requires multiple interactions with current search engines.  Unlike existing work on extrinsic diversity rad:09 that deals with ambiguity in intent across multiple users, ID queries often have little ambiguity in intent but seek content covering a variety of aspects on a shared theme.  In such scenarios, the underlying needs are typically exploratory, comparative, or breadth-oriented in nature. We identify and address three key problems for ID retrieval: identifying authentic examples of ID tasks from post-hoc analysis of behavioral signals in search logs; learning to identify initiator queries that mark the start of an ID search task; and given an initiator query, predicting which content to prefetch and rank.",
    "title": "Toward Whole-Session Relevance: Exploring Intrinsic Diversity in Web Search",
    "authors": [
      {
        "affiliation": "Cornell University",
        "location": "Ithaca, NY, USA",
        "name": "Karthik Raman",
        "email": "karthik@cs.cornell.edu"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Paul N Bennett",
        "email": "pauben@microsoft.com"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Kevyn Collins-Thompson",
        "email": "kevynct@microsoft.com"
      }
    ]
  },
  "r5a03": {
    "abstract": "We introduce a general information access evaluation framework that can potentially handle summaries, ranked document lists and even multi-query sessions seamlessly. Our framework first builds a trailtext which represents a concatenation of all the texts read by the user during a search session, and then computes an evaluation metric called U-measure over the trailtext. Instead of discounting the value of a retrieved piece of information based on ranks, U-measure discounts it based on its  position within the trailtext. U-measure takes the document length into account just like Time-Biased Gain (TBG), and has the diminishing return property. It is therefore more realistic than rank-based metrics. Furthermore, it is arguably more flexible than TBG, as it is free from the linear traversal assumption (i.e., that the user scans the ranked list from top to bottom), and can handle information access tasks other than ad hoc retrieval. This paper demonstrates the validity and versatility of the U-measure framework. Our main conclusions are: (a) For ad hoc retrieval, U-measure is at least as reliable as TBG in terms of rank correlations with traditional metrics and discriminative power; (b) For diversified search, our diversity versions of U-measure are highly correlated with state-of-the-art diversity metrics; (c) For multi-query sessions, U-measure is highly correlated with Session nDCG; and (d) Unlike rank-based metrics such as DCG, U-measure can quantify the differences between linear and nonlinear traversals in sessions. We argue that our new framework is useful for understanding the user's search behaviour and for comparison across different information access styles (e.g. examining a direct answer vs. examining a ranked list of web pages).",
    "title": "Summaries, Ranked Retrieval and Sessions: A Unified Framework for Information Access Evaluation",
    "authors": [
      {
        "affiliation": "MSRA",
        "location": "Beijing, China",
        "name": "Tetsuya Sakai",
        "email": "tetsuyasakai@acm.org"
      },
      {
        "affiliation": "MSRA",
        "location": "Beijing, China",
        "name": "Zhicheng Dou",
        "email": "zhichdou@microsoft.com"
      }
    ]
  },
  "r5b01": {
    "abstract": "Statistical translation models and latent semantic analysis (LSA) are two effective approaches to exploiting click-through data for Web search ranking. While the former learns semantic relationships between query terms and document terms directly, the latter maps a document and the queries for which it has been clicked to vectors in a lower dimensional semantic space. This paper presents two document ranking models that combine the strengths of both the approaches by explicitly modeling word-pairs. The first model, called PairModel, is a monolingual ranking model based on word-pairs derived from click-through data. It maps queries and documents into a concept space spanned by these word-pairs. The second model, called Bilingual Paired Topic Model (BPTM), uses bilingual word translations and can jointly model query-document collections written in multiple languages. This model uses topics to capture term dependencies and maps queries and documents in multiple languages into a lower dimensional semantic sub-space spanned by the topics. These models are evaluated on the Web search task using real world data sets in three different languages. Results show that they consistently outperform various state-of-the-art baseline models, and the best result is obtained by interpolating PairModel and BPTM.",
    "title": "Modeling Click-through Based Word-pairs for Web Search",
    "authors": [
      {
        "affiliation": "University of Maryland",
        "location": "College Park, MD, USA",
        "name": "Jagadeesh Jagarlamudi",
        "email": "jags@umiacs.umd.edu"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Jianfeng Gao",
        "email": "jfgao@microsoft.com"
      }
    ]
  },
  "r5b02": {
    "abstract": "In recent years many models have been proposed that are aimed at predicting clicks of web search users. In addition, some information retrieval evaluation metrics have been built on top of a user model. In this paper we bring these two directions together and propose a common approach to converting any click model into an evaluation metric. We then put the resulting model-based metrics as well as traditional metrics (like DCG or Precision) into a common evaluation framework and compare them along a number of dimensions. One of the dimensions we are particularly interested in is the agreement between offline and online experimental outcomes. It is widely believed, especially in an industrial setting, that online A/B-testing and interleaving experiments are generally better at capturing system quality than offline measurements. We show that offline metrics that are based on click models are more strongly correlated with online experimental outcomes than traditional offline metrics, especially in situations when we have incomplete relevance judgements.",
    "title": "Click Model-Based Information Retrieval Metrics",
    "authors": [
      {
        "affiliation": "Yandex & ISLA, University of Amsterdam",
        "location": "Moscow, Russia",
        "name": "Aleksandr Chuklin",
        "email": "A.Chuklin@uva.nl"
      },
      {
        "affiliation": "Yandex",
        "location": "Moscow, Russia",
        "name": "Pavel Serdyukov",
        "email": "pavser@yandex-team.ru"
      },
      {
        "affiliation": "ISLA, University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Maarten de Rijke",
        "email": "deRijke@uva.nl"
      }
    ]
  },
  "r5b03": {
    "abstract": "In modern search engines, an increasing number of search result pages (SERPs) are federated from multiple specialized search engines (called verticals, such as Image or Video). As an effective approach to interpret users click-through behavior as feedback information, most click models were designed to reduce the position bias and improve ranking performance of ordinary search results, which have homogeneous appearances. However, when vertical results are combined with ordinary ones, significant differences in presentation may lead to user behavior biases and thus failure of state-of-the-art click models. With the help of a popular commercial search engine in China, we collected a large scale log data set which contains behavior information on both vertical and ordinary results. We also performed eye-tracking analysis to study users real-world examining behavior. According these analysis, we found that different result appearances may cause different behavior biases both for vertical results (local effect) and for the whole result lists (global effect). These biases include: examine bias for vertical results (especially those with multimedia components), trust bias for result lists with vertical results, and a higher probability of result revisitation for vertical results. Based on these findings, a novel click model considering these biases besides position bias was constructed to describe interaction with SERPs containing verticals. Experimental results show that the new Vertical-aware Click Model (VCM) is better at interpreting user click behavior on federated searches in terms of both log-likelihood and perplexity than existing models.",
    "title": "Incorporating Vertical Results into Search Click Models",
    "authors": [
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": "Chao Wang",
        "email": "chaowang0707@gmail.com"
      },
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": "Yiqun Liu",
        "email": "yiqunliu@tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": "Min Zhang",
        "email": "z-m@tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": "Shaoping Ma",
        "email": "msp@tsinghua.edu.cn"
      },
      {
        "affiliation": "Department of Psychology, Tsinghua University",
        "location": "Beijing, China",
        "name": "Meihong Zheng",
        "email": "zhengmh@mail.tsinghua.edu.cn"
      },
      {
        "affiliation": "Department of Psychology, Tsinghua University",
        "location": "Beijing, China",
        "name": "Jing Qian",
        "email": "jqian@mail.tsinghua.edu.cn"
      },
      {
        "affiliation": "Tsinghua National Laboratory for Information Science and Technology",
        "location": "Beijing, China",
        "name": "Kuo Zhang",
        "email": "zhangkuo@sogou-inc.com"
      }
    ]
  },
  "r6a01": {
    "abstract": "We focus on the problem of selecting meaningful tweets given a user's interests; the dynamic nature of user interests, the sheer volume, and the sparseness of individual messages make this an challenging problem. Specifically, we consider the task of time-aware tweets summarization, based on a user's history and collaborative social influences from ``social circles.''  We propose a time-aware user behavior model, the Tweet Propagation Model (TPM), in which we infer dynamic probabilistic distributions over interests and topics. We then explicitly consider novelty, coverage, and diversity to arrive at an iterative optimization algorithm for selecting tweets.  Experimental results validate the effectiveness of our personalized time-aware tweets summarization method based on TPM.",
    "title": "Personalized Time-Aware Tweets Summarization",
    "authors": [
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Zhaochun Ren",
        "email": "z.ren@uva.nl"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Shangsong Liang",
        "email": "s.liang@uva.nl"
      },
      {
        "affiliation": "Yahoo! Research",
        "location": "Barcelona, Spain",
        "name": "Edgar Meij",
        "email": "emeij@yahoo-inc.com"
      },
      {
        "affiliation": "University of Amsterdam",
        "location": "Amsterdam, Netherlands",
        "name": "Maarten de Rijke",
        "email": "derijke@uva.nl"
      }
    ]
  },
  "r6a02": {
    "abstract": "Twitter has attracted hundred millions of users to share and disseminate most up-to-date information. However, the noisy and short nature of tweets makes many applications in information retrieval (IR) and natural language processing (NLP) challenging. Recently, segment-based tweet representation has demonstrated effectiveness in named entity recognition (NER) and event detection from tweet streams. To split tweets into meaningful phrases or segments, the previous work is purely based on external knowledge bases, which ignores the rich local context information embedded in the tweets. In this paper, we propose a novel framework for tweet segmentation in a batch mode, called HybridSeg. HybridSeg incorporates local context knowledge with global knowledge bases for better tweet segmentation. HybridSeg consists of two steps: learning from off-the-shelf weak NERs and learning from pseudo feedback. In the first step, the existing NER tools are applied to a batch of tweets. The named entities recognized by these NERs are then employed to guide the tweet segmentation process. In the second step, HybridSeg adjusts the tweet segmentation results iteratively by exploiting all segments in the batch of tweets in a collective manner. Experiments on two tweet datasets show that HybridSeg significantly improves tweet segmentation quality compared with the state-of-the-art algorithm. We also conduct a case study by using tweet segments for the task of named entity recognition from tweets. The experimental results demonstrate that HybridSeg significantly benefits the downstream applications.",
    "title": "Exploiting Hybrid Contexts for Tweet Segmentation",
    "authors": [
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Chenliang Li",
        "email": "lich0020@ntu.edu.sg"
      },
      {
        "affiliation": "Nanyang Technological University",
        "location": "Singapore, Singapore",
        "name": "Aixin Sun",
        "email": "axsun@ntu.edu.sg"
      },
      {
        "affiliation": "Independent Researcher",
        "location": "Singapore, Singapore",
        "name": " Jianshu Weng ",
        "email": "jianshu@acm.org"
      },
      {
        "affiliation": "IBM Almaden Research Center",
        "location": "heq@us.ibm.com",
        "name": "Qi He",
        "email": "San Jose, USA"
      }
    ]
  },
  "r6a03": {
    "abstract": "With the explosive growth of microblogging services, short-text messages (also known as tweets) are being created and shared at an unprecedented rate. Tweets in its raw form can be incredibly informative, but also overwhelming. For both end-users and data analysts it is a nightmare to plow through millions of tweets which contain enormous noises and redundancies. In this paper, we study continuous tweet summarization as a solution to address this problem. While traditional document summarization methods focus on static and small-scale data, we aim to deal with dynamic, quickly arriving, and large-scale tweet streams. We propose a novel prototype called Sumblr (SUMmarization By stream cLusteRing) for tweet streams. We first propose an online tweet stream clustering algorithm to cluster tweets and maintain distilled statistics called Tweet Cluster Vectors. Then we develop a TCV-Rank summarization technique for generating online summaries and historical summaries of arbitrary time durations. Finally, we describe a topic evolvement detection method, which consumes online and historical summaries to produce timelines automatically from tweet streams. Our experiments on large-scale real tweets demonstrate the efficiency and effectiveness of our approach.",
    "title": "Sumblr: Continuous Summarization of Evolving Tweet Streams",
    "authors": [
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Lidan Shou",
        "email": "should@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Zhenhua Wang",
        "email": "wzh-cs@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Ke Chen",
        "email": "chenk@zju.edu.cn"
      },
      {
        "affiliation": "Zhejiang University",
        "location": "Hangzhou, China",
        "name": "Gang Chen",
        "email": "cg@zju.edu.cn"
      }
    ]
  },
  "r6a04": {
    "abstract": "Collaborative web sites, such as collaborative encyclopedias, blogs, and forums, are characterized by a loose edit control, which allows anyone to freely edit their content. As a consequence, the quality of this content raises much concern. To deal with this, many sites adopt manual quality control mechanisms. However, given their size and change rate, manual assessment strategies do not scale and content that is new or unpopular is seldom reviewed. This has a negative impact on the many services provided, such as ranking and recommendation. To tackle with this problem, we propose a learning to rank (L2R) approach for ranking answers in Q&A forums. In particular, we adopt an approach based on Random Forests and represent query and answer pairs using eight different groups of features. Some of these features are used in the Q&A domain for the first time. Our L2R method was trained to learn the answer rating, based on the feedback users give to answers in Q&A forums. Using the proposed method, we were able (i) to outperform a state of the art baseline with gains of up to 21% in NDCG, a metric used to evaluate rankings; we also conducted a comprehensive study of the features, showing that (ii) review and user features are the most important in the Q&A domain although text features are useful for assessing quality of new answers; and (iii) the best set of new features we proposed was able to yield the best quality rankings.",
    "title": "Exploiting User Feedback to Learn to Rank Answers in Q & A Forums: a Case Study with Stackoverflow",
    "authors": [
      {
        "affiliation": "Universidade Federal de Minas Gerais",
        "location": "Belo Horizonte, Brazil",
        "name": "Daniel Hasan Dalip",
        "email": "hasan@dcc.ufmg.br"
      },
      {
        "affiliation": "Universidade Federal de Minas Gerais",
        "location": "Belo Horizonte, Brazil",
        "name": "Marcos André Gonçalves",
        "email": "mgoncalv@dcc.ufmg.br"
      },
      {
        "affiliation": "Institute of Computing",
        "location": "Manaus, Brazil",
        "name": "Marco Cristo",
        "email": "marco.cristo@ic.ufam.edu.br"
      },
      {
        "affiliation": "Instituto Superior Técnico/ INESC-ID",
        "location": "Porto Salvo, Portugal",
        "name": "Pavel Calado",
        "email": "pavel.calado@tagus.ist.utl.pt"
      }
    ]
  },
  "r6b01": {
    "abstract": "Pseudo-relevance feedback is an important strategy to improve search accuracy. It is often implemented as a two-round retrieval process: the first round is to retrieve an initial set of documents relevant to an original query, and the second round is to retrieve final retrieval results using the original query expanded with terms selected from the previously retrieved documents. This two-round retrieval process is clearly time consuming, which could arguably be one of main reasons that hinder the wide adaptation of the pseudo-relevance feedback methods in real-world IR systems. In this paper, we study how to improve the efficiency of pseudo-relevance feedback methods. The basic idea is to reduce the time needed for the second round of retrieval by leveraging the query processing results of the first round. Specifically, instead of processing the expand query as a newly submitted query, we propose an incremental approach, which resumes  the query processing results (i.e. document accumulators) for the first round of retrieval and process the second round of retrieval mainly as a step of adjusting the scores in the accumulators. Experimental results on TREC Terabyte collections show that the proposed incremental approach can improve the efficiency of pseudo-relevance feedback methods by a factor of two without sacrificing their effectiveness.",
    "title": "An Incremental Approach to Efficient Pseudo Relevance Feedback",
    "authors": [
      {
        "affiliation": "University of Delaware",
        "location": "Newark, DE, USA",
        "name": "Hao Wu",
        "email": "haow@udel.edu"
      },
      {
        "affiliation": "University of Delaware",
        "location": "Newark, DE, USA",
        "name": "Hui Fang",
        "email": "hfang@udel.edu"
      }
    ]
  },
  "r6b02": {
    "abstract": "This paper exploits Web search logs for query expansion (QE) by presenting a new QE method based on path-constrained random walks (PCRW), where the search logs are represented as a labeled, directed graph, and the probability of picking an expansion term for an input query is computed by a learned combination of constrained random walks on the graph. The method is shown to be generic in that it covers most of the popular QE models as special cases and flexible in that it provides a principled mathematical framework in which a wide variety of information useful for QE can be incorporated in a unified way. Evaluation is performed on the Web document ranking task using a real-world data set. Results show that the PCRW-based method is very effective for the expansion of rare queries, i.e., low-frequency queries that are unseen in search logs, and that it outperforms significantly other state-of-the-art QE meth-ods.",
    "title": "Query Expansion using Path-Constrained Random Walks",
    "authors": [
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Jianfeng Gao",
        "email": "jfgao@microsoft.com"
      },
      {
        "affiliation": "Microsoft",
        "location": "Bellevue, WA, USA",
        "name": "Gu Xu",
        "email": "guxu@microsoft.com"
      },
      {
        "affiliation": "Microsoft",
        "location": "Bellevue, WA, USA",
        "name": "Jinxi Xu",
        "email": "jinxixu@microsoft.com"
      }
    ]
  },
  "r6b03": {
    "abstract": "In recent years, a number of open databases have emerged on the Web, providing Web users with platforms to collaboratively create structured information. As these databases are intended to accommodate heterogeneous information and knowledge, they usually comprise a very large schema and billions of instances. Browsing and searching data on such a scale is not an easy task for a Web user. In this context, interactive query construction offers an intuitive interface for novice users to retrieve information from databases neither requiring any knowledge of structured query languages, nor any prior knowledge of the database schema. However, the existing mechanisms do not scale well on large scale datasets. This paper presents a set of techniques to boost the scalability of interactive query construction, from the perspective of both, user interaction cost and performance. We connect an abstract ontology layer to the database schema to shorten the process of user-computer interaction. We also introduce a search mechanism to enable efficient exploration of query interpretation spaces over large scale data. Extensive experiments show that our approach scales well on Freebase - an open database containing more than 7,000 relational tables in more than 100 domains.",
    "title": "Efficient Query Construction for Large Scale Data",
    "authors": [
      {
        "affiliation": "Leibniz Universität Hannover",
        "location": "Hannover, Germany",
        "name": "Elena Demidova",
        "email": "demidova@L3S.de"
      },
      {
        "affiliation": "Renmin University of China",
        "location": "Beijing, China",
        "name": "Xuan Zhou",
        "email": "zhou.xuan@outlook.com"
      },
      {
        "affiliation": "Leibniz Universität Hannover",
        "location": "Hannover, Germany",
        "name": "Wolfgang Nejdl ",
        "email": "nejdl@L3S.de"
      }
    ]
  },
  "r6b04": {
    "abstract": "Many recent and highly effective retrieval models for long queries use query reformulation methods that jointly optimize term weights and term selection. These methods learn using word context and global context but typically fail to capture query context. In this paper, we present a novel term ranking algorithm, PhRank, that extends work on Markov chain frameworks for query expansion to select compact and focused terms from within a query itself. This focuses queries so that one to five terms in an unweighted model achieve better retrieval effectiveness than weighted term selection models that use up to 30 terms. PhRank terms are also typically compact and contain 1-2 words compared to competing models that use query subsets up to 7 words long. PhRank captures query context with an affinity graph constructed using word co-occurrence in pseudo-relevant documents. A random walk of the graph is used for term ranking in combination with discrimination weights. Empirical evaluation using newswire and web collections demonstrates that performance of reformulated queries is significantly improved for long queries and at least as good for short, keyword queries compared to highly competitive information retrieval (IR) models.",
    "title": "Compact Query Term Selection Using Topically Related Text",
    "authors": [
      {
        "affiliation": "University of Edinburgh",
        "location": "Edinburgh, Scotland, UK",
        "name": "Tamsin Maxwell",
        "email": "t.maxwell@ed.ac.uk"
      },
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Bruce W. Croft",
        "email": "croft@cs.umass.edu"
      }
    ]
  },
  "r7a01": {
    "abstract": "Prior search result diversification work focuses on achieving topical variety in a ranked list, typically equally across all aspects. In this paper, we diversify with sentiments according to an explicit bias. We want to allow users to switch the result perspective to better grasp the polarity of opinionated content, such as during a literature review. For this, we first infer the prior sentiment bias inherent in a controversial topic -- the `Topic Sentiment'. Then, we utilize this information in 3 different ways to diversify results according to various sentiment biases: (1) Equal diversification to achieve a balanced and unbiased representation of all sentiments on the topic; (2) Diversification towards the Topic Sentiment, in which the actual sentiment bias in the topic is mirrored to emphasize the general perception of the topic; (3) Diversification against the Topic Sentiment, in which documents about the `minority' or outlying sentiment(s) are boosted and those with the popular sentiment are demoted. Since sentiment classification is an essential tool for this task, we experiment by gradually degrading the accuracy of a perfect classifier down to 40%, and show which diversification approaches prove most stable in this setting. The results reveal that the proportionality-based methods and our SCSF model, considering sentiment strength and frequency in the diversified list, yield the highest gains. Further, in case the Topic Sentiment cannot be reliably estimated, we show how performance is affected by equal diversification when actually an emphasis either towards or against the Topic Sentiment is desired: in the former case, an average of 6.48% is lost across all evaluation measures, whereas in the latter case this is 16.23%, confirming that bias-specific sentiment diversification is crucial.",
    "title": "Sentiment Diversification With Different Biases",
    "authors": [
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Elif Aktolga",
        "email": "elif@cs.umass.edu"
      },
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "James Allan",
        "email": "allan@cs.umass.edu"
      }
    ]
  },
  "r7a02": {
    "abstract": "Current approaches for search result diversification have been categorized as either implicit or explicit. The implicit approach assumes each document represents its own topic, and promotes diversity by selecting documents for different topics based on the difference of their vocabulary. On the other hand, the explicit approach models the set of query topics, or aspects. While the former approach is generally less effective, the latter usually depends on a manually created description of the query aspects, the automatic construction of which has proven difficult. This paper introduces a new approach: term-level diversification. Instead of modeling the set of query aspects, which are typically represented as coherent groups of terms, our approach uses terms without the grouping. Our results on the ClueWeb collection show that the grouping of topic terms provides very little benefit to diversification compared to simply using the terms themselves. Consequently, we demonstrate that term-level diversification, with topic terms identified automatically from the search results using a simple greedy algorithm, significantly outperforms methods that attempt to create a full topic structure for diversification.",
    "title": "Term Level Search Result Diversification",
    "authors": [
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Van Dang ",
        "email": "vdang@cs.umass.edu"
      },
      {
        "affiliation": "University of Massachusetts Amherst",
        "location": "Amherst, MA, USA",
        "name": "Bruce W Croft",
        "email": "croft@cs.umass.edu"
      }
    ]
  },
  "r7a03": {
    "abstract": "Prior research in resource selection for federated search mainly focused on selecting a small number of information sources that are most relevant to a user query. However, result novelty and diversification are largely unexplored, which does not reflect the various kinds of information needs of users in real world applications. This paper proposes two general approaches to model both result relevance and diversification in selecting sources, in order to provide more comprehensive coverage of multiple aspects of a user query. The first approach focuses on diversifying the document ranking on a centralized sample database before selecting information sources under the framework of Relevant Document Distribution Estimation (ReDDE). The second approach first evaluates the relevance of information sources with respect to each aspect of the query, and then ranks the sources based on the novelty and relevance that they offer. Both approaches can be applied with a wide range of existing resource selection algorithms such as ReDDE, CRCS, CORI and Big Document. Moreover, this paper proposes a learning based approach to combine multiple resource selection algorithms for result diversification, which can further improve the performance. We propose a set of new metrics for resource selection in federated search to evaluate the diversification performance of different approaches. To our best knowledge, this is the first piece of work that addresses the problem of search result diversification in federated search. The effectiveness of the proposed approaches has been demonstrated by an extensive set of experiments on the federated search testbed of the Clueweb dataset.",
    "title": "Search Result Diversification in Resource Selection for Federated Search",
    "authors": [
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA",
        "name": "Dzung Hong",
        "email": "dthong@cs.purdue.edu"
      },
      {
        "affiliation": "Purdue University",
        "location": "West Lafayette, IN, USA",
        "name": "Luo Si",
        "email": "lsi@cs.purdue.edu"
      }
    ]
  },
  "r7b01": {
    "abstract": "Human assessments of document relevance are needed for the construction of test collections, for ad-hoc evaluation, and for training text classifiers. Showing documents to assessors in different orderings, however, may lead to different assessment outcomes. We examine the effect that threshold priming, seeing varying degrees of relevant documents, has on people's calibration of relevance. Participants judged the relevance of a prologue of documents containing highly relevant, moderately relevant, or non-relevant documents, followed by a common epilogue of documents of mixed relevance. We observe that participants exposed to only non-relevant documents in the prologue assigned significantly higher average relevance scores to prologue and epilogue documents than participants exposed to moderately or highly relevant documents in the prologue. We also examine how need for cognition, an individual difference measure of the extent to which a person enjoys engaging in effortful cognitive activity, impacts relevance assessments. High need for cognition participants had a significantly higher level of agreement with expert assessors than low need for cognition participants did. Our findings indicate that assessors should be exposed to documents from multiple relevance levels early in the judging process, in order to calibrate their relevance thresholds in a balanced way, and that individual difference measures might be a useful way to screen assessors.",
    "title": "The Effect of Threshold Priming and Need for Cognition on Relevance Calibration and Assessment",
    "authors": [
      {
        "affiliation": "RMIT University",
        "location": "Melbourne, Australia",
        "name": "Falk Scholer",
        "email": "falk.scholer@rmit.edu.au"
      },
      {
        "affiliation": "University of North Carolina",
        "location": "Chapel Hill, NC, USA",
        "name": "Diane Kelly",
        "email": "dianek@email.unc.edu"
      },
      {
        "affiliation": "University of North Carolina",
        "location": "Chapel Hill, NC, USA",
        "name": "Wan-Ching Wu",
        "email": "wanchinw@live.unc.edu"
      },
      {
        "affiliation": "University of North Carolina",
        "location": "Chapel Hill, NC, USA",
        "name": "Hanseul S. Lee",
        "email": "hanseul@live.unc.edu"
      },
      {
        "affiliation": "University of Maryland",
        "location": "College Park, MD, USA",
        "name": "William Webber",
        "email": "wew@umd.edu"
      }
    ]
  },
  "r7b02": {
    "abstract": "Query suggestion or auto-completion mechanisms are widely used by search engines and are increasingly attracting interest from the research community. However, the lack of commonly accepted evaluation methodology and metrics means that it is not possible to compare results and approaches from the literature. Moreover, often the metrics used to evaluate query suggestions tend to be an adaptation from other domains without a proper justification. Hence, it is not necessarily clear if the improvements reported in the literature would result in an actual improvement in the users' experience. Inspired by the cascade user models and state-of-the-art evaluation metrics in the web search domain, we address the query suggestion evaluation, by first studying the users behaviour from a search engines query log and thereby deriving a new family of user models describing the users interaction with a query suggestion mechanism. Next, assuming a query log-based evaluation approach, we propose two new metrics to evaluate query suggestions, pSaved and eSaved. Both metrics are parameterised by a user model. pSaved is defined as the probability of using the query suggestions while submitting a query. eSaved equates to the expected relative amount of effort (keypresses) a user can avoid due to the deployed query suggestion mechanism. Finally, we experiment with both metrics using four user model instantiations as well as metrics previously used in the literature on a dataset of 6.1M sessions. Our results demonstrate that pSaved and eSaved show the best alignment with the users satisfaction amongst the considered metrics.",
    "title": "User model-based metrics for offline query suggestion evaluation",
    "authors": [
      {
        "affiliation": "Yandex & Glasgow University",
        "location": "Moscow, Russia",
        "name": "Eugene Kharitonov",
        "email": "eugene.kharitonov@gmail.com"
      },
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Craig Macdonald",
        "email": "Craig.Macdonald@glasgow.ac.uk"
      },
      {
        "affiliation": "Yandex",
        "location": "Moscow, Russia",
        "name": "Pavel Serdyukov",
        "email": "pavser@yandex-team.ru"
      },
      {
        "affiliation": "University of Glasgow",
        "location": "Glasgow, Scotland, UK",
        "name": "Iadh Ounis",
        "email": "Iadh.Ounis@glasgow.ac.uk"
      }
    ]
  },
  "r7b03": {
    "abstract": "A number of key Information Access tasks -- Document Retrieval, Clustering, Filtering, and their combinations -- can be seen as instances of a generic document organization problem that establishes priority and relatedness relationships between documents (in other words, a problem of forming and ranking clusters). As far as we know, no analysis has been made yet on the evaluation of these tasks from a global perspective. In this paper we propose two complementary evaluation measures -- Reliability and Sensitivity -- for the generic Document Organization task which are derived from a proposed set of formal constraints (properties that any suitable measure must satisfy). In addition to be the first measures that can be applied to any mixture of ranking, clustering and filtering tasks, Reliability and Sensitivity satisfy more formal constraints than previously existing evaluation metrics for each of the subsumed tasks. Besides their formal properties, its most salient feature from an empirical point of view is their strictness: a high score according to the harmonic mean of Reliability and Sensitivity ensures a high score with any of the most popular evaluation metrics in all the Document Retrieval, Clustering and Filtering datasets used in our experiments.",
    "title": "A General Evaluation Measure for Document Organization Tasks",
    "authors": [
      {
        "affiliation": "UNED",
        "location": "Madrid, Spain",
        "name": "Enrique Amigó",
        "email": "enrique@lsi.uned.es"
      },
      {
        "affiliation": "UNED",
        "location": "Madrid, Spain",
        "name": "Julio Gonzalo",
        "email": "julio@lsi.uned.es"
      },
      {
        "affiliation": "UNED",
        "location": "Madrid, Spain",
        "name": "Felisa Verdejo",
        "email": "felisa@lsi.uned.es"
      }
    ]
  },
  "r8a01": {
    "abstract": "Traditional information retrieval (IR) models use bag-of-words as the basic representation and assume that some form of independence holds between terms. Representing term dependencies and defining a scoring function capable of integrating such additional evidence is theoretically and practically challenging. Recently, Quantum Theory (QT) has been proposed as a possible, more general framework for IR. However, only a limited number of investigations have been made and the potential of QT has not been fully explored and tested. We develop a new, generalized Language Modeling approach for IR by adopting the probabilistic framework of QT. In particular, quantum probability could account for both single and compound terms at once without having to extend the term space artificially as in previous studies.  This naturally allows us to avoid the weight-normalization problem, which arises in the current practice by mixing scores from matching compound terms and from matching single terms. Our model is the first practical application of quantum probability to show significant improvements over a robust bag-of-words baseline and achieves better performance on a stronger non bag-of-words baseline.",
    "title": "Modeling Term Dependencies with Quantum Language Models for IR",
    "authors": [
      {
        "affiliation": "Université de Montréal",
        "location": "Montréal, PQ, Canada",
        "name": "Alessandro Sordoni",
        "email": "sordonia@iro.umontreal.ca"
      },
      {
        "affiliation": "Université de Montréal",
        "location": "Montréal, PQ, Canada",
        "name": "Jian-Yun Nie",
        "email": "nie@iro.umontreal.ca"
      },
      {
        "affiliation": "Université de Montréal",
        "location": "Montréal, PQ, Canada",
        "name": "Yoshua Bengio ",
        "email": "bengioy@iro.umontreal.ca"
      }
    ]
  },
  "r8a02": {
    "abstract": "In many domains of information retrieval, system estimates of document relevance are based on multidimensional quality criteria that have to be accommodated in a unidimensional result ranking.  Current solutions to this challenge are often inconsistent with the formal probabilistic framework in which constituent scores were estimated, or use sophisticated learning methods that make it difficult for humans to understand the origin of the final ranking. To address these issues, we introduce the use of copulas, a powerful statistical framework for modeling complex multi-dimensional dependencies, to information retrieval tasks.  We provide a formal background to copulas and demonstrate their effectiveness on standard IR tasks such as combining multidimensional relevance estimates and fusion of results from multiple search engines.  We introduce copula-based versions of standard relevance estimators and fusion methods and show that these lead to significant performance improvements on several tasks, as evaluated on large-scale standard corpora, compared to their non-copula counterparts.  We also investigate criteria for understanding the likely effect of using copula models in a given retrieval scenario.",
    "title": "Copulas for Information Retrieval",
    "authors": [
      {
        "affiliation": "Delft University of Technology",
        "location": "Delft, Netherlands",
        "name": "Carsten Eickhoff",
        "email": "c.eickhoff@acm.org"
      },
      {
        "affiliation": "Centrum Wiskunde & Informatica",
        "location": "Amsterdam, Netherlands",
        "name": "Arjen P. de Vries",
        "email": "arjen@acm.org"
      },
      {
        "affiliation": "Microsoft Research",
        "location": "Redmond, WA, USA",
        "name": "Kevyn Collins-Thompson",
        "email": "kevynct@microsoft.com"
      }
    ]
  },
  "r8a03": {
    "abstract": "Search engines can improve their efficiency by selecting only few promising shards for each query. State-of-the-art shard selection algorithms first query a central index of sampled documents, and their effectiveness is similar to searching all shards. However, the search in the central index also hurts efficiency. Additionally, we show that the effectiveness of these approaches varies substantially with the sampled documents. This paper proposes Taily, a novel shard selection algorithm that models a query's score distribution in each shard as a Gamma distribution and selects shards with highly scored documents in the tail of the distribution. Taily estimates the parameters of score distributions based on the mean and variance of the score function's features in the collections and shards. Because Taily operates on term statistics instead of document samples, it is efficient and has deterministic effectiveness. Experiments on large web collections (Gov2, CluewebA and CluewebB) show that Taily achieves similar effectiveness to sample-based approaches, and improves upon their efficiency by roughly 20% in terms of used resources and response time. ",
    "title": "Taily: Shard Selection Using the Tail of Score Distributions",
    "authors": [
      {
        "affiliation": "University Twente",
        "location": "Enschede, Netherlands",
        "name": " Robin Aly",
        "email": "r.aly@ewi.utwenet.nl"
      },
      {
        "affiliation": "University Twente",
        "location": "Enschede, Netherlands",
        "name": "Djoerd Hiemstra",
        "email": "hiemstra@ewi.utwente.nl"
      },
      {
        "affiliation": "Ghent University",
        "location": "Ghent, Belgium",
        "name": "Thomas Demeester",
        "email": "thomas.demeester@intec.ugent.be"
      }
    ]
  },
  "r8a04": {
    "abstract": "We consider the problem of information retrieval evaluation and the methods and metrics used for such evaluations.  We propose a probabilistic framework for evaluation which we use to develop new information-theoretic evaluation metrics. We demonstrate that these new metrics are powerful and generalizable, enabling evaluations heretofore not possible. We introduce four preliminary uses of our framework: (1) a measure of conditional rank correlation, information tau, a powerful meta-evaluation tool whose use we demonstrate on understanding novelty and diversity evaluation; (2) a new evaluation measure, relevance information correlation, which is correlated with traditional evaluation measures and can be used to (3) evaluate a collection of systems simultaneously, which provides a natural upper bound on metasearch performance; and (4) a measure of the similarity between rankers on judged documents, information difference, which allows us to determine whether systems with similar performance are in fact different.",
    "title": "A Mutual Information-based Framework for the Analysis of Information Retrieval Systems",
    "authors": [
      {
        "affiliation": "Northeastern University",
        "location": "Boston, MA, USA",
        "name": "Peter B. Golbus",
        "email": "pgolbus@ccs.neu.edu"
      },
      {
        "affiliation": "Northeastern University",
        "location": "Boston, MA, USA",
        "name": "Javed A. Aslam",
        "email": "jaa@ccs.neu.edu"
      }
    ]
  },
  "r8b01": {
    "abstract": "A large amount of research has focused on faster methods for finding top-k results in large document collections, one of the main scalability challenges for web search engines. In this paper, we propose a method for accelerating such top-k queries that builds on and generalizes methods recently proposed by several groups of researchers based on Block-Max Indexes. In particular, we describe a system that uses a new filtering mechanism, based on a combination of block maxima and bitmaps, that radically reduces the number of documents that have to be further evaluated. Our filtering mechanism exploits the SIMD processing capabilities of current microprocessors, and it is optimized through caching policies that select and store suitable filter structures based on properties of the query load. Our experimental evaluation shows that the mechanism results in very significant speed-ups for disjunctive top-k queries under several state-of-the-art algorithms, including a speed-up of more than a factor of 2 over the fastest previously known methods.",
    "title": "A Candidate Filtering Mechanism for Fast Top-K Query Processing on Modern CPUs",
    "authors": [
      {
        "affiliation": "Polytechnic Institute of NYU",
        "location": "Brooklyn, NY, USA",
        "name": "Constantinos Dimopoulos",
        "email": "constantinos@cis.poly.edu"
      },
      {
        "affiliation": "Polytechnic Institute of NYU",
        "location": "Brooklyn, NY, USA",
        "name": "Sergey Nepomnyachiy",
        "email": "snepom01@students.poly.edu"
      },
      {
        "affiliation": "Polytechnic Institute of NYU",
        "location": "Brooklyn, NY, USA",
        "name": "Torsten Suel",
        "email": "suel@poly.edu"
      }
    ]
  },
  "r8b02": {
    "abstract": "There is a long history of developing efficient algorithms for set intersection, which is a fundamental operation in information retrieval and databases. In this paper, we describe a new data structure, a Cardinality Filter, to quickly compute an upper bound on the size of a set intersection. Knowing an upper bound of the size can be used to accelerate many applications such as top-$ k $ query processing in text mining. Given finite sets $ A $ and $ B $, the expected computation time for the upper bound of the size of the intersection $ |A \cap B| $ is $ O( (|A| + |B|) / w) $, where $ w $ is the machine word length. This is much faster than the current best algorithm for the exact intersection, which runs in $ O((|A| + |B|) / \sqrt w + |A \cap B|) $ expected time. Our performance studies show that our implementations of Cardinality Filters are from 2 to 10 times faster than existing set intersection algorithms, and the time for a top-$ k $ query in a text mining application can be reduced by half.",
    "title": "Faster Upper Bounding of Intersection Sizes",
    "authors": [
      {
        "affiliation": "IBM Research  Tokyo",
        "location": "Tokyo, Japan",
        "name": "Daisuke Takuma",
        "email": "ta9ma@jp.ibm.com"
      },
      {
        "affiliation": "IBM Research  Tokyo",
        "location": "Tokyo, Japan",
        "name": "Hiroki Yanagisawa",
        "email": "yanagis@jp.ibm.com"
      }
    ]
  },
  "r8b03": {
    "abstract": "All-pairs similarity search can be implemented in two stages. The first stage is to partition the  data and group potentially similar vectors.  The second stage is to run a set of tasks where each task compares a partition of vectors with other candidate partitions. Because of data sparsity, accessing feature vectors in memory for runtime comparison in the second stage, incurs significant overhead due to the presence of memory hierarchy. This paper  proposes a cache-conscious data layout and traversal optimization to reduce the execution time through size-controlled data splitting and vector coalescing.  It also provides an  analysis to  guide the optimal choice for the parameter setting. Our evaluation with several application datasets verifies the performance gains obtained by the optimization and shows that the proposed scheme is  upto 2.74x as fast as the cache-oblivious  baseline.",
    "title": "Cache-Conscious Performance Optimization for Similarity Search",
    "authors": [
      {
        "affiliation": "University of California at Santa Barbara",
        "location": "Santa Barbara, CA, USA",
        "name": "Maha Ahmed Alabduljalil",
        "email": "maha@cs.ucsb.edu"
      },
      {
        "affiliation": "University of California at Santa Barbara",
        "location": "Santa Barbara, CA, USA",
        "name": "Xun Tang",
        "email": "xtang@cs.ucsb.edu"
      },
      {
        "affiliation": "University of California at Santa Barbara",
        "location": "Santa Barbara, CA, USA",
        "name": "Tao Yang",
        "email": "tyang@cs.ucsb.edu"
      }
    ]
  },
  "r8b04": {
    "abstract": "Caching is an important optimization in search engine architectures. Existing caching techniques for search engine optimization are mostly biased towards the reduction of random accesses to disks, because random accesses are known to be much more expensive than sequential accesses in traditional magnetic hard disk drive (HDD). Recently, solid state drive (SSD) has emerged as a new kind of secondary storage medium, and some search engines like Baidu have already used SSD to completely replace HDD in their infrastructure. One notable property of SSD is that its random access latency is comparable to its sequential access latency. Therefore, the use of SSDs to replace HDDs in a search engine infrastructure may void the cache management of existing search engines. In this paper, we carry out a series of  empirical experiments to study the impact of SSD on search engine cache management. The results give insights to practitioners and researchers on how to adapt the infrastructure and how to redesign the caching policies for SSD-based search engines.",
    "title": "The Impact of Solid State Drive on Search Engine Cache Management",
    "authors": [
      {
        "affiliation": "The Hong Kong Polytechnic University",
        "location": "Kowloon, Hong Kong ",
        "name": "Jianguo Wang",
        "email": "csjgwang@comp.polyu.edu.hk"
      },
      {
        "affiliation": "The Hong Kong Polytechnic University",
        "location": "Kowloon, Hong Kong ",
        "name": "Eric Lo",
        "email": "ericlo@comp.polyu.edu.hk"
      },
      {
        "affiliation": "The Hong Kong Polytechnic University",
        "location": "Kowloon, Hong Kong ",
        "name": "Man Lung Yiu",
        "email": "csmlyiu@comp.polyu.edu.hk"
      },
      {
        "affiliation": "Nankai University",
        "location": "Tianjin  China",
        "name": "Jiancong Tong",
        "email": ""
      },
      {
        "affiliation": "Nankai University",
        "location": "Tianjin  China",
        "name": "Gang Wang",
        "email": "wgzwpzy@gmail.com"
      },
      {
        "affiliation": "Nankai University",
        "location": "Tianjin  China",
        "name": "Xiaoguang Liu",
        "email": "liuxguang@gmail.com"
      }
    ]
  },
  "closingpanel": {
    "abstract": "",
    "title": "Closing Session",
    "authors": [
      {
        "affiliation": "SIGIR",
        "location": "",
        "name": "Closing Panel",
        "email": ""
      }
    ]
  }
}